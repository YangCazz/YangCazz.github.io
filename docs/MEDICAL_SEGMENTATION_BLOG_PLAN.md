# åŒ»å­¦å½±åƒåˆ†å‰²ç½‘ç»œç³»åˆ—åšå®¢è§„åˆ’

## ğŸ“‹ æ€»ä½“æ–¹æ¡ˆ

### ç›®æ ‡
æ’°å†™ä¸€ç³»åˆ—é«˜è´¨é‡åšå®¢æ–‡ç« ï¼Œç³»ç»Ÿä»‹ç»åŒ»å­¦å½±åƒåˆ†å‰²é¢†åŸŸçš„ç»å…¸ç½‘ç»œï¼Œä»åŸºç¡€åˆ°å‰æ²¿ï¼Œè¦†ç›–ä¸»è¦æŠ€æœ¯è·¯çº¿ã€‚

### ç³»åˆ—ç‰¹è‰²
- âœ… **æ—¶é—´è„‰ç»œæ¸…æ™°**ï¼šæŒ‰æŠ€æœ¯æ¼”è¿›é¡ºåºç»„ç»‡
- âœ… **æ•°å­¦ä¸¥è°¨**ï¼šåŒ…å«å®Œæ•´çš„æ•°å­¦å®šä¹‰å’Œå…¬å¼æ¨å¯¼
- âœ… **ä»£ç å¯å¤ç°**ï¼šæä¾›å®˜æ–¹ä»£ç åº“é“¾æ¥å’Œå…³é”®å®ç°
- âœ… **æŠ€æœ¯å…³è”**ï¼šæ˜ç¡®å„ç½‘ç»œä¹‹é—´çš„ç»§æ‰¿å’Œåˆ›æ–°å…³ç³»
- âœ… **å®ç”¨å¯¼å‘**ï¼šåŒ…å«åº”ç”¨åœºæ™¯å’Œæ€§èƒ½å¯¹æ¯”

---

## ğŸ—ºï¸ æŠ€æœ¯å‘å±•è·¯çº¿å›¾

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€æ¶æ„æ—¶ä»£ (2015-2016)
**æ ¸å¿ƒç‰¹å¾**ï¼šå…¨å·ç§¯ç½‘ç»œã€ç¼–ç å™¨-è§£ç å™¨ç»“æ„

```
FCN (2015) â”€â”€â”€â”€â”
               â”œâ”€â”€â†’ å…¨å·ç§¯æ€æƒ³
UNet (2015) â”€â”€â”€â”¤
               â””â”€â”€â†’ Skip Connection
                    
V-Net (2016) â”€â”€â”€â”€â”€â”€â†’ 3Dæ‰©å±•
```

**æŠ€æœ¯å…³é”®è¯**ï¼š
- Fully Convolutional Networks
- Encoder-Decoder Architecture
- Skip Connections
- Upsampling (Transposed Convolution)

---

### ç¬¬äºŒé˜¶æ®µï¼šUNetæ”¹è¿›æ—¶ä»£ (2017-2020)
**æ ¸å¿ƒç‰¹å¾**ï¼šæ³¨æ„åŠ›æœºåˆ¶ã€å¯†é›†è¿æ¥ã€å¤šå°ºåº¦èåˆ

```
UNet (2015)
    â”‚
    â”œâ”€â”€â†’ ResUNet (2017) â”€â”€â”€â”€â”€â”€â”€â†’ æ®‹å·®è¿æ¥
    â”‚
    â”œâ”€â”€â†’ Attention UNet (2018) â”€â†’ æ³¨æ„åŠ›é—¨æ§
    â”‚
    â”œâ”€â”€â†’ UNet++ (2018) â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ åµŒå¥—Skipè¿æ¥
    â”‚
    â””â”€â”€â†’ UNet 3+ (2020) â”€â”€â”€â”€â”€â”€â”€â”€â†’ å…¨å°ºåº¦èåˆ
```

**æŠ€æœ¯å…³é”®è¯**ï¼š
- Residual Connections
- Attention Gates
- Nested Skip Connections
- Deep Supervision
- Multi-scale Feature Fusion

---

### ç¬¬ä¸‰é˜¶æ®µï¼šTransformeré©å‘½ (2021-2022)
**æ ¸å¿ƒç‰¹å¾**ï¼šè‡ªæ³¨æ„åŠ›ã€é•¿ç¨‹ä¾èµ–ã€æ··åˆæ¶æ„

```
Vision Transformer (2020)
    â”‚
    â”œâ”€â”€â†’ TransUNet (2021) â”€â”€â†’ Transformerä½œä¸ºEncoder
    â”‚
    â”œâ”€â”€â†’ Swin-UNet (2021) â”€â”€â†’ Shifted Window Attention
    â”‚
    â”œâ”€â”€â†’ UNETR (2021) â”€â”€â”€â”€â”€â”€â†’ çº¯Transformer Encoder
    â”‚
    â”œâ”€â”€â†’ nnFormer (2021) â”€â”€â”€â†’ 3DåŒ»å­¦å›¾åƒ
    â”‚
    â””â”€â”€â†’ MedFormer (2022) â”€â”€â”€â†’ è½»é‡åŒ–åŒ»å­¦Transformer
```

**æŠ€æœ¯å…³é”®è¯**ï¼š
- Self-Attention Mechanism
- Patch Embedding
- Position Encoding
- Window-based Attention
- Hybrid CNN-Transformer

---

### ç¬¬å››é˜¶æ®µï¼šåŸºç¡€æ¨¡å‹æ—¶ä»£ (2023-è‡³ä»Š)
**æ ¸å¿ƒç‰¹å¾**ï¼šå¤§è§„æ¨¡é¢„è®­ç»ƒã€æç¤ºå­¦ä¹ ã€é›¶æ ·æœ¬/å°‘æ ·æœ¬

```
SAM (2023) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Segment Anything Model
    â”‚
    â”œâ”€â”€â†’ MedSAM (2023) â”€â”€â”€â”€â”€â”€â†’ åŒ»å­¦é¢†åŸŸå¾®è°ƒ
    â”‚
    â”œâ”€â”€â†’ SAM-Med2D (2023) â”€â”€â”€â†’ 2DåŒ»å­¦å›¾åƒä¼˜åŒ–
    â”‚
    â”œâ”€â”€â†’ SAM-Med3D (2023) â”€â”€â”€â†’ 3DåŒ»å­¦å›¾åƒæ‰©å±•
    â”‚
    â””â”€â”€â†’ MedicalSAM (2024) â”€â”€â†’ å¤šæ¨¡æ€åŒ»å­¦SAM
```

**æŠ€æœ¯å…³é”®è¯**ï¼š
- Foundation Models
- Prompt Engineering
- Zero-shot Learning
- Few-shot Learning
- Interactive Segmentation

---

### ç‰¹æ®Šåˆ†æ”¯ï¼šè‡ªé€‚åº”æ¡†æ¶
```
nnU-Net (2018) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ è‡ªåŠ¨é…ç½®åˆ†å‰²æ¡†æ¶
    â”‚
    â””â”€â”€â†’ nnU-Net v2 (2022) â”€â†’ æ”¹è¿›ç‰ˆæœ¬
```

**æŠ€æœ¯å…³é”®è¯**ï¼š
- Automatic Configuration
- Self-adapting
- Best Practices

---

## ğŸ“š åšå®¢ç³»åˆ—è§„åˆ’

### ç³»åˆ—1ï¼šåŸºç¡€ç¯‡ - åŒ»å­¦åˆ†å‰²çš„å¥ åŸºä¹‹ä½œ

#### åšå®¢1: FCNä¸UNet - å…¨å·ç§¯ç½‘ç»œçš„è¯ç”Ÿ (2015)
**æ–‡ä»¶å**: `2025-02-01-fcn-unet-foundation.md`
**å‘å¸ƒæ—¥æœŸ**: 2025-02-01

**å†…å®¹å¤§çº²**ï¼š
1. **å¼•è¨€**
   - åŒ»å­¦å›¾åƒåˆ†å‰²çš„æŒ‘æˆ˜
   - ä»åˆ†ç±»åˆ°åˆ†å‰²çš„æ¼”è¿›

2. **FCN: Fully Convolutional Networks**
   - æ ¸å¿ƒæ€æƒ³ï¼šå»é™¤å…¨è¿æ¥å±‚
   - æ•°å­¦å®šä¹‰ï¼š
     - è½¬ç½®å·ç§¯ (Transposed Convolution)
     - ä¸Šé‡‡æ ·ç­–ç•¥
   - ç½‘ç»œæ¶æ„
   - è®ºæ–‡ï¼š[Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1411.4038)
   - ä»£ç ï¼š[å®˜æ–¹å®ç°](https://github.com/shelhamer/fcn.berkeleyvision.org)

3. **UNet: åŒ»å­¦å›¾åƒåˆ†å‰²çš„é‡Œç¨‹ç¢‘**
   - æ ¸å¿ƒåˆ›æ–°ï¼šå¯¹ç§°çš„Uå‹ç»“æ„ + Skip Connections
   - æ•°å­¦å®šä¹‰ï¼š
     - ç¼–ç å™¨-è§£ç å™¨å…¬å¼
     - Skip Connectionçš„æ•°å­¦è¡¨ç¤º
     - æŸå¤±å‡½æ•°ï¼ˆDice Loss, Cross Entropyï¼‰
   - ç½‘ç»œæ¶æ„è¯¦è§£
   - ä¸ºä»€ä¹ˆé€‚åˆåŒ»å­¦å›¾åƒï¼Ÿ
     - å°æ ·æœ¬å­¦ä¹ 
     - æ•°æ®å¢å¼ºç­–ç•¥
   - è®ºæ–‡ï¼š[U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
   - ä»£ç ï¼š
     - [å®˜æ–¹TensorFlowå®ç°](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)
     - [PyTorchå®ç°](https://github.com/milesial/Pytorch-UNet)

4. **æ€§èƒ½å¯¹æ¯”ä¸åº”ç”¨**
   - åœ¨åŒ»å­¦æ•°æ®é›†ä¸Šçš„è¡¨ç°
   - å…¸å‹åº”ç”¨åœºæ™¯

5. **æ€»ç»“ä¸å±•æœ›**

---

#### åšå®¢2: V-Net - 3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„çªç ´ (2016)
**æ–‡ä»¶å**: `2025-02-05-vnet-3d-segmentation.md`
**å‘å¸ƒæ—¥æœŸ**: 2025-02-05

**å†…å®¹å¤§çº²**ï¼š
1. **ä»2Dåˆ°3Dçš„æŒ‘æˆ˜**
2. **V-Netæ ¸å¿ƒåˆ›æ–°**
   - 3Då·ç§¯
   - Residual Connections
   - Dice Loss
3. **æ•°å­¦å®šä¹‰**
   - 3Då·ç§¯å…¬å¼
   - Dice Lossæ¨å¯¼
   - æ®‹å·®å—å®šä¹‰
4. **ç½‘ç»œæ¶æ„**
5. **è®ºæ–‡ä¸ä»£ç **
   - è®ºæ–‡ï¼š[V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation](https://arxiv.org/abs/1606.04797)
   - ä»£ç ï¼š[PyTorchå®ç°](https://github.com/mattmacy/vnet.pytorch)

---

### ç³»åˆ—2ï¼šè¿›é˜¶ç¯‡ - UNetçš„æ¼”è¿›ä¸æ”¹è¿›

#### åšå®¢3: Attention UNet - æ³¨æ„åŠ›æœºåˆ¶çš„å¼•å…¥ (2018)
**æ–‡ä»¶å**: `2025-02-10-attention-unet.md`
**å‘å¸ƒæ—¥æœŸ**: 2025-02-10

**å†…å®¹å¤§çº²**ï¼š
1. **æ³¨æ„åŠ›æœºåˆ¶ç®€ä»‹**
2. **Attention Gates**
   - æ ¸å¿ƒæ€æƒ³
   - æ•°å­¦å®šä¹‰
   - é—¨æ§æœºåˆ¶å…¬å¼
3. **ç½‘ç»œæ¶æ„**
4. **ä¸æ ‡å‡†UNetå¯¹æ¯”**
5. **è®ºæ–‡ä¸ä»£ç **
   - è®ºæ–‡ï¼š[Attention U-Net: Learning Where to Look for the Pancreas](https://arxiv.org/abs/1804.03999)
   - ä»£ç ï¼š[å®˜æ–¹å®ç°](https://github.com/ozan-octopus/attention-unet)

---

#### åšå®¢4: UNet++ å’Œ UNet 3+ - å¯†é›†è¿æ¥çš„åŠ›é‡
**æ–‡ä»¶å**: `2025-02-15-unet-plus-series.md`
**å‘å¸ƒæ—¥æœŸ**: 2025-02-15

**å†…å®¹å¤§çº²**ï¼š
1. **UNet++: åµŒå¥—Skipè¿æ¥**
   - æ ¸å¿ƒåˆ›æ–°ï¼šDense Skip Connections
   - æ•°å­¦å®šä¹‰
   - Deep Supervision
   - è®ºæ–‡ï¼š[UNet++: A Nested U-Net Architecture](https://arxiv.org/abs/1807.10165)
   - ä»£ç ï¼š[å®˜æ–¹å®ç°](https://github.com/MrGiovanni/UNetPlusPlus)

2. **UNet 3+: å…¨å°ºåº¦ç‰¹å¾èåˆ**
   - æ ¸å¿ƒåˆ›æ–°ï¼šFull-scale Skip Connections
   - æ•°å­¦å®šä¹‰
   - è®ºæ–‡ï¼š[UNet 3+: A Full-Scale Connected UNet](https://arxiv.org/abs/2004.08790)
   - ä»£ç ï¼š[PyTorchå®ç°](https://github.com/ZJUGiveLab/UNet-Version)

3. **å¯¹æ¯”åˆ†æ**

---

### ç³»åˆ—3ï¼šTransformerç¯‡ - è‡ªæ³¨æ„åŠ›çš„é©å‘½

#### åšå®¢5: TransUNet - CNNä¸Transformerçš„èåˆ (2021)
**æ–‡ä»¶å**: `2025-02-20-transunet-hybrid-architecture.md`
**å‘å¸ƒæ—¥æœŸ**: 2025-02-20

**å†…å®¹å¤§çº²**ï¼š
1. **Transformeråœ¨è§†è§‰é¢†åŸŸçš„åº”ç”¨**
2. **TransUNetæ¶æ„**
   - CNN Encoder
   - Transformerä½œä¸ºBottleneck
   - CNN Decoder
3. **æ•°å­¦å®šä¹‰**
   - Multi-Head Self-Attention
   - Position Encoding
   - æ··åˆæ¶æ„å…¬å¼
4. **è®ºæ–‡ä¸ä»£ç **
   - è®ºæ–‡ï¼š[TransUNet: Transformers Make Strong Encoders](https://arxiv.org/abs/2102.04306)
   - ä»£ç ï¼š[å®˜æ–¹å®ç°](https://github.com/Beckschen/TransUNet)

---

#### åšå®¢6: Swin-UNet - å±‚çº§åŒ–è§†è§‰Transformer (2021)
**æ–‡ä»¶å**: `2025-02-25-swin-unet-hierarchical-transformer.md`
**å‘å¸ƒæ—¥æœŸ**: 2025-02-25

**å†…å®¹å¤§çº²**ï¼š
1. **Swin Transformerç®€ä»‹**
2. **Swin-UNetæ¶æ„**
   - Shifted Window Attention
   - Patch Merging
   - å±‚çº§åŒ–ç‰¹å¾
3. **æ•°å­¦å®šä¹‰**
   - Window-based Attention
   - Shifted Windowæœºåˆ¶
   - ç›¸å¯¹ä½ç½®ç¼–ç 
4. **è®ºæ–‡ä¸ä»£ç **
   - è®ºæ–‡ï¼š[Swin-UNet: Unet-like Pure Transformer](https://arxiv.org/abs/2105.05537)
   - ä»£ç ï¼š[å®˜æ–¹å®ç°](https://github.com/HuCaoFighting/Swin-Unet)

---

#### åšå®¢7: UNETR å’Œ nnFormer - çº¯Transformeræ¶æ„
**æ–‡ä»¶å**: `2025-03-01-unetr-nnformer-pure-transformer.md`
**å‘å¸ƒæ—¥æœŸ**: 2025-03-01

**å†…å®¹å¤§çº²**ï¼š
1. **UNETR: çº¯Transformer Encoder**
   - 3D Patch Embedding
   - è®ºæ–‡ï¼š[UNETR: Transformers for 3D Medical Image Segmentation](https://arxiv.org/abs/2103.10504)
   - ä»£ç ï¼š[MONAIå®ç°](https://github.com/Project-MONAI/research-contributions)

2. **nnFormer: 3DåŒ»å­¦å›¾åƒçš„Transformer**
   - è®ºæ–‡ï¼š[nnFormer: Interleaved Transformer](https://arxiv.org/abs/2109.03201)
   - ä»£ç ï¼š[å®˜æ–¹å®ç°](https://github.com/282857341/nnFormer)

---

### ç³»åˆ—4ï¼šåŸºç¡€æ¨¡å‹ç¯‡ - SAMä¸åŒ»å­¦åº”ç”¨

#### åšå®¢8: SAM - Segment Anything Model (2023)
**æ–‡ä»¶å**: `2025-03-05-sam-segment-anything.md`
**å‘å¸ƒæ—¥æœŸ**: 2025-03-05

**å†…å®¹å¤§çº²**ï¼š
1. **åŸºç¡€æ¨¡å‹çš„æ¦‚å¿µ**
2. **SAMæ¶æ„**
   - Image Encoder (ViT)
   - Prompt Encoder
   - Mask Decoder
3. **æ•°å­¦å®šä¹‰**
   - Prompt Learning
   - Multi-scale Features
4. **è®ºæ–‡ä¸ä»£ç **
   - è®ºæ–‡ï¼š[Segment Anything](https://arxiv.org/abs/2304.02643)
   - ä»£ç ï¼š[å®˜æ–¹å®ç°](https://github.com/facebookresearch/segment-anything)

---

#### åšå®¢9: MedSAMç³»åˆ— - SAMçš„åŒ»å­¦æ”¹è¿›
**æ–‡ä»¶å**: `2025-03-10-medsam-medical-adaptation.md`
**å‘å¸ƒæ—¥æœŸ**: 2025-03-10

**å†…å®¹å¤§çº²**ï¼š
1. **SAMåœ¨åŒ»å­¦é¢†åŸŸçš„æŒ‘æˆ˜**
2. **MedSAM**
   - åŒ»å­¦æ•°æ®å¾®è°ƒ
   - è®ºæ–‡ï¼š[Segment Anything in Medical Images](https://arxiv.org/abs/2304.12306)
   - ä»£ç ï¼š[å®˜æ–¹å®ç°](https://github.com/bowang-lab/MedSAM)

3. **SAM-Med2D**
   - 2DåŒ»å­¦å›¾åƒä¼˜åŒ–
   - è®ºæ–‡ï¼š[SAM-Med2D](https://arxiv.org/abs/2308.16184)
   - ä»£ç ï¼š[å®˜æ–¹å®ç°](https://github.com/OpenGVLab/SAM-Med2D)

4. **æ€§èƒ½å¯¹æ¯”ä¸åº”ç”¨**

---

### ç³»åˆ—5ï¼šå®ç”¨æ¡†æ¶ç¯‡

#### åšå®¢10: nnU-Net - è‡ªé€‚åº”åŒ»å­¦åˆ†å‰²æ¡†æ¶ (2018-2022)
**æ–‡ä»¶å**: `2025-03-15-nnunet-self-configuring-framework.md`
**å‘å¸ƒæ—¥æœŸ**: 2025-03-15

**å†…å®¹å¤§çº²**ï¼š
1. **nnU-Netçš„å“²å­¦**
   - è‡ªåŠ¨é…ç½®
   - æœ€ä½³å®è·µé›†åˆ
2. **æ ¸å¿ƒç»„ä»¶**
   - æ•°æ®é¢„å¤„ç†
   - ç½‘ç»œæ¶æ„è‡ªé€‚åº”
   - è®­ç»ƒç­–ç•¥
   - åå¤„ç†
3. **æ•°å­¦å®šä¹‰ä¸å®ç°**
4. **è®ºæ–‡ä¸ä»£ç **
   - è®ºæ–‡v1ï¼š[nnU-Net: Self-adapting Framework](https://arxiv.org/abs/1809.10486)
   - è®ºæ–‡v2ï¼š[nnU-Net Revisited](https://arxiv.org/abs/2106.06858)
   - ä»£ç ï¼š[å®˜æ–¹å®ç°](https://github.com/MIC-DKFZ/nnUNet)

---

## ğŸ“Š ç½‘ç»œå¯¹æ¯”æ€»è¡¨

| ç½‘ç»œåç§° | å¹´ä»½ | æ ¸å¿ƒåˆ›æ–° | ç»´åº¦ | Dice (ç¤ºä¾‹) | å®˜æ–¹ä»£ç  |
|---------|------|---------|------|------------|---------|
| FCN | 2015 | å…¨å·ç§¯ | 2D | - | [é“¾æ¥](https://github.com/shelhamer/fcn.berkeleyvision.org) |
| UNet | 2015 | Skipè¿æ¥ | 2D | 0.92 | [é“¾æ¥](https://github.com/milesial/Pytorch-UNet) |
| V-Net | 2016 | 3D+Dice Loss | 3D | 0.89 | [é“¾æ¥](https://github.com/mattmacy/vnet.pytorch) |
| Attention UNet | 2018 | æ³¨æ„åŠ›é—¨æ§ | 2D | 0.93 | [é“¾æ¥](https://github.com/ozan-octopus/attention-unet) |
| UNet++ | 2018 | å¯†é›†Skip | 2D/3D | 0.94 | [é“¾æ¥](https://github.com/MrGiovanni/UNetPlusPlus) |
| nnU-Net | 2018 | è‡ªé€‚åº”æ¡†æ¶ | 2D/3D | 0.95+ | [é“¾æ¥](https://github.com/MIC-DKFZ/nnUNet) |
| UNet 3+ | 2020 | å…¨å°ºåº¦èåˆ | 2D | 0.94 | [é“¾æ¥](https://github.com/ZJUGiveLab/UNet-Version) |
| TransUNet | 2021 | CNN+Transformer | 2D | 0.94 | [é“¾æ¥](https://github.com/Beckschen/TransUNet) |
| Swin-UNet | 2021 | Shifted Window | 2D | 0.95 | [é“¾æ¥](https://github.com/HuCaoFighting/Swin-Unet) |
| UNETR | 2021 | çº¯Transformer | 3D | 0.93 | [é“¾æ¥](https://github.com/Project-MONAI/research-contributions) |
| nnFormer | 2021 | 3D Transformer | 3D | 0.94 | [é“¾æ¥](https://github.com/282857341/nnFormer) |
| SAM | 2023 | åŸºç¡€æ¨¡å‹ | 2D | - | [é“¾æ¥](https://github.com/facebookresearch/segment-anything) |
| MedSAM | 2023 | åŒ»å­¦SAM | 2D | 0.90 | [é“¾æ¥](https://github.com/bowang-lab/MedSAM) |
| SAM-Med2D | 2023 | 2DåŒ»å­¦ä¼˜åŒ– | 2D | 0.92 | [é“¾æ¥](https://github.com/OpenGVLab/SAM-Med2D) |

---

## ğŸ¨ åšå®¢ç»Ÿä¸€æ¨¡æ¿

æ¯ç¯‡åšå®¢å°†åŒ…å«ä»¥ä¸‹æ ‡å‡†éƒ¨åˆ†ï¼š

### 1. Front Matter
```yaml
---
layout: post
title: "ç½‘ç»œåç§° - å‰¯æ ‡é¢˜"
date: YYYY-MM-DD
categories: [åŒ»å­¦å½±åƒ, å›¾åƒåˆ†å‰²]
tags: [æ·±åº¦å­¦ä¹ , UNetç³»åˆ—/Transformer/SAM, åŒ»å­¦AI]
excerpt: "ç®€çŸ­æ‘˜è¦ï¼ˆ2-3å¥è¯ï¼‰"
author: YangCazz
math: true
---
```

### 2. æ–‡ç« ç»“æ„
1. **å¼•è¨€** - èƒŒæ™¯ä¸åŠ¨æœº
2. **æ ¸å¿ƒæ€æƒ³** - ä¸»è¦åˆ›æ–°ç‚¹
3. **ç½‘ç»œæ¶æ„** - è¯¦ç»†ç»“æ„
4. **æ•°å­¦å®šä¹‰** - å…¬å¼æ¨å¯¼
5. **å®ç°ç»†èŠ‚** - ä»£ç è§£æ
6. **å®éªŒç»“æœ** - æ€§èƒ½åˆ†æ
7. **åº”ç”¨åœºæ™¯** - å®é™…æ¡ˆä¾‹
8. **æ€»ç»“** - ä¼˜ç¼ºç‚¹ä¸å±•æœ›
9. **å‚è€ƒèµ„æ–™** - è®ºæ–‡ã€ä»£ç ã€æ‰©å±•é˜…è¯»

### 3. å›¾ç‰‡èµ„æº
- ç½‘ç»œæ¶æ„å›¾
- å…³é”®æ¨¡å—ç¤ºæ„å›¾
- å®éªŒç»“æœå¯è§†åŒ–
- æ€§èƒ½å¯¹æ¯”å›¾è¡¨

---

## ğŸ“… å‘å¸ƒæ—¶é—´è¡¨

| åšå®¢ç¼–å· | æ ‡é¢˜ | è®¡åˆ’å‘å¸ƒæ—¥æœŸ |
|---------|------|-------------|
| 1 | FCNä¸UNet - åŸºç¡€ | 2025-02-01 |
| 2 | V-Net - 3Dåˆ†å‰² | 2025-02-05 |
| 3 | Attention UNet | 2025-02-10 |
| 4 | UNet++/UNet 3+ | 2025-02-15 |
| 5 | TransUNet | 2025-02-20 |
| 6 | Swin-UNet | 2025-02-25 |
| 7 | UNETR/nnFormer | 2025-03-01 |
| 8 | SAM | 2025-03-05 |
| 9 | MedSAMç³»åˆ— | 2025-03-10 |
| 10 | nnU-Net | 2025-03-15 |

---

## ğŸ”§ æŠ€æœ¯å‡†å¤‡

### æ•°å­¦å…¬å¼æ¸²æŸ“
- âœ… å·²é…ç½®MathJax 3
- âœ… æ”¯æŒè¡Œå†…å…¬å¼ `\( ... \)`
- âœ… æ”¯æŒå—çº§å…¬å¼ `$$ ... $$`

### ä»£ç é«˜äº®
- âœ… å·²é…ç½®Rougeè¯­æ³•é«˜äº®
- âœ… æ”¯æŒPythonã€YAMLç­‰
- âœ… ä¸€é”®å¤åˆ¶åŠŸèƒ½

### å›¾ç‰‡ç®¡ç†
- å­˜æ”¾è·¯å¾„ï¼š`assets/images/medical-segmentation/`
- å­æ–‡ä»¶å¤¹æŒ‰ç½‘ç»œåˆ†ç±»

---

## ğŸ“– å‚è€ƒèµ„æº

### ç»¼è¿°è®ºæ–‡
1. [A survey on deep learning in medical image segmentation](https://arxiv.org/abs/2009.13120)
2. [Medical Image Segmentation: A Review](https://arxiv.org/abs/2102.09747)

### æ•°æ®é›†
1. ACDC (å¿ƒè„åˆ†å‰²)
2. Synapse (å¤šå™¨å®˜åˆ†å‰²)
3. BTCV (è…¹éƒ¨å™¨å®˜)
4. BraTS (è„‘è‚¿ç˜¤)

### è¯„ä»·æŒ‡æ ‡
- Dice Coefficient
- IoU (Intersection over Union)
- Hausdorff Distance
- Surface Dice

---

**ä¸‹ä¸€æ­¥**ï¼šå¼€å§‹åˆ›å»ºç¬¬ä¸€ç¯‡åšå®¢ - FCNä¸UNet

