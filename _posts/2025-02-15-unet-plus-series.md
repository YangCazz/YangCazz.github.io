---
layout: post
title: "UNet++ä¸UNet 3+ï¼šå¯†é›†è¿æ¥é‡æ–°å®šä¹‰Skip Connections"
date: 2025-02-15
categories: [åŒ»å­¦å½±åƒ, å›¾åƒåˆ†å‰²]
tags: [æ·±åº¦å­¦ä¹ , UNet++, UNet 3+, å¯†é›†è¿æ¥, æ·±åº¦ç›‘ç£]
excerpt: "æ·±å…¥æ¢è®¨UNet++çš„åµŒå¥—Skip Connectionså’ŒUNet 3+çš„å…¨å°ºåº¦ç‰¹å¾èåˆï¼Œç†è§£å¯†é›†è¿æ¥å¦‚ä½•å¼¥åˆç¼–ç å™¨å’Œè§£ç å™¨ä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿã€‚"
author: YangCazz
math: true
---

## ğŸ“‹ å¼•è¨€

åœ¨å‰é¢çš„æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†[UNet](/2025/02/01/fcn-unet-foundation/)çš„åŸºç¡€æ¶æ„ã€[V-Net](/2025/02/05/vnet-3d-segmentation/)çš„3Dæ‰©å±•ï¼Œä»¥åŠ[Attention UNet](/2025/02/10/attention-unet/)çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚è¿™äº›æ”¹è¿›ä¸»è¦å…³æ³¨**å¦‚ä½•é€‰æ‹©ç‰¹å¾**ï¼Œä½†å¿½ç•¥äº†ä¸€ä¸ªæ ¹æœ¬é—®é¢˜ï¼š

**ç¼–ç å™¨å’Œè§£ç å™¨ä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿ**ï¼ˆSemantic Gapï¼‰

```
é—®é¢˜ï¼š
ç¼–ç å™¨æ·±å±‚ï¼ˆlow-levelï¼‰ï¼šè¾¹ç¼˜ã€çº¹ç†
è§£ç å™¨æµ…å±‚ï¼ˆhigh-levelï¼‰ï¼šè¯­ä¹‰ã€ç±»åˆ«

ç›´æ¥skipè¿æ¥ï¼š
Low-level â”€â”€â”€â”€â†’ High-level
      â†‘            â†‘
   è¯­ä¹‰å·®è·å¤§ï¼Œèåˆæ•ˆæœå·®
```

**UNet++**ï¼ˆ2018ï¼‰å’Œ**UNet 3+**ï¼ˆ2020ï¼‰é€šè¿‡**å¯†é›†è¿æ¥**ï¼ˆDense Connectionsï¼‰è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œåˆ†åˆ«æå‡ºï¼š
- **UNet++**: åµŒå¥—çš„Skip Connectionsï¼ˆNested Skip Pathwaysï¼‰
- **UNet 3+**: å…¨å°ºåº¦Skip Connectionsï¼ˆFull-scale Skip Connectionsï¼‰

---

## ğŸ¯ Part 1: UNet++ (2018)

### è®ºæ–‡ä¿¡æ¯
- **æ ‡é¢˜**: UNet++: A Nested U-Net Architecture for Medical Image Segmentation
- **ä½œè€…**: Zongwei Zhou, et al. (Arizona State University)
- **å‘è¡¨**: DLMIA 2018 (Deep Learning in Medical Image Analysis)
- **è®ºæ–‡é“¾æ¥**: [arXiv:1807.10165](https://arxiv.org/abs/1807.10165)
- **å®˜æ–¹ä»£ç **: [GitHub](https://github.com/MrGiovanni/UNetPlusPlus)

### æ ¸å¿ƒæ€æƒ³ï¼šåµŒå¥—Skip Connections

**æ ‡å‡†UNetçš„é—®é¢˜**ï¼š

```
ç¼–ç å™¨ X^0,0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ è§£ç å™¨ X^0,4
       â†“                          â†‘
      Pool                    ç›´æ¥è¿æ¥
       â†“                          â†‘
       X^1,0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ X^1,3
       
è¯­ä¹‰é¸¿æ²Ÿï¼š
X^0,0: æµ…å±‚ç‰¹å¾ï¼ˆè¾¹ç¼˜ã€çº¹ç†ï¼‰
X^0,4: æ·±å±‚è¯­ä¹‰ï¼ˆç±»åˆ«ã€å¯¹è±¡ï¼‰
â†’ èåˆå›°éš¾
```

**UNet++çš„è§£å†³æ–¹æ¡ˆ**ï¼š

åœ¨ç¼–ç å™¨å’Œè§£ç å™¨ä¹‹é—´æ’å…¥**å¯†é›†å·ç§¯å—**ï¼Œé€æ­¥å¼¥åˆè¯­ä¹‰å·®è·ï¼š

```
X^0,0 â”€â†’ X^0,1 â”€â†’ X^0,2 â”€â†’ X^0,3 â”€â†’ X^0,4
 â†“        â†‘ â†“      â†‘ â†“      â†‘ â†“      â†‘
Pool     â”‚ Pool   â”‚ Pool   â”‚ Pool   Up
 â†“        â”‚  â†“      â”‚  â†“      â”‚  â†“      
X^1,0 â”€â”€â”€â”˜ X^1,1 â”€â”€â”˜ X^1,2 â”€â”€â”˜ X^1,3
 â†“           â†‘ â†“       â†‘ â†“       â†‘
Pool        â”‚ Pool    â”‚ Pool    Up
 â†“           â”‚  â†“       â”‚  â†“      
X^2,0 â”€â”€â”€â”€â”€â”€â”˜ X^2,1 â”€â”€â”€â”˜ X^2,2
 â†“              â†‘ â†“        â†‘
Pool           â”‚ Pool     Up
 â†“              â”‚  â†“       
X^3,0 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ X^3,1
 â†“                 â†‘
Pool              Up
 â†“                 
X^4,0 (Bottleneck)
```

**ç¬¦å·è¯´æ˜**ï¼š
- \( X^{i,j} \): ç¬¬\(i\)å±‚ï¼ˆä¸‹é‡‡æ ·çº§åˆ«ï¼‰ï¼Œç¬¬\(j\)åˆ—ï¼ˆä¸Šé‡‡æ ·æ­¥éª¤ï¼‰
- \( i \in [0, 4] \): 0ä¸ºæœ€æµ…å±‚ï¼Œ4ä¸ºæœ€æ·±å±‚
- \( j \in [0, 4] \): 0ä¸ºç¼–ç å™¨ï¼Œ4ä¸ºè§£ç å™¨æœ€ç»ˆè¾“å‡º

### æ•°å­¦å®šä¹‰

è®¾ \( X^{i,j} \) ä¸ºç¬¬\(i\)å±‚ã€ç¬¬\(j\)åˆ—çš„ç‰¹å¾ï¼Œè®¡ç®—å…¬å¼ä¸ºï¼š

$$
X^{i,j} = 
\begin{cases}
\mathcal{H}(X^{i-1,j}) & j = 0 \text{ (ç¼–ç å™¨è·¯å¾„)} \\
\mathcal{H}\left( \left[ \left[ X^{i,k} \right]_{k=0}^{j-1}, \mathcal{U}(X^{i+1,j-1}) \right] \right) & j > 0 \text{ (å¯†é›†skip)}
\end{cases}
$$

å…¶ä¸­ï¼š
- \( \mathcal{H}(\cdot) \): å·ç§¯æ“ä½œï¼ˆé€šå¸¸æ˜¯ä¸¤ä¸ª3Ã—3å·ç§¯ + ReLU + BNï¼‰
- \( \mathcal{U}(\cdot) \): ä¸Šé‡‡æ ·æ“ä½œï¼ˆè½¬ç½®å·ç§¯æˆ–åŒçº¿æ€§æ’å€¼ï¼‰
- \( [\cdot, \cdot] \): é€šé“ç»´åº¦æ‹¼æ¥
- \( \left[ X^{i,k} \right]_{k=0}^{j-1} \): åŒä¸€å±‚æ‰€æœ‰å‰é¢åˆ—çš„ç‰¹å¾

**å…³é”®ç‚¹**ï¼šæ¯ä¸ªèŠ‚ç‚¹ \( X^{i,j} \) æ¥æ”¶ï¼š
1. **åŒå±‚æ‰€æœ‰å‰é¢èŠ‚ç‚¹**ï¼š\( X^{i,0}, X^{i,1}, \ldots, X^{i,j-1} \)
2. **ä¸‹ä¸€å±‚ä¸Šé‡‡æ ·**ï¼š\( \mathcal{U}(X^{i+1,j-1}) \)

### PyTorchå®ç°

```python
class UNetPlusPlus(nn.Module):
    def __init__(self, in_channels=1, num_classes=2, deep_supervision=True):
        super(UNetPlusPlus, self).__init__()
        
        self.deep_supervision = deep_supervision
        
        # ç¼–ç å™¨ï¼ˆç¬¬0åˆ—ï¼‰
        self.conv0_0 = DoubleConv(in_channels, 64)
        self.conv1_0 = DoubleConv(64, 128)
        self.conv2_0 = DoubleConv(128, 256)
        self.conv3_0 = DoubleConv(256, 512)
        self.conv4_0 = DoubleConv(512, 1024)
        
        self.pool = nn.MaxPool2d(2)
        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
        
        # åµŒå¥—å·ç§¯å—
        # ç¬¬1åˆ—
        self.conv0_1 = DoubleConv(64 + 128, 64)
        self.conv1_1 = DoubleConv(128 + 256, 128)
        self.conv2_1 = DoubleConv(256 + 512, 256)
        self.conv3_1 = DoubleConv(512 + 1024, 512)
        
        # ç¬¬2åˆ—
        self.conv0_2 = DoubleConv(64 * 2 + 128, 64)
        self.conv1_2 = DoubleConv(128 * 2 + 256, 128)
        self.conv2_2 = DoubleConv(256 * 2 + 512, 256)
        
        # ç¬¬3åˆ—
        self.conv0_3 = DoubleConv(64 * 3 + 128, 64)
        self.conv1_3 = DoubleConv(128 * 3 + 256, 128)
        
        # ç¬¬4åˆ—
        self.conv0_4 = DoubleConv(64 * 4 + 128, 64)
        
        # è¾“å‡ºå±‚ï¼ˆDeep Supervisionï¼‰
        if deep_supervision:
            self.out1 = nn.Conv2d(64, num_classes, 1)
            self.out2 = nn.Conv2d(64, num_classes, 1)
            self.out3 = nn.Conv2d(64, num_classes, 1)
            self.out4 = nn.Conv2d(64, num_classes, 1)
        else:
            self.out = nn.Conv2d(64, num_classes, 1)
    
    def forward(self, x):
        # ç¼–ç å™¨ï¼ˆåˆ—0ï¼‰
        x0_0 = self.conv0_0(x)
        x1_0 = self.conv1_0(self.pool(x0_0))
        x2_0 = self.conv2_0(self.pool(x1_0))
        x3_0 = self.conv3_0(self.pool(x2_0))
        x4_0 = self.conv4_0(self.pool(x3_0))
        
        # åˆ—1
        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))
        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))
        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))
        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))
        
        # åˆ—2
        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))
        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))
        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))
        
        # åˆ—3
        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))
        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))
        
        # åˆ—4ï¼ˆæœ€ç»ˆè¾“å‡ºï¼‰
        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))
        
        # è¾“å‡º
        if self.deep_supervision:
            # æ·±åº¦ç›‘ç£ï¼šè¿”å›å¤šä¸ªåˆ†è¾¨ç‡çš„è¾“å‡º
            out1 = self.out1(x0_1)
            out2 = self.out2(x0_2)
            out3 = self.out3(x0_3)
            out4 = self.out4(x0_4)
            return [out1, out2, out3, out4]
        else:
            return self.out(x0_4)
```

### Deep Supervisionï¼ˆæ·±åº¦ç›‘ç£ï¼‰

UNet++çš„å¦ä¸€ä¸ªé‡è¦åˆ›æ–°ï¼šåœ¨æ¯ä¸€åˆ—éƒ½æ·»åŠ è¾“å‡ºå±‚ã€‚

**æ ‡å‡†UNet**ï¼š
```
Input â†’ Encoder â†’ Bottleneck â†’ Decoder â†’ Output (å•ä¸€ç›‘ç£)
```

**UNet++ with Deep Supervision**ï¼š
```
Input â†’ Nested Blocks â†’ Output1 (from column 1)
                      â†’ Output2 (from column 2)
                      â†’ Output3 (from column 3)
                      â†’ Output4 (from column 4, æœ€ç»ˆ)
```

**æŸå¤±å‡½æ•°**ï¼š

$$
\mathcal{L}_{\text{total}} = \sum_{i=1}^{4} \mathcal{L}(Y^{i}, \hat{Y}^{i})
$$

å…¶ä¸­ \( Y^{i} \) æ˜¯çœŸå®æ ‡ç­¾ï¼Œ\( \hat{Y}^{i} \) æ˜¯ç¬¬\(i\)åˆ—çš„è¾“å‡ºã€‚

**ä¼˜åŠ¿**ï¼š
1. **ç¼“è§£æ¢¯åº¦æ¶ˆå¤±**ï¼šä¸­é—´å±‚ç›´æ¥æ¥æ”¶ç›‘ç£ä¿¡å·
2. **å¤šå°ºåº¦ç›‘ç£**ï¼šä¸åŒåˆ—å­¦ä¹ ä¸åŒç²’åº¦çš„ç‰¹å¾
3. **æ¨¡å‹å‰ªæ**ï¼šæ¨ç†æ—¶å¯ä»¥åªä½¿ç”¨å‰é¢å‡ åˆ—ï¼ˆé€Ÿåº¦æ›´å¿«ï¼‰

**æ¨¡å‹å‰ªæ**ï¼š

```python
# è®­ç»ƒæ—¶ä½¿ç”¨æ·±åº¦ç›‘ç£
model.train()
outputs = model(images)  # [out1, out2, out3, out4]
loss = sum([criterion(out, targets) for out in outputs])

# æ¨ç†æ—¶å¯é€‰æ‹©ä¸åŒç²¾åº¦
model.eval()

# æ¨¡å¼L1ï¼šä»…ä½¿ç”¨åˆ—1ï¼ˆæœ€å¿«ï¼Œç²¾åº¦è¾ƒä½ï¼‰
out_L1 = model.forward_L1(image)

# æ¨¡å¼L2ï¼šä½¿ç”¨åˆ—1-2ï¼ˆå¹³è¡¡ï¼‰
out_L2 = model.forward_L2(image)

# æ¨¡å¼L4ï¼šä½¿ç”¨æ‰€æœ‰åˆ—ï¼ˆæœ€æ…¢ï¼Œç²¾åº¦æœ€é«˜ï¼‰
out_L4 = model.forward_L4(image)
```

---

## ğŸš€ Part 2: UNet 3+ (2020)

### è®ºæ–‡ä¿¡æ¯
- **æ ‡é¢˜**: UNet 3+: A Full-Scale Connected UNet for Medical Image Segmentation
- **ä½œè€…**: Huimin Huang, et al. (Zhejiang University)
- **å‘è¡¨**: ICASSP 2020
- **è®ºæ–‡é“¾æ¥**: [arXiv:2004.08790](https://arxiv.org/abs/2004.08790)
- **å®˜æ–¹ä»£ç **: [GitHub](https://github.com/ZJUGiveLab/UNet-Version)

### æ ¸å¿ƒæ€æƒ³ï¼šå…¨å°ºåº¦Skip Connections

**UNet++çš„å±€é™**ï¼š

è™½ç„¶UNet++é€šè¿‡åµŒå¥—å·ç§¯å—å¼¥åˆäº†è¯­ä¹‰é¸¿æ²Ÿï¼Œä½†ï¼š
- âŒ åªåœ¨ç›¸é‚»å±‚ä¹‹é—´è¿æ¥
- âŒ æ·±å±‚ç‰¹å¾éš¾ä»¥ç›´æ¥åˆ°è¾¾æµ…å±‚è§£ç å™¨
- âŒ å¤šå°ºåº¦ä¿¡æ¯èåˆä¸å……åˆ†

**UNet 3+çš„è§£å†³æ–¹æ¡ˆ**ï¼š

**Full-scale Skip Connections** - æ¯ä¸ªè§£ç å™¨å±‚æ¥æ”¶**æ‰€æœ‰å°ºåº¦**çš„ç‰¹å¾ï¼š

```
ç¼–ç å™¨                    è§£ç å™¨
E1 (HÃ—W)    â”€â”€â”€â”€â”
E2 (H/2Ã—W/2) â”€â”€â”€â”¼â”€â”€â”
E3 (H/4Ã—W/4) â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”
E4 (H/8Ã—W/8) â”€â”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â”
E5 (H/16Ã—W/16)â”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â”¼â”€â”€â†’ D4 (H/8Ã—W/8)
                â”‚  â”‚  â”‚  â”‚
                â†“  â†“  â†“  â†“
            [E1, E2, E3, E4, D5] â†’ èåˆ â†’ D4

æ¯ä¸ªè§£ç å™¨å±‚æ¥æ”¶ï¼š
- æ‰€æœ‰ç¼–ç å™¨å±‚çš„ç‰¹å¾ï¼ˆå¤šå°ºåº¦ï¼‰
- ä¸‹ä¸€å±‚è§£ç å™¨çš„ç‰¹å¾ï¼ˆä¸Šä¸‹æ–‡ï¼‰
```

**å…³é”®ç‰¹ç‚¹**ï¼š
- âœ… ä»»æ„ç¼–ç å™¨å±‚å¯ç›´æ¥è¿æ¥åˆ°ä»»æ„è§£ç å™¨å±‚
- âœ… å……åˆ†èåˆä½å±‚ç»†èŠ‚å’Œé«˜å±‚è¯­ä¹‰
- âœ… æ›´ä¸°å¯Œçš„å¤šå°ºåº¦ä¿¡æ¯

### æ•°å­¦å®šä¹‰

è®¾ç¬¬\(i\)å±‚è§£ç å™¨ç‰¹å¾ä¸º \( D^i \)ï¼Œå®ƒç”±ä»¥ä¸‹5éƒ¨åˆ†èåˆè€Œæˆï¼š

$$
D^i = \mathcal{H} \left( \bigoplus_{j=1}^{5} X^{i}_{\text{en}}(j) \right)
$$

å…¶ä¸­ \( \bigoplus \) è¡¨ç¤ºæ‹¼æ¥ï¼Œ\( X^{i}_{\text{en}}(j) \) æ˜¯æ¥è‡ªä¸åŒæºçš„ç‰¹å¾ï¼š

**1. æ¥è‡ªç¼–ç å™¨çš„ç‰¹å¾**ï¼ˆj = 1, 2, ..., i-1, i, i+1, ..., 5ï¼‰

- å¦‚æœç¼–ç å™¨ç‰¹å¾**åˆ†è¾¨ç‡æ›´é«˜**ï¼ˆ\(j < i\)ï¼‰ï¼šéœ€è¦**ä¸‹é‡‡æ ·**
  $$
  X^{i}_{\text{en}}(j) = \text{MaxPool}^{i-j}(E^j)
  $$

- å¦‚æœç¼–ç å™¨ç‰¹å¾**åˆ†è¾¨ç‡ç›¸åŒ**ï¼ˆ\(j = i\)ï¼‰ï¼šç›´æ¥ä½¿ç”¨
  $$
  X^{i}_{\text{en}}(i) = E^i
  $$

- å¦‚æœç¼–ç å™¨ç‰¹å¾**åˆ†è¾¨ç‡æ›´ä½**ï¼ˆ\(j > i\)ï¼‰ï¼šéœ€è¦**ä¸Šé‡‡æ ·**
  $$
  X^{i}_{\text{en}}(j) = \text{Upsample}^{j-i}(E^j)
  $$

**2. æ¥è‡ªä¸‹ä¸€å±‚è§£ç å™¨**ï¼ˆj = i+1ï¼‰

$$
X^{i}_{\text{de}} = \text{Upsample}(D^{i+1})
$$

**å®Œæ•´å…¬å¼**ï¼š

$$
D^i = \mathcal{H} \left( \left[ X^{i}_{\text{en}}(1), \ldots, X^{i}_{\text{en}}(5), X^{i}_{\text{de}} \right] \right)
$$

**ç¤ºä¾‹ï¼šD4çš„è®¡ç®—**ï¼ˆ\(H/8 \times W/8\)åˆ†è¾¨ç‡ï¼‰

$$
\begin{aligned}
D^4 = \mathcal{H} \bigg( & \text{MaxPool}^3(E^1), \quad & \text{(ä» HÃ—W ä¸‹é‡‡æ ·åˆ° H/8Ã—W/8)} \\
                         & \text{MaxPool}^2(E^2), \quad & \text{(ä» H/2Ã—W/2 ä¸‹é‡‡æ ·)} \\
                         & \text{MaxPool}(E^3), \quad & \text{(ä» H/4Ã—W/4 ä¸‹é‡‡æ ·)} \\
                         & E^4, \quad & \text{(ç›¸åŒåˆ†è¾¨ç‡ï¼Œç›´æ¥ä½¿ç”¨)} \\
                         & \text{Upsample}(E^5), \quad & \text{(ä» H/16Ã—W/16 ä¸Šé‡‡æ ·)} \\
                         & \text{Upsample}(D^5) \quad & \text{(è§£ç å™¨ç‰¹å¾ä¸Šé‡‡æ ·)} \bigg)
\end{aligned}
$$

### PyTorchå®ç°

```python
class UNet3Plus(nn.Module):
    def __init__(self, in_channels=1, num_classes=2, feature_channels=64):
        super(UNet3Plus, self).__init__()
        
        filters = [feature_channels, feature_channels * 2, 
                   feature_channels * 4, feature_channels * 8, 
                   feature_channels * 16]
        
        # ç¼–ç å™¨
        self.enc1 = DoubleConv(in_channels, filters[0])
        self.enc2 = DoubleConv(filters[0], filters[1])
        self.enc3 = DoubleConv(filters[1], filters[2])
        self.enc4 = DoubleConv(filters[2], filters[3])
        self.enc5 = DoubleConv(filters[3], filters[4])
        
        self.pool = nn.MaxPool2d(2)
        
        # CatChannelsï¼šæ¯ä¸ªè§£ç å™¨å±‚æ¥æ”¶5ä¸ªç¼–ç å™¨å±‚ + 1ä¸ªè§£ç å™¨å±‚
        CatChannels = filters[0]
        CatBlocks = 6  # 5ç¼–ç å™¨ + 1è§£ç å™¨
        UpChannels = CatChannels * CatBlocks
        
        ### è§£ç å™¨4 ###
        # æ¥è‡ªç¼–ç å™¨e1çš„ç‰¹å¾ï¼ˆéœ€è¦3æ¬¡ä¸‹é‡‡æ ·ï¼‰
        self.d4_e1 = nn.Sequential(
            nn.MaxPool2d(8),
            nn.Conv2d(filters[0], CatChannels, 3, padding=1),
            nn.BatchNorm2d(CatChannels),
            nn.ReLU(inplace=True)
        )
        # æ¥è‡ªe2ï¼ˆéœ€è¦2æ¬¡ä¸‹é‡‡æ ·ï¼‰
        self.d4_e2 = nn.Sequential(
            nn.MaxPool2d(4),
            nn.Conv2d(filters[1], CatChannels, 3, padding=1),
            nn.BatchNorm2d(CatChannels),
            nn.ReLU(inplace=True)
        )
        # æ¥è‡ªe3ï¼ˆéœ€è¦1æ¬¡ä¸‹é‡‡æ ·ï¼‰
        self.d4_e3 = nn.Sequential(
            nn.MaxPool2d(2),
            nn.Conv2d(filters[2], CatChannels, 3, padding=1),
            nn.BatchNorm2d(CatChannels),
            nn.ReLU(inplace=True)
        )
        # æ¥è‡ªe4ï¼ˆç›¸åŒåˆ†è¾¨ç‡ï¼‰
        self.d4_e4 = nn.Sequential(
            nn.Conv2d(filters[3], CatChannels, 3, padding=1),
            nn.BatchNorm2d(CatChannels),
            nn.ReLU(inplace=True)
        )
        # æ¥è‡ªe5ï¼ˆéœ€è¦ä¸Šé‡‡æ ·ï¼‰
        self.d4_e5 = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            nn.Conv2d(filters[4], CatChannels, 3, padding=1),
            nn.BatchNorm2d(CatChannels),
            nn.ReLU(inplace=True)
        )
        # èåˆ
        self.d4_conv = nn.Sequential(
            nn.Conv2d(UpChannels, UpChannels, 3, padding=1),
            nn.BatchNorm2d(UpChannels),
            nn.ReLU(inplace=True)
        )
        
        ### è§£ç å™¨3 ###ï¼ˆç±»ä¼¼d4ï¼Œçœç•¥è¯¦ç»†ä»£ç ï¼‰
        self.d3_e1 = nn.Sequential(nn.MaxPool2d(4), ...)
        self.d3_e2 = nn.Sequential(nn.MaxPool2d(2), ...)
        self.d3_e3 = nn.Sequential(...)
        self.d3_e4 = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear'), ...)
        self.d3_e5 = nn.Sequential(nn.Upsample(scale_factor=4, mode='bilinear'), ...)
        self.d3_d4 = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear'), ...)
        self.d3_conv = nn.Sequential(...)
        
        ### è§£ç å™¨2, 1 ###ï¼ˆç±»ä¼¼ï¼‰
        # ...
        
        # è¾“å‡ºå±‚
        self.output = nn.Conv2d(UpChannels, num_classes, 1)
    
    def forward(self, x):
        # ç¼–ç å™¨
        e1 = self.enc1(x)       # HÃ—WÃ—64
        e2 = self.enc2(self.pool(e1))  # H/2Ã—W/2Ã—128
        e3 = self.enc3(self.pool(e2))  # H/4Ã—W/4Ã—256
        e4 = self.enc4(self.pool(e3))  # H/8Ã—W/8Ã—512
        e5 = self.enc5(self.pool(e4))  # H/16Ã—W/16Ã—1024
        
        # è§£ç å™¨4 (H/8Ã—W/8)
        d4_inputs = [
            self.d4_e1(e1),  # ä»e1ä¸‹é‡‡æ ·
            self.d4_e2(e2),  # ä»e2ä¸‹é‡‡æ ·
            self.d4_e3(e3),  # ä»e3ä¸‹é‡‡æ ·
            self.d4_e4(e4),  # ä»e4ç›´æ¥
            self.d4_e5(e5),  # ä»e5ä¸Šé‡‡æ ·
        ]
        d4 = self.d4_conv(torch.cat(d4_inputs, 1))
        
        # è§£ç å™¨3, 2, 1ï¼ˆç±»ä¼¼ï¼‰
        # ...
        
        # è¾“å‡º
        out = self.output(d1)
        return out
```

### UNet 3+çš„ç‹¬ç‰¹ä¼˜åŠ¿

#### 1. Classification-Guided Moduleï¼ˆCGMï¼‰

UNet 3+æ·»åŠ äº†ä¸€ä¸ª**åˆ†ç±»åˆ†æ”¯**ï¼Œç”¨äºå›¾åƒçº§åˆ«çš„ç›‘ç£ï¼š

```python
class ClassificationGuidedModule(nn.Module):
    def __init__(self, in_channels):
        super().__init__()
        self.cls = nn.Sequential(
            nn.Dropout(0.5),
            nn.Conv2d(in_channels, 2, 1),  # 2ç±»ï¼šæœ‰/æ— ç›®æ ‡
            nn.AdaptiveAvgPool2d(1),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        cls_output = self.cls(x)  # (B, 2, 1, 1)
        return cls_output.view(-1, 2)

# è”åˆæŸå¤±
total_loss = seg_loss + 0.5 * cls_loss
```

**ä½œç”¨**ï¼š
- æä¾›å›¾åƒçº§ç›‘ç£ï¼ˆæ˜¯å¦åŒ…å«ç›®æ ‡ï¼‰
- å‡å°‘å‡é˜³æ€§ï¼ˆé¿å…åœ¨ç©ºç™½å›¾åƒä¸­åˆ†å‰²ï¼‰
- ä½œä¸ºè´¨é‡æ§åˆ¶æœºåˆ¶

#### 2. Hybrid Loss Function

$$
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{seg}} + \lambda_1 \mathcal{L}_{\text{ms-ssim}} + \lambda_2 \mathcal{L}_{\text{IoU}} + \lambda_3 \mathcal{L}_{\text{cls}}
$$

- \( \mathcal{L}_{\text{seg}} \): æ ‡å‡†åˆ†å‰²æŸå¤±ï¼ˆDice + CEï¼‰
- \( \mathcal{L}_{\text{ms-ssim}} \): å¤šå°ºåº¦ç»“æ„ç›¸ä¼¼æ€§æŸå¤±ï¼ˆä¿æŒè¾¹ç•Œï¼‰
- \( \mathcal{L}_{\text{IoU}} \): IoUæŸå¤±ï¼ˆç›´æ¥ä¼˜åŒ–è¯„ä»·æŒ‡æ ‡ï¼‰
- \( \mathcal{L}_{\text{cls}} \): åˆ†ç±»æŸå¤±ï¼ˆå›¾åƒçº§ç›‘ç£ï¼‰

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

### æ•°æ®é›†

| æ•°æ®é›† | ä»»åŠ¡ | æ¨¡æ€ | æŒ‘æˆ˜ |
|--------|------|------|------|
| **ISIC 2018** | çš®è‚¤ç—…å˜åˆ†å‰² | çš®è‚¤é•œå›¾åƒ | è¾¹ç•Œæ¨¡ç³Š |
| **LiTS** | è‚è„&è‚¿ç˜¤åˆ†å‰² | CT | å¤šç±»åˆ«ï¼Œå°ºåº¦å·®å¼‚å¤§ |
| **Kvasir-SEG** | æ¯è‚‰åˆ†å‰² | å†…çª¥é•œ | å½¢æ€å¤šæ · |

### å®éªŒç»“æœ

#### ISIC 2018ï¼ˆçš®è‚¤ç—…å˜åˆ†å‰²ï¼‰

| æ–¹æ³• | Dice | IoU | Sensitivity | Specificity |
|------|------|-----|-------------|-------------|
| UNet | 0.847 | 0.735 | 0.865 | 0.942 |
| Attention UNet | 0.858 | 0.752 | 0.875 | 0.948 |
| **UNet++** | **0.868** | **0.767** | **0.884** | **0.953** |
| **UNet 3+** | **0.873** | **0.778** | **0.890** | **0.957** |

**æå‡**ï¼š
- UNet++ vs. UNet: +2.1% Dice
- UNet 3+ vs. UNet: +2.6% Dice
- UNet 3+ vs. UNet++: +0.5% Dice

#### LiTSï¼ˆè‚è„è‚¿ç˜¤åˆ†å‰²ï¼‰

| æ–¹æ³• | Liver Dice | Tumor Dice | å¹³å‡ Dice |
|------|-----------|------------|----------|
| UNet | 0.952 | 0.673 | 0.813 |
| UNet++ | 0.960 | 0.712 | 0.836 |
| **UNet 3+** | **0.965** | **0.738** | **0.852** |

**è§‚å¯Ÿ**ï¼š
- å¯¹å°ç›®æ ‡ï¼ˆè‚¿ç˜¤ï¼‰æå‡æ›´æ˜æ˜¾ï¼ˆ+6.5%ï¼‰
- å¤§ç›®æ ‡ï¼ˆè‚è„ï¼‰ä¹Ÿæœ‰æå‡ï¼ˆ+1.3%ï¼‰

### æ¶ˆèå®éªŒ

#### UNet++æ¶ˆè

| é…ç½® | Dice | è¯´æ˜ |
|------|------|------|
| UNetï¼ˆåŸºçº¿ï¼‰ | 0.847 | - |
| + Nested Skip | 0.859 | åµŒå¥—è¿æ¥ (+1.2%) |
| + Deep Supervision | **0.868** | æ·±åº¦ç›‘ç£ (+0.9%) |

#### UNet 3+æ¶ˆè

| é…ç½® | Dice | è¯´æ˜ |
|------|------|------|
| UNet | 0.847 | - |
| + Full-scale Skip | 0.865 | å…¨å°ºåº¦è¿æ¥ (+1.8%) |
| + CGM | 0.870 | åˆ†ç±»å¼•å¯¼ (+0.5%) |
| + Hybrid Loss | **0.873** | æ··åˆæŸå¤± (+0.3%) |

---

## ğŸ’¡ UNet++ä¸UNet 3+å¯¹æ¯”

| ç»´åº¦ | UNet++ | UNet 3+ |
|------|--------|---------|
| **Skipç­–ç•¥** | åµŒå¥—ï¼Œç›¸é‚»å±‚è¿æ¥ | å…¨å°ºåº¦ï¼Œä»»æ„å±‚è¿æ¥ |
| **ç‰¹å¾èåˆ** | æ¸è¿›å¼å¼¥åˆé¸¿æ²Ÿ | ç›´æ¥èåˆå¤šå°ºåº¦ |
| **å‚æ•°é‡** | çº¦9.0Mï¼ˆÃ—2.9ï¼‰ | çº¦26.9Mï¼ˆÃ—8.7ï¼‰ |
| **è®¡ç®—é‡** | çº¦54.7 GFLOPsï¼ˆÃ—2.1ï¼‰ | çº¦157.2 GFLOPsï¼ˆÃ—6.1ï¼‰ |
| **è®­ç»ƒé€Ÿåº¦** | ä¸­ç­‰ | è¾ƒæ…¢ |
| **æ¨ç†é€Ÿåº¦** | å¯å‰ªæåŠ é€Ÿ | è¾ƒæ…¢ |
| **ç²¾åº¦ï¼ˆDiceï¼‰** | +2.1% vs. UNet | +2.6% vs. UNet |
| **é€‚ç”¨åœºæ™¯** | é€šç”¨åˆ†å‰² | ç²¾åº¦ä¼˜å…ˆä»»åŠ¡ |

**é€‰æ‹©å»ºè®®**ï¼š
- å®æ—¶åº”ç”¨ â†’ UNet++ï¼ˆæ”¯æŒå‰ªæï¼‰
- ç¦»çº¿é«˜ç²¾åº¦ â†’ UNet 3+
- èµ„æºå—é™ â†’ UNet++ L1/L2æ¨¡å¼
- å¤šç±»åˆ«å¤æ‚åœºæ™¯ â†’ UNet 3+

---

## ğŸ“ è®­ç»ƒæŠ€å·§

### 1. æ·±åº¦ç›‘ç£è®­ç»ƒç­–ç•¥

```python
def train_with_deep_supervision(model, data_loader):
    for images, masks in data_loader:
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        outputs = model(images)  # [out1, out2, out3, out4]
        
        # è®¡ç®—æ¯ä¸ªè¾“å‡ºçš„æŸå¤±
        losses = []
        for out in outputs:
            loss = dice_loss(out, masks) + ce_loss(out, masks)
            losses.append(loss)
        
        # æ€»æŸå¤±ï¼ˆå¯é€‰æ‹©ä¸åŒæƒé‡ï¼‰
        # æ–¹æ¡ˆ1ï¼šç­‰æƒé‡
        total_loss = sum(losses)
        
        # æ–¹æ¡ˆ2ï¼šé€’å¢æƒé‡ï¼ˆåé¢åˆ—æ›´é‡è¦ï¼‰
        weights = [0.1, 0.2, 0.3, 0.4]
        total_loss = sum([w * l for w, l in zip(weights, losses)])
        
        # åå‘ä¼ æ’­
        total_loss.backward()
        optimizer.step()
```

### 2. æ¸è¿›å¼è§£å†»è®­ç»ƒ

```python
# UNet 3+ç”±äºå‚æ•°é‡å¤§ï¼Œå®¹æ˜“è¿‡æ‹Ÿåˆ
# é‡‡ç”¨æ¸è¿›å¼è§£å†»ç­–ç•¥

# é˜¶æ®µ1ï¼šä»…è®­ç»ƒç¼–ç å™¨
for epoch in range(20):
    for name, param in model.named_parameters():
        if 'enc' in name:
            param.requires_grad = True
        else:
            param.requires_grad = False
    train_epoch()

# é˜¶æ®µ2ï¼šè§£å†»è§£ç å™¨
for epoch in range(20, 50):
    for name, param in model.named_parameters():
        if 'dec' in name or 'enc' in name:
            param.requires_grad = True
        else:
            param.requires_grad = False
    train_epoch()

# é˜¶æ®µ3ï¼šå…¨ç½‘ç»œfine-tune
for epoch in range(50, 100):
    for param in model.parameters():
        param.requires_grad = True
    train_epoch()
```

### 3. æ··åˆæŸå¤±æƒé‡è°ƒä¼˜

```python
# UNet 3+çš„æ··åˆæŸå¤±éœ€è¦ä»”ç»†è°ƒä¼˜
class HybridLoss(nn.Module):
    def __init__(self, w_seg=1.0, w_ssim=0.5, w_iou=0.5, w_cls=0.5):
        super().__init__()
        self.w_seg = w_seg
        self.w_ssim = w_ssim
        self.w_iou = w_iou
        self.w_cls = w_cls
        
        self.dice = DiceLoss()
        self.ce = nn.CrossEntropyLoss()
        self.ssim = MS_SSIM_Loss()
        self.iou = IoULoss()
        self.bce = nn.BCEWithLogitsLoss()
    
    def forward(self, seg_pred, cls_pred, seg_target, cls_target):
        # åˆ†å‰²æŸå¤±
        l_dice = self.dice(seg_pred, seg_target)
        l_ce = self.ce(seg_pred, seg_target)
        l_seg = l_dice + l_ce
        
        # MS-SSIMæŸå¤±ï¼ˆä¿æŒç»“æ„ï¼‰
        l_ssim = self.ssim(seg_pred, seg_target)
        
        # IoUæŸå¤±
        l_iou = self.iou(seg_pred, seg_target)
        
        # åˆ†ç±»æŸå¤±
        l_cls = self.bce(cls_pred, cls_target)
        
        # æ€»æŸå¤±
        total = (self.w_seg * l_seg + 
                 self.w_ssim * l_ssim + 
                 self.w_iou * l_iou + 
                 self.w_cls * l_cls)
        
        return total
```

---

## ğŸ“– æ€»ç»“

### å¯†é›†è¿æ¥çš„æ¼”è¿›

```
UNet (2015):
ç¼–ç å™¨ â”€â”€â”€â”€â†’ è§£ç å™¨ï¼ˆå•ä¸€skipï¼‰

UNet++ (2018):
ç¼–ç å™¨ â”€â”€â†’ ä¸­é—´å±‚ â”€â”€â†’ è§£ç å™¨ï¼ˆåµŒå¥—skipï¼‰

UNet 3+ (2020):
ç¼–ç å™¨ï¼ˆæ‰€æœ‰å±‚ï¼‰ â”€â”€â†’ è§£ç å™¨ï¼ˆå…¨å°ºåº¦skipï¼‰
```

### æ ¸å¿ƒè´¡çŒ®

**UNet++**ï¼š
1. âœ… åµŒå¥—Skip Connectionså¼¥åˆè¯­ä¹‰é¸¿æ²Ÿ
2. âœ… Deep Supervisionæä¾›å¤šå°ºåº¦ç›‘ç£
3. âœ… æ¨¡å‹å‰ªææ”¯æŒé€Ÿåº¦-ç²¾åº¦å¹³è¡¡

**UNet 3+**ï¼š
1. âœ… Full-scale Skip Connectionså……åˆ†èåˆå¤šå°ºåº¦
2. âœ… Classification-Guided Moduleå‡å°‘å‡é˜³æ€§
3. âœ… Hybrid Loss Functionå¤šè§’åº¦ä¼˜åŒ–

### é€‚ç”¨åœºæ™¯å»ºè®®

| åœºæ™¯ | æ¨èæ–¹æ³• | ç†ç”± |
|------|---------|------|
| **è¾¹ç•Œç²¾ç»†** | UNet 3+ | å…¨å°ºåº¦ç‰¹å¾ä¿ç•™ç»†èŠ‚ |
| **å°ç›®æ ‡** | UNet 3+ | å¤šå°ºåº¦èåˆå¢å¼ºæ„ŸçŸ¥ |
| **å®æ—¶åº”ç”¨** | UNet++ (L1/L2) | æ”¯æŒå‰ªæ |
| **èµ„æºå—é™** | UNet++ | å‚æ•°é‡é€‚ä¸­ |
| **å¤šç±»åˆ«** | UNet 3+ | CGMè¾…åŠ©åˆ†ç±» |
| **é€šç”¨åˆ†å‰²** | UNet++ | æ€§ä»·æ¯”é«˜ |

**ä¸‹ä¸€ç¯‡é¢„å‘Š**ï¼š[TransUNetï¼šCNNä¸Transformerçš„èåˆ](/2025/02/20/transunet-hybrid-architecture/) - æ¢ç´¢Transformerå¦‚ä½•ä¸ºåŒ»å­¦å›¾åƒåˆ†å‰²å¸¦æ¥å…¨å±€å»ºæ¨¡èƒ½åŠ›ã€‚

---

## ğŸ“š å‚è€ƒèµ„æ–™

### è®ºæ–‡
1. [UNet++] Zhou, Z., et al. (2018). UNet++: A Nested U-Net Architecture for Medical Image Segmentation. *DLMIA*.
2. [UNet 3+] Huang, H., et al. (2020). UNet 3+: A Full-Scale Connected UNet for Medical Image Segmentation. *ICASSP*.
3. [DenseNet] Huang, G., et al. (2017). Densely Connected Convolutional Networks. *CVPR*.

### ä»£ç å®ç°
- [UNet++å®˜æ–¹](https://github.com/MrGiovanni/UNetPlusPlus) - åŸå§‹Keraså®ç°
- [UNet 3+å®˜æ–¹](https://github.com/ZJUGiveLab/UNet-Version) - åŸå§‹PyTorchå®ç°
- [Segmentation Models PyTorch](https://github.com/qubvel/segmentation_models.pytorch) - åŒ…å«ä¸¤è€…çš„åº“

### æ•°æ®é›†
- [ISIC 2018](https://challenge.isic-archive.com/landing/2018/) - çš®è‚¤ç—…å˜
- [LiTS](https://competitions.codalab.org/competitions/17094) - è‚è„è‚¿ç˜¤
- [Kvasir-SEG](https://datasets.simula.no/kvasir-seg/) - æ¯è‚‰åˆ†å‰²

---

## ğŸ”— ç³»åˆ—æ–‡ç« å¯¼èˆª

1. [FCNä¸UNetï¼šåŒ»å­¦åˆ†å‰²çš„å¥ åŸºä¹‹ä½œ](/2025/02/01/fcn-unet-foundation/)
2. [V-Netï¼š3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„çªç ´](/2025/02/05/vnet-3d-segmentation/)
3. [Attention UNetï¼šæ³¨æ„åŠ›æœºåˆ¶çš„å¼•å…¥](/2025/02/10/attention-unet/)
4. ğŸ“ **UNet++/UNet 3+ï¼šå¯†é›†è¿æ¥çš„åŠ›é‡**ï¼ˆæœ¬æ–‡ï¼‰
5. [TransUNetï¼šCNNä¸Transformerçš„èåˆ](/2025/02/20/transunet-hybrid-architecture/)
6. [Swin-UNetï¼šå±‚çº§åŒ–Transformer](/2025/02/25/swin-unet-hierarchical-transformer/)
7. [SAMä¸MedSAMï¼šåŸºç¡€æ¨¡å‹çš„åŒ»å­¦åº”ç”¨](/2025/03/05/sam-segment-anything/)
8. [nnU-Netï¼šè‡ªé€‚åº”åŒ»å­¦åˆ†å‰²æ¡†æ¶](/2025/03/15/nnunet-self-configuring-framework/)

---

*æœ¬æ–‡æ·±å…¥æ¢è®¨äº†UNet++å’ŒUNet 3+å¦‚ä½•é€šè¿‡å¯†é›†è¿æ¥ç­–ç•¥é‡æ–°å®šä¹‰Skip Connectionsï¼Œåˆ†åˆ«é€šè¿‡åµŒå¥—è·¯å¾„å’Œå…¨å°ºåº¦èåˆå¼¥åˆç¼–ç å™¨-è§£ç å™¨ä¹‹é—´çš„è¯­ä¹‰é¸¿æ²Ÿã€‚ä¸‹ä¸€ç¯‡å°†ä»‹ç»Transformerå¦‚ä½•é©æ–°åŒ»å­¦å›¾åƒåˆ†å‰²ã€‚*

