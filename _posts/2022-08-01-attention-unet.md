---
layout: post
title: "Attention UNetï¼šæ³¨æ„åŠ›æœºåˆ¶å¼•é¢†åŒ»å­¦åˆ†å‰²æ–°çºªå…ƒ"
date: 2022-08-01 10:00:00 +0800
categories: [åŒ»å­¦å½±åƒ, å›¾åƒåˆ†å‰²]
tags: [UNet, Attention, åŒ»å­¦å›¾åƒ]
excerpt: "æ·±å…¥è§£æAttention UNetå¦‚ä½•é€šè¿‡æ³¨æ„åŠ›é—¨æ§æœºåˆ¶è®©ç½‘ç»œè‡ªåŠ¨å­¦ä¹ å…³æ³¨é‡è¦åŒºåŸŸï¼Œåœ¨èƒ°è…ºç­‰å°å™¨å®˜åˆ†å‰²ä»»åŠ¡ä¸Šå–å¾—çªç ´æ€§è¿›å±•ã€‚"
author: YangCazz
math: true
---

## ğŸ“‹ å¼•è¨€

åœ¨å‰é¢çš„æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†[UNet](/2025/02/01/fcn-unet-foundation/)çš„å¯¹ç§°Uå‹ç»“æ„å’Œ[V-Net](/2025/02/05/vnet-3d-segmentation/)çš„3Dæ‰©å±•ã€‚è¿™äº›ç½‘ç»œè™½ç„¶å¼ºå¤§ï¼Œä½†å­˜åœ¨ä¸€ä¸ªé—®é¢˜ï¼š**Skip Connectionsç›²ç›®åœ°ä¼ é€’æ‰€æœ‰ç‰¹å¾**ï¼Œæ— æ³•åŒºåˆ†å“ªäº›ç‰¹å¾æ˜¯é‡è¦çš„ï¼Œå“ªäº›æ˜¯å™ªå£°ã€‚

**Attention UNet**ï¼ˆ2018ï¼‰å¼•å…¥äº†**æ³¨æ„åŠ›é—¨æ§ï¼ˆAttention Gatesï¼‰**æœºåˆ¶ï¼Œè®©ç½‘ç»œå­¦ä¼š"çœ‹å“ªé‡Œ"â€”â€”è‡ªåŠ¨èšç„¦äºä¸ä»»åŠ¡ç›¸å…³çš„åŒºåŸŸï¼ŒæŠ‘åˆ¶æ— å…³èƒŒæ™¯ã€‚

### ä¸ºä»€ä¹ˆéœ€è¦æ³¨æ„åŠ›æœºåˆ¶ï¼Ÿ

**ä¼ ç»ŸUNetçš„é—®é¢˜**ï¼š
```
ç¼–ç å™¨ â”€â”€â†’ [æ‰€æœ‰ç‰¹å¾] â”€â”€â†’ è§£ç å™¨
         â†‘
    åŒ…å«å¤§é‡èƒŒæ™¯å™ªå£°
```

**ç¤ºä¾‹ï¼šèƒ°è…ºåˆ†å‰²**
```
CTå›¾åƒï¼š512Ã—512
èƒ°è…ºåŒºåŸŸï¼šçº¦50Ã—30ï¼ˆä»…å 3%ï¼‰
èƒŒæ™¯ï¼š97%

ä¼ ç»ŸUNetï¼š
âœ“ ç¼–ç å™¨æå–ç‰¹å¾
âœ— Skipä¼ é€’æ‰€æœ‰ç‰¹å¾ï¼ˆåŒ…æ‹¬97%çš„æ— å…³èƒŒæ™¯ï¼‰
âœ— è§£ç å™¨è¢«å¤§é‡èƒŒæ™¯ä¿¡æ¯å¹²æ‰°
```

**Attention UNetçš„æ”¹è¿›**ï¼š
```
ç¼–ç å™¨ â”€â”€â†’ [æ‰€æœ‰ç‰¹å¾] â”€â”€â†’ Attention Gate â”€â”€â†’ [åŠ æƒç‰¹å¾] â”€â”€â†’ è§£ç å™¨
                              â†‘
                         è‡ªåŠ¨å­¦ä¹ é‡è¦æ€§
                         âœ“ çªå‡ºå‰æ™¯ï¼ˆèƒ°è…ºï¼‰
                         âœ— æŠ‘åˆ¶èƒŒæ™¯
```

---

## ğŸ¯ Attention UNetï¼šæ ¸å¿ƒåˆ›æ–°

### è®ºæ–‡ä¿¡æ¯
- **æ ‡é¢˜**: Attention U-Net: Learning Where to Look for the Pancreas
- **ä½œè€…**: Ozan Oktay, Jo Schlemper, et al. (Imperial College London)
- **å‘è¡¨**: MIDL 2018 (Medical Imaging with Deep Learning)
- **è®ºæ–‡é“¾æ¥**: [arXiv:1804.03999](https://arxiv.org/abs/1804.03999)
- **å®˜æ–¹ä»£ç **: [GitHub](https://github.com/ozan-octopus/attention-unet)

### æ ¸å¿ƒæ€æƒ³ï¼šæ³¨æ„åŠ›é—¨æ§ï¼ˆAttention Gatesï¼‰

**Attention Gate**æ˜¯æ’å…¥åœ¨Skip Connectionä¸­çš„æ¨¡å—ï¼Œä½œç”¨æ˜¯ï¼š
1. æ¥æ”¶**ä¸¤ä¸ªè¾“å…¥**ï¼šç¼–ç å™¨ç‰¹å¾ï¼ˆ\(x^l\)ï¼‰å’Œè§£ç å™¨ç‰¹å¾ï¼ˆ\(g\)ï¼‰
2. è®¡ç®—**æ³¨æ„åŠ›ç³»æ•°**ï¼ˆ\(\alpha\)ï¼‰ï¼šåˆ¤æ–­ç¼–ç å™¨ç‰¹å¾çš„æ¯ä¸ªä½ç½®æ˜¯å¦é‡è¦
3. è¾“å‡º**åŠ æƒç‰¹å¾**ï¼š\(\hat{x}^l = \alpha \odot x^l\)ï¼ˆ\(\odot\)è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ï¼‰

**å…³é”®ä¼˜åŠ¿**ï¼š
- âœ… **è‡ªåŠ¨å­¦ä¹ **ï¼šæ— éœ€æ‰‹å·¥æ ‡æ³¨æ„Ÿå…´è¶£åŒºåŸŸ
- âœ… **ç«¯åˆ°ç«¯è®­ç»ƒ**ï¼šæ³¨æ„åŠ›æƒé‡é€šè¿‡åå‘ä¼ æ’­å­¦ä¹ 
- âœ… **å¯è§£é‡Šæ€§**ï¼šå¯è§†åŒ–æ³¨æ„åŠ›å›¾ï¼Œäº†è§£ç½‘ç»œå…³æ³¨å“ªé‡Œ
- âœ… **æ— é¢å¤–ç›‘ç£**ï¼šä»…ç”¨åˆ†å‰²æ ‡ç­¾ï¼Œä¸éœ€è¦é¢å¤–æ³¨é‡Š

---

## ğŸ—ï¸ Attention Gateè¯¦è§£

### 1. æ•´ä½“æ¶æ„

Attention UNetåŸºäºæ ‡å‡†UNetï¼Œåœ¨æ¯ä¸ªSkip Connectionå¤„æ·»åŠ Attention Gateï¼š

```
ç¼–ç å™¨è·¯å¾„                    è§£ç å™¨è·¯å¾„
                              
Input                          Output
  â†“                              â†‘
Conv â”€â”€â”€â”€â”€â”€[AG]â”€â”€â”€â”€â”€â†’ UpConv + Concat
  â†“          â†‘                  â†‘
Pool         â”‚                  â”‚
  â†“          â”‚                  â”‚
Conv â”€â”€â”€â”€â”€â”€[AG]â”€â”€â”€â”€â”€â†’ UpConv + Concat
  â†“          â†‘                  â†‘
Pool         â”‚                  â”‚
  â†“          â”‚                  â”‚
Conv â”€â”€â”€â”€â”€â”€[AG]â”€â”€â”€â”€â”€â†’ UpConv + Concat
  â†“          â†‘                  â†‘
Pool         â”‚                  â”‚
  â†“          â”‚                  â”‚
Bottleneck â”€â”€â”˜                  â”‚
  â”‚                             â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[AG] = Attention Gateï¼ˆé—¨æ§å•å…ƒï¼‰
```

**å…³é”®ç‚¹**ï¼š
- Attention Gateä½¿ç”¨**è§£ç å™¨ç‰¹å¾ä½œä¸ºquery**ï¼ˆ"æˆ‘ç°åœ¨éœ€è¦ä»€ä¹ˆä¿¡æ¯ï¼Ÿ"ï¼‰
- Attention Gateä½¿ç”¨**ç¼–ç å™¨ç‰¹å¾ä½œä¸ºkey/value**ï¼ˆ"æˆ‘æœ‰å“ªäº›ä¿¡æ¯ï¼Ÿ"ï¼‰
- è¾“å‡ºåŠ æƒçš„ç¼–ç å™¨ç‰¹å¾ï¼Œä¼ é€’ç»™è§£ç å™¨

### 2. Attention Gateçš„æ•°å­¦å®šä¹‰

è®¾ç¼–ç å™¨ç‰¹å¾ä¸º \(x^l \in \mathbb{R}^{H \times W \times C}\)ï¼Œè§£ç å™¨ç‰¹å¾ä¸º \(g \in \mathbb{R}^{H' \times W' \times C'}\)ã€‚

**æ­¥éª¤1ï¼šç‰¹å¾å˜æ¢**

å°†ä¸¤ä¸ªè¾“å…¥æ˜ å°„åˆ°ç›¸åŒçš„é€šé“ç©ºé—´ï¼š

$$
\begin{aligned}
W_x * x^l &\in \mathbb{R}^{H \times W \times F_{\text{int}}} \\
W_g * g &\in \mathbb{R}^{H \times W \times F_{\text{int}}}
\end{aligned}
$$

å…¶ä¸­ \(F_{\text{int}}\) æ˜¯ä¸­é—´ç‰¹å¾ç»´åº¦ï¼ˆé€šå¸¸ä¸º \(C/2\)ï¼‰ã€‚

**æ­¥éª¤2ï¼šç›¸åŠ å¹¶æ¿€æ´»**

$$
q_{\text{att}} = \text{ReLU}(W_x * x^l + W_g * g + b)
$$

è¿™é‡Œ \(g\) é€šè¿‡ä¸Šé‡‡æ ·æˆ–1Ã—1å·ç§¯è°ƒæ•´åˆ°ä¸ \(x^l\) ç›¸åŒçš„ç©ºé—´å°ºå¯¸ã€‚

**æ­¥éª¤3ï¼šè®¡ç®—æ³¨æ„åŠ›ç³»æ•°**

$$
\alpha^l = \sigma(\psi^T * q_{\text{att}} + b_{\psi})
$$

å…¶ä¸­ï¼š
- \(\psi\) æ˜¯1Ã—1å·ç§¯ï¼ˆé™ç»´åˆ°1é€šé“ï¼‰
- \(\sigma\) æ˜¯Sigmoidå‡½æ•°ï¼Œè¾“å‡ºèŒƒå›´[0, 1]
- \(\alpha^l \in \mathbb{R}^{H \times W \times 1}\)

**æ­¥éª¤4ï¼šç‰¹å¾åŠ æƒ**

$$
\hat{x}^l = \alpha^l \odot x^l
$$

é€å…ƒç´ ç›¸ä¹˜ï¼Œé‡è¦åŒºåŸŸ \(\alpha \approx 1\)ï¼Œä¸é‡è¦åŒºåŸŸ \(\alpha \approx 0\)ã€‚

### 3. å®Œæ•´å…¬å¼

å°†ä¸Šè¿°æ­¥éª¤æ•´åˆï¼š

$$
\alpha^l(i, j) = \sigma_1 \left( \psi^T \left( \sigma_2(W_x x^l_{i,j} + W_g g_i + b) \right) + b_{\psi} \right)
$$

å…¶ä¸­ï¼š
- \((i, j)\) æ˜¯ç©ºé—´ä½ç½®
- \(\sigma_1\) æ˜¯Sigmoidï¼ˆè¾“å‡ºæ³¨æ„åŠ›ç³»æ•°ï¼‰
- \(\sigma_2\) æ˜¯ReLUï¼ˆéçº¿æ€§æ¿€æ´»ï¼‰

**è¾“å‡º**ï¼š

$$
\hat{x}^l = x^l \odot \alpha^l
$$

### 4. PyTorchå®ç°

```python
class AttentionGate(nn.Module):
    def __init__(self, F_g, F_l, F_int):
        """
        Attention Gate
        Args:
            F_g: è§£ç å™¨ç‰¹å¾é€šé“æ•° (gating signal)
            F_l: ç¼–ç å™¨ç‰¹å¾é€šé“æ•° (input feature)
            F_int: ä¸­é—´å±‚é€šé“æ•°
        """
        super(AttentionGate, self).__init__()
        
        # ç‰¹å¾å˜æ¢
        self.W_g = nn.Sequential(
            nn.Conv2d(F_g, F_int, kernel_size=1, padding=0, bias=True),
            nn.BatchNorm2d(F_int)
        )
        
        self.W_x = nn.Sequential(
            nn.Conv2d(F_l, F_int, kernel_size=1, padding=0, bias=True),
            nn.BatchNorm2d(F_int)
        )
        
        # æ³¨æ„åŠ›ç³»æ•°è®¡ç®—
        self.psi = nn.Sequential(
            nn.Conv2d(F_int, 1, kernel_size=1, padding=0, bias=True),
            nn.BatchNorm2d(1),
            nn.Sigmoid()
        )
        
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, g, x):
        """
        Args:
            g: è§£ç å™¨ç‰¹å¾ (gating signal) - (B, F_g, H', W')
            x: ç¼–ç å™¨ç‰¹å¾ (input feature) - (B, F_l, H, W)
        Returns:
            attention-weighted features - (B, F_l, H, W)
        """
        # 1. å¯¹é½ç©ºé—´å°ºå¯¸ï¼ˆå¦‚æœgæ¯”xå°ï¼Œéœ€è¦ä¸Šé‡‡æ ·ï¼‰
        g1 = self.W_g(g)  # (B, F_int, H', W')
        
        # åŒçº¿æ€§æ’å€¼ï¼Œå°†gä¸Šé‡‡æ ·åˆ°ä¸xç›¸åŒçš„å°ºå¯¸
        g1 = F.interpolate(g1, size=x.size()[2:], 
                          mode='bilinear', align_corners=True)
        
        # 2. ç¼–ç å™¨ç‰¹å¾å˜æ¢
        x1 = self.W_x(x)  # (B, F_int, H, W)
        
        # 3. ç›¸åŠ å¹¶æ¿€æ´»
        psi = self.relu(g1 + x1)  # (B, F_int, H, W)
        
        # 4. è®¡ç®—æ³¨æ„åŠ›ç³»æ•°
        psi = self.psi(psi)  # (B, 1, H, W)
        
        # 5. ç‰¹å¾åŠ æƒ
        out = x * psi  # (B, F_l, H, W)
        
        return out


# å®Œæ•´Attention UNet
class AttentionUNet(nn.Module):
    def __init__(self, in_channels=1, num_classes=2):
        super(AttentionUNet, self).__init__()
        
        # Encoder
        self.enc1 = DoubleConv(in_channels, 64)
        self.enc2 = DoubleConv(64, 128)
        self.enc3 = DoubleConv(128, 256)
        self.enc4 = DoubleConv(256, 512)
        
        self.pool = nn.MaxPool2d(2)
        
        # Bottleneck
        self.bottleneck = DoubleConv(512, 1024)
        
        # Attention Gates
        self.att4 = AttentionGate(F_g=1024, F_l=512, F_int=256)
        self.att3 = AttentionGate(F_g=512, F_l=256, F_int=128)
        self.att2 = AttentionGate(F_g=256, F_l=128, F_int=64)
        self.att1 = AttentionGate(F_g=128, F_l=64, F_int=32)
        
        # Decoder
        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)
        self.dec4 = DoubleConv(1024, 512)
        
        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.dec3 = DoubleConv(512, 256)
        
        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec2 = DoubleConv(256, 128)
        
        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec1 = DoubleConv(128, 64)
        
        # Output
        self.out = nn.Conv2d(64, num_classes, kernel_size=1)
    
    def forward(self, x):
        # Encoder
        e1 = self.enc1(x)       # 64
        e2 = self.enc2(self.pool(e1))  # 128
        e3 = self.enc3(self.pool(e2))  # 256
        e4 = self.enc4(self.pool(e3))  # 512
        
        # Bottleneck
        b = self.bottleneck(self.pool(e4))  # 1024
        
        # Decoder with Attention
        d4 = self.up4(b)  # 512
        e4_att = self.att4(g=d4, x=e4)  # æ³¨æ„åŠ›åŠ æƒ
        d4 = torch.cat([e4_att, d4], dim=1)  # 1024
        d4 = self.dec4(d4)  # 512
        
        d3 = self.up3(d4)  # 256
        e3_att = self.att3(g=d3, x=e3)
        d3 = torch.cat([e3_att, d3], dim=1)  # 512
        d3 = self.dec3(d3)  # 256
        
        d2 = self.up2(d3)  # 128
        e2_att = self.att2(g=d2, x=e2)
        d2 = torch.cat([e2_att, d2], dim=1)  # 256
        d2 = self.dec2(d2)  # 128
        
        d1 = self.up1(d2)  # 64
        e1_att = self.att1(g=d1, x=e1)
        d1 = torch.cat([e1_att, d1], dim=1)  # 128
        d1 = self.dec1(d1)  # 64
        
        # Output
        out = self.out(d1)
        return out
```

### 5. æ³¨æ„åŠ›æœºåˆ¶çš„ç›´è§‚ç†è§£

**å¯è§†åŒ–æ³¨æ„åŠ›æƒé‡**ï¼š

```python
def visualize_attention(model, image):
    """å¯è§†åŒ–å„å±‚æ³¨æ„åŠ›å›¾"""
    model.eval()
    
    # å‰å‘ä¼ æ’­ï¼Œæå–æ³¨æ„åŠ›æƒé‡
    with torch.no_grad():
        # ... (çœç•¥ç»†èŠ‚)
        att_maps = model.get_attention_maps(image)
    
    # ç»˜åˆ¶
    fig, axes = plt.subplots(1, 5, figsize=(20, 4))
    axes[0].imshow(image[0, 0].cpu(), cmap='gray')
    axes[0].set_title('Input Image')
    
    for i, att_map in enumerate(att_maps):
        axes[i+1].imshow(att_map[0, 0].cpu(), cmap='jet', vmin=0, vmax=1)
        axes[i+1].set_title(f'Attention Layer {i+1}')
    
    plt.show()
```

**å…¸å‹çš„æ³¨æ„åŠ›å›¾**ï¼š
```
æµ…å±‚ï¼ˆLayer 1-2ï¼‰ï¼š
- å…³æ³¨å™¨å®˜è¾¹ç•Œå’Œçº¹ç†ç»†èŠ‚
- æ³¨æ„åŠ›è¾ƒåˆ†æ•£

ä¸­å±‚ï¼ˆLayer 3ï¼‰ï¼š
- å¼€å§‹èšç„¦äºç›®æ ‡å™¨å®˜
- èƒŒæ™¯è¢«éƒ¨åˆ†æŠ‘åˆ¶

æ·±å±‚ï¼ˆLayer 4ï¼‰ï¼š
- é«˜åº¦èšç„¦äºç›®æ ‡åŒºåŸŸï¼ˆå¦‚èƒ°è…ºï¼‰
- èƒŒæ™¯å‡ ä¹å®Œå…¨è¢«æŠ‘åˆ¶ï¼ˆÎ± â‰ˆ 0ï¼‰
```

---

## ğŸ“Š å®éªŒç»“æœ

### æ•°æ®é›†

**1. Pancreas-CT**
- **ä»»åŠ¡**: CTå›¾åƒä¸­çš„èƒ°è…ºåˆ†å‰²
- **æŒ‘æˆ˜**: 
  - èƒ°è…ºä½“ç§¯å°ï¼ˆçº¦å å›¾åƒçš„3%ï¼‰
  - å½¢çŠ¶å¤šå˜
  - ä¸å‘¨å›´ç»„ç»‡å¯¹æ¯”åº¦ä½
- **æ•°æ®**: 82ä¾‹æ‚£è€…ï¼Œ12,000+åˆ‡ç‰‡

**2. Liver Tumor**
- **ä»»åŠ¡**: è‚è„å’Œè‚è‚¿ç˜¤åˆ†å‰²
- **æ•°æ®**: 131ä¾‹æ‚£è€…

### æ€§èƒ½å¯¹æ¯”

#### Pancreas-CTæ•°æ®é›†

| æ–¹æ³• | Diceç³»æ•° | Sensitivity | Specificity |
|------|---------|-------------|-------------|
| FCN | 0.68 | 0.65 | 0.98 |
| UNet | 0.82 | 0.80 | 0.99 |
| ResUNet | 0.84 | 0.82 | 0.99 |
| **Attention UNet** | **0.86** | **0.85** | **0.99** |

**æå‡**ï¼š
- Dice: +4% vs. ResUNet, +18% vs. FCN
- Sensitivity: +3% vs. ResUNetï¼ˆå‡å°‘æ¼æ£€ï¼‰

#### æ¶ˆèå®éªŒ

| é…ç½® | Dice | è¯´æ˜ |
|------|------|------|
| UNetï¼ˆåŸºçº¿ï¼‰ | 0.82 | - |
| + Attention (ä»…æ·±å±‚) | 0.84 | ä»…åœ¨Layer 4æ·»åŠ AG |
| + Attention (æ‰€æœ‰å±‚) | **0.86** | åœ¨æ‰€æœ‰å±‚æ·»åŠ AG |
| + Deep Supervision | 0.87 | é¢å¤–æ·»åŠ æ·±åº¦ç›‘ç£ |

**ç»“è®º**ï¼š
- å¤šå±‚æ³¨æ„åŠ›æ¯”å•å±‚æ•ˆæœæ›´å¥½ï¼ˆ+2%ï¼‰
- æ·±åº¦ç›‘ç£è¿›ä¸€æ­¥æå‡ï¼ˆ+1%ï¼‰

### å¯è§†åŒ–åˆ†æ

**æ³¨æ„åŠ›å›¾çš„æ¼”è¿›**ï¼š
```
è¾“å…¥å›¾åƒï¼šèƒ°è…ºCTåˆ‡ç‰‡ï¼ˆ512Ã—512ï¼‰

Layer 1æ³¨æ„åŠ›å›¾ï¼š
- è¾¹ç•Œå’Œçº¹ç†è¢«çªå‡º
- èƒŒæ™¯éƒ¨åˆ†è¢«æŠ‘åˆ¶
- Î±_background â‰ˆ 0.3-0.5

Layer 2æ³¨æ„åŠ›å›¾ï¼š
- èƒ°è…ºåŒºåŸŸæ›´åŠ æ˜æ˜¾
- èƒŒæ™¯è¿›ä¸€æ­¥æŠ‘åˆ¶
- Î±_background â‰ˆ 0.1-0.3

Layer 3æ³¨æ„åŠ›å›¾ï¼š
- èƒ°è…ºåŒºåŸŸé«˜äº®ï¼ˆÎ± â‰ˆ 0.9ï¼‰
- èƒŒæ™¯å‡ ä¹æ¶ˆå¤±ï¼ˆÎ± â‰ˆ 0.05ï¼‰
- ç„¦ç‚¹åŒºåŸŸæ¸…æ™°

Layer 4æ³¨æ„åŠ›å›¾ï¼ˆæœ€æ·±å±‚ï¼‰ï¼š
- èƒ°è…ºåŒºåŸŸå®Œå…¨æ¿€æ´»ï¼ˆÎ± â‰ˆ 1.0ï¼‰
- èƒŒæ™¯å®Œå…¨æŠ‘åˆ¶ï¼ˆÎ± â‰ˆ 0.01ï¼‰
- ç±»ä¼¼äºç²—ç³™çš„åˆ†å‰²mask
```

---

## ğŸ’¡ Attention UNetçš„ä¼˜åŠ¿ä¸å±€é™

### âœ… ä¼˜åŠ¿

#### 1. æå‡å°ç›®æ ‡åˆ†å‰²

**å¯¹æ¯”UNet**ï¼š
```
åœºæ™¯ï¼šèƒ°è…ºåˆ†å‰²ï¼ˆå å›¾åƒ3%ï¼‰

UNetï¼š
- ç¼–ç å™¨ç‰¹å¾åŒ…å«97%èƒŒæ™¯
- Skipä¼ é€’å…¨éƒ¨ç‰¹å¾
- è§£ç å™¨è¢«èƒŒæ™¯å¹²æ‰°
- Dice: 0.82

Attention UNetï¼š
- æ³¨æ„åŠ›é—¨æ§æŠ‘åˆ¶97%èƒŒæ™¯
- Skipä»…ä¼ é€’é‡è¦ç‰¹å¾
- è§£ç å™¨ä¸“æ³¨å‰æ™¯
- Dice: 0.86ï¼ˆ+4%ï¼‰
```

#### 2. å¯è§£é‡Šæ€§

```python
# å¯è§†åŒ–æ³¨æ„åŠ›ï¼Œç†è§£ç½‘ç»œå†³ç­–
att_maps = model.get_attention_maps(image)

for i, att in enumerate(att_maps):
    print(f"Layer {i}: å…³æ³¨åŒºåŸŸæ¯”ä¾‹ = {(att > 0.5).float().mean():.2%}")

è¾“å‡ºï¼š
Layer 1: å…³æ³¨åŒºåŸŸæ¯”ä¾‹ = 45%  ï¼ˆå¹¿æ³›å…³æ³¨ï¼‰
Layer 2: å…³æ³¨åŒºåŸŸæ¯”ä¾‹ = 25%  ï¼ˆå¼€å§‹èšç„¦ï¼‰
Layer 3: å…³æ³¨åŒºåŸŸæ¯”ä¾‹ = 8%   ï¼ˆé«˜åº¦èšç„¦ï¼‰
Layer 4: å…³æ³¨åŒºåŸŸæ¯”ä¾‹ = 3%   ï¼ˆç²¾ç¡®å®šä½ï¼‰
```

#### 3. æ— éœ€é¢å¤–æ ‡æ³¨

- âœ… ä»…ç”¨åˆ†å‰²maskè®­ç»ƒï¼Œæ— éœ€ROIæ ‡æ³¨
- âœ… æ³¨æ„åŠ›æƒé‡è‡ªåŠ¨å­¦ä¹ 
- âœ… ç«¯åˆ°ç«¯ä¼˜åŒ–

#### 4. è®¡ç®—æ•ˆç‡é«˜

**å‚æ•°é‡å¯¹æ¯”**ï¼š
```
UNet: 31.0M å‚æ•°
Attention UNet: 34.5M å‚æ•°ï¼ˆ+11%ï¼‰

é¢å¤–è®¡ç®—ï¼š
- æ¯ä¸ªAG: 2æ¬¡1Ã—1å·ç§¯ + 1æ¬¡æ’å€¼
- æ€»é¢å¤–è®¡ç®—: çº¦5%
```

ç›¸æ¯”å¢åŠ ç½‘ç»œæ·±åº¦æˆ–å®½åº¦ï¼Œæ³¨æ„åŠ›æœºåˆ¶çš„ä»£ä»·å¾ˆå°ã€‚

### âŒ å±€é™

#### 1. å¤šç±»åˆ«åˆ†å‰²æŒ‘æˆ˜

```
é—®é¢˜ï¼šæ³¨æ„åŠ›æ˜¯å…¨å±€çš„ï¼Œéš¾ä»¥åŒæ—¶å…³æ³¨å¤šä¸ªç›®æ ‡

ç¤ºä¾‹ï¼šåŒæ—¶åˆ†å‰²è‚è„å’Œè‚¿ç˜¤
- è‚è„ï¼šå¤§ç›®æ ‡ï¼ˆå 30%ï¼‰
- è‚¿ç˜¤ï¼šå°ç›®æ ‡ï¼ˆå 2%ï¼‰

Attention UNetå€¾å‘äºï¼š
- å…³æ³¨è‚è„ï¼ˆå¤§ç›®æ ‡æ›´æ˜¾è‘—ï¼‰
- å¿½ç•¥è‚¿ç˜¤ï¼ˆå°ç›®æ ‡è¢«æŠ‘åˆ¶ï¼‰

è§£å†³æ–¹æ¡ˆï¼š
- ä½¿ç”¨å¤šä¸ªæ³¨æ„åŠ›å¤´ï¼ˆMulti-head Attentionï¼‰
- æˆ–åˆ†åˆ«è®­ç»ƒä¸¤ä¸ªç½‘ç»œ
```

#### 2. ä¾èµ–è§£ç å™¨è´¨é‡

```
æ³¨æ„åŠ›é—¨æ§ä¾èµ–è§£ç å™¨ç‰¹å¾gä½œä¸ºquery

å¦‚æœè§£ç å™¨ç‰¹å¾è´¨é‡å·®ï¼š
â†’ æ³¨æ„åŠ›æƒé‡ä¸å‡†ç¡®
â†’ åè€Œé™ä½æ€§èƒ½

ç¤ºä¾‹ï¼š
Early Epoch: è§£ç å™¨æœªæ”¶æ•›
â†’ gåŒ…å«å¤§é‡å™ªå£°
â†’ æ³¨æ„åŠ›å›¾æ··ä¹±
â†’ æ€§èƒ½å·®äºæ ‡å‡†UNet

Later Epoch: è§£ç å™¨æ”¶æ•›
â†’ gå‡†ç¡®è¡¨ç¤ºç›®æ ‡è¯­ä¹‰
â†’ æ³¨æ„åŠ›å›¾ç²¾ç¡®
â†’ æ€§èƒ½è¶…è¶ŠUNet
```

#### 3. è®­ç»ƒä¸ç¨³å®š

```python
# æ³¨æ„åŠ›é—¨æ§å¯èƒ½å¯¼è‡´æ¢¯åº¦é—®é¢˜

é—®é¢˜1ï¼šæ³¨æ„åŠ›é¥±å’Œ
Î± â†’ 1ï¼ˆå§‹ç»ˆæ¿€æ´»ï¼‰æˆ– Î± â†’ 0ï¼ˆå§‹ç»ˆæŠ‘åˆ¶ï¼‰
â†’ æ¢¯åº¦æ¶ˆå¤±

è§£å†³æ–¹æ¡ˆï¼š
- ä½¿ç”¨Batch Normalization
- é€‚å½“çš„åˆå§‹åŒ–
- æ¢¯åº¦è£å‰ª

# ç¤ºä¾‹ï¼šæ”¹è¿›çš„AG
class StableAttentionGate(nn.Module):
    def __init__(self, F_g, F_l, F_int):
        super().__init__()
        # ...
        
        # åˆå§‹åŒ–ä¸ºæ’ç­‰æ˜ å°„
        self.psi[-1].weight.data.zero_()  # Sigmoidè¾“å…¥æ¥è¿‘0
        self.psi[-1].bias.data.fill_(1.0)  # Î±åˆå§‹æ¥è¿‘0.73
    
    def forward(self, g, x):
        # ...
        psi = self.psi(psi)
        
        # é˜²æ­¢æ³¨æ„åŠ›é¥±å’Œ
        psi = psi.clamp(min=0.01, max=0.99)
        
        return x * psi
```

---

## ğŸ”¬ å˜ç§ä¸æ‰©å±•

### 1. Dual Attention UNet

**æ€æƒ³**: ç©ºé—´æ³¨æ„åŠ› + é€šé“æ³¨æ„åŠ›

```python
class DualAttentionGate(nn.Module):
    def __init__(self, F_g, F_l, F_int):
        super().__init__()
        # ç©ºé—´æ³¨æ„åŠ›ï¼ˆåŸç‰ˆAGï¼‰
        self.spatial_att = AttentionGate(F_g, F_l, F_int)
        
        # é€šé“æ³¨æ„åŠ›
        self.channel_att = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(F_l, F_l // 16, 1),
            nn.ReLU(),
            nn.Conv2d(F_l // 16, F_l, 1),
            nn.Sigmoid()
        )
    
    def forward(self, g, x):
        # ç©ºé—´æ³¨æ„åŠ›
        x_spatial = self.spatial_att(g, x)
        
        # é€šé“æ³¨æ„åŠ›
        channel_weight = self.channel_att(x_spatial)
        x_channel = x_spatial * channel_weight
        
        return x_channel
```

### 2. 3D Attention UNet

æ‰©å±•åˆ°3DåŒ»å­¦å›¾åƒï¼š

```python
class AttentionGate3D(nn.Module):
    def __init__(self, F_g, F_l, F_int):
        super().__init__()
        self.W_g = nn.Conv3d(F_g, F_int, 1)  # 3Då·ç§¯
        self.W_x = nn.Conv3d(F_l, F_int, 1)
        self.psi = nn.Conv3d(F_int, 1, 1)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, g, x):
        g1 = self.W_g(g)
        g1 = F.interpolate(g1, size=x.size()[2:], mode='trilinear')
        x1 = self.W_x(x)
        psi = self.sigmoid(self.psi(F.relu(g1 + x1)))
        return x * psi
```

### 3. Multi-scale Attention

**æ€æƒ³**: ä¸åŒå°ºåº¦çš„æ³¨æ„åŠ›

```python
class MultiScaleAttention(nn.Module):
    def __init__(self, F_g, F_l):
        super().__init__()
        # å¤šå°ºåº¦æ³¨æ„åŠ›
        self.att_1x = AttentionGate(F_g, F_l, F_l // 2)
        self.att_2x = AttentionGate(F_g, F_l, F_l // 2)
        self.att_4x = AttentionGate(F_g, F_l, F_l // 2)
    
    def forward(self, g, x):
        # ä¸åŒä¸‹é‡‡æ ·ç‡çš„g
        g_1x = g
        g_2x = F.avg_pool2d(g, 2)
        g_4x = F.avg_pool2d(g, 4)
        
        # å¤šå°ºåº¦æ³¨æ„åŠ›
        att_1x = self.att_1x(g_1x, x)
        att_2x = self.att_2x(g_2x, x)
        att_4x = self.att_4x(g_4x, x)
        
        # èåˆ
        return (att_1x + att_2x + att_4x) / 3
```

---

## ğŸ“ è®­ç»ƒæŠ€å·§

### 1. æŸå¤±å‡½æ•°

```python
# ç»„åˆæŸå¤±
class CombinedLoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.dice = DiceLoss()
        self.ce = nn.CrossEntropyLoss()
        self.focal = FocalLoss()  # é’ˆå¯¹å°ç›®æ ‡
    
    def forward(self, pred, target):
        dice_loss = self.dice(pred, target)
        ce_loss = self.ce(pred, target)
        focal_loss = self.focal(pred, target)
        
        # åŠ æƒç»„åˆ
        return 0.4 * dice_loss + 0.3 * ce_loss + 0.3 * focal_loss
```

### 2. æ•°æ®å¢å¼º

èƒ°è…ºç­‰å°å™¨å®˜åˆ†å‰²éœ€è¦å¼ºæ•°æ®å¢å¼ºï¼š

```python
transforms = A.Compose([
    # å‡ ä½•å˜æ¢
    A.RandomRotate90(p=0.5),
    A.HorizontalFlip(p=0.5),
    A.ShiftScaleRotate(
        shift_limit=0.1,
        scale_limit=0.2,
        rotate_limit=30,
        p=0.8
    ),
    A.ElasticTransform(alpha=50, sigma=5, p=0.5),
    
    # å¼ºåº¦å˜æ¢
    A.RandomBrightnessContrast(p=0.5),
    A.RandomGamma(p=0.5),
    
    # å™ªå£°
    A.GaussNoise(p=0.3),
    
    # æ¨¡ç³Š
    A.GaussianBlur(p=0.3),
])
```

### 3. å­¦ä¹ ç‡è°ƒåº¦

```python
# Warm-up + Cosine Annealing
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# Warm-up: å‰5ä¸ªepochçº¿æ€§å¢åŠ 
warmup_scheduler = torch.optim.lr_scheduler.LinearLR(
    optimizer,
    start_factor=0.1,
    end_factor=1.0,
    total_iters=5
)

# Cosine Annealing: åç»­epochä½™å¼¦è¡°å‡
cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer,
    T_max=95,
    eta_min=1e-6
)

scheduler = torch.optim.lr_scheduler.SequentialLR(
    optimizer,
    schedulers=[warmup_scheduler, cosine_scheduler],
    milestones=[5]
)
```

### 4. æ¸è¿›å¼è®­ç»ƒ

```python
# å…ˆè®­ç»ƒæ ‡å‡†UNetï¼Œå†fine-tune Attention
# é˜¶æ®µ1ï¼šå†»ç»“AGï¼Œè®­ç»ƒUNetä¸»å¹²
for epoch in range(50):
    # å†»ç»“AG
    for name, param in model.named_parameters():
        if 'att' in name:
            param.requires_grad = False
    
    train_epoch(model, train_loader)

# é˜¶æ®µ2ï¼šè§£å†»AGï¼Œfine-tuneå…¨ç½‘ç»œ
for epoch in range(50, 100):
    # è§£å†»AG
    for param in model.parameters():
        param.requires_grad = True
    
    train_epoch(model, train_loader)
```

---

## ğŸ“– æ€»ç»“

### Attention UNetçš„è´¡çŒ®

1. **è‡ªåŠ¨ç‰¹å¾é€‰æ‹©**
   - Skip Connectionä¸å†ç›²ç›®ä¼ é€’æ‰€æœ‰ç‰¹å¾
   - ç½‘ç»œå­¦ä¼šå…³æ³¨é‡è¦åŒºåŸŸï¼ŒæŠ‘åˆ¶å™ªå£°

2. **æå‡å°ç›®æ ‡åˆ†å‰²**
   - åœ¨èƒ°è…ºã€ç—…ç¶ç­‰å°ç›®æ ‡ä¸Šæ˜¾è‘—æå‡
   - Diceç³»æ•°æå‡2-4%

3. **å¢å¼ºå¯è§£é‡Šæ€§**
   - å¯è§†åŒ–æ³¨æ„åŠ›å›¾ï¼Œç†è§£ç½‘ç»œå†³ç­–
   - è¾…åŠ©ä¸´åºŠè¯Šæ–­

4. **è®¡ç®—é«˜æ•ˆ**
   - ä»…å¢åŠ 11%å‚æ•°ï¼Œ5%è®¡ç®—é‡
   - æ€§ä»·æ¯”æé«˜çš„æ”¹è¿›

### æ ¸å¿ƒæ€æƒ³æ€»ç»“

> **Attention UNetæ•™ä¼šäº†ç½‘ç»œ"çœ‹å“ªé‡Œ"**ï¼šåœ¨è§£ç é˜¶æ®µï¼Œç½‘ç»œä¸æ˜¯è¢«åŠ¨æ¥å—ç¼–ç å™¨çš„æ‰€æœ‰ç‰¹å¾ï¼Œè€Œæ˜¯ä¸»åŠ¨é€‰æ‹©éœ€è¦çš„ä¿¡æ¯ã€‚

**æ•°å­¦æœ¬è´¨**ï¼š

$$
\text{Standard UNet: } \quad y = \text{Decoder}(x_{\text{enc}} \oplus x_{\text{dec}})
$$

$$
\text{Attention UNet: } \quad y = \text{Decoder}(\underbrace{\alpha \odot x_{\text{enc}}}_{\text{åŠ æƒç‰¹å¾}} \oplus x_{\text{dec}})
$$

å…¶ä¸­ \(\alpha = f(x_{\text{enc}}, x_{\text{dec}})\) æ˜¯å­¦ä¹ åˆ°çš„æ³¨æ„åŠ›æƒé‡ã€‚

### åç»­å½±å“

Attention UNetå¼€å¯äº†åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„"æ³¨æ„åŠ›æ—¶ä»£"ï¼š
- âœ… UNet++ã€UNet 3+ é‡‡ç”¨ç±»ä¼¼æœºåˆ¶
- âœ… Transformerï¼ˆTransUNetã€Swin-UNetï¼‰çš„è‡ªæ³¨æ„åŠ›
- âœ… æˆä¸ºç°ä»£åˆ†å‰²ç½‘ç»œçš„æ ‡é…æ¨¡å—

**ä¸‹ä¸€ç¯‡é¢„å‘Š**ï¼š[UNet++/UNet 3+ï¼šå¯†é›†è¿æ¥çš„åŠ›é‡](/2025/02/15/unet-plus-series/) - æ¢ç´¢å¦‚ä½•é€šè¿‡å¯†é›†è·³è·ƒè¿æ¥å’Œæ·±åº¦ç›‘ç£è¿›ä¸€æ­¥æå‡åˆ†å‰²æ€§èƒ½ã€‚

---

## ğŸ“š å‚è€ƒèµ„æ–™

### è®ºæ–‡
1. [Attention UNet] Oktay, O., et al. (2018). Attention u-net: Learning where to look for the pancreas. *MIDL*.
2. [UNet] Ronneberger, O., et al. (2015). U-net: Convolutional networks for biomedical image segmentation. *MICCAI*.
3. [SENet] Hu, J., et al. (2018). Squeeze-and-excitation networks. *CVPR*.

### ä»£ç å®ç°
- [Attention UNetå®˜æ–¹](https://github.com/ozan-octopus/attention-unet) - åŸå§‹å®ç°
- [PyTorchå®ç°](https://github.com/LeeJunHyun/Image_Segmentation) - æ¸…æ™°çš„PyTorchç‰ˆæœ¬
- [åŒ»å­¦å›¾åƒå·¥å…·åŒ…](https://github.com/Project-MONAI/MONAI) - MONAIæ¡†æ¶åŒ…å«Attention UNet

### æ•°æ®é›†
- [Pancreas-CT](https://wiki.cancerimagingarchive.net/display/Public/Pancreas-CT) - èƒ°è…ºåˆ†å‰²æ•°æ®é›†
- [LiTS](https://competitions.codalab.org/competitions/17094) - è‚è„è‚¿ç˜¤åˆ†å‰²
- [Medical Segmentation Decathlon](http://medicaldecathlon.com/) - å¤šå™¨å®˜åˆ†å‰²æŒ‘æˆ˜

### æ‰©å±•é˜…è¯»
- [æ³¨æ„åŠ›æœºåˆ¶ç»¼è¿°](https://arxiv.org/abs/2103.16563)
- [åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„æ³¨æ„åŠ›](https://arxiv.org/abs/2012.12453)

---

## ğŸ”— ç³»åˆ—æ–‡ç« å¯¼èˆª

**åŒ»å­¦å½±åƒåˆ†å‰²ç½‘ç»œç³»åˆ—**ï¼š

1. [FCNä¸UNetï¼šåŒ»å­¦åˆ†å‰²çš„å¥ åŸºä¹‹ä½œ](/2025/02/01/fcn-unet-foundation/)
2. [V-Netï¼š3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„çªç ´](/2025/02/05/vnet-3d-segmentation/)
3. ğŸ“ **Attention UNetï¼šæ³¨æ„åŠ›æœºåˆ¶çš„å¼•å…¥**ï¼ˆæœ¬æ–‡ï¼‰
4. [UNet++/UNet 3+ï¼šå¯†é›†è¿æ¥çš„åŠ›é‡](/2025/02/15/unet-plus-series/)
5. [TransUNetï¼šCNNä¸Transformerçš„èåˆ](/2025/02/20/transunet-hybrid-architecture/)
6. [Swin-UNetï¼šå±‚çº§åŒ–Transformer](/2025/02/25/swin-unet-hierarchical-transformer/)
7. [SAMä¸MedSAMï¼šåŸºç¡€æ¨¡å‹çš„åŒ»å­¦åº”ç”¨](/2025/03/05/sam-segment-anything/)
8. [nnU-Netï¼šè‡ªé€‚åº”åŒ»å­¦åˆ†å‰²æ¡†æ¶](/2025/03/15/nnunet-self-configuring-framework/)

---

*æœ¬æ–‡æ·±å…¥è§£æäº†Attention UNetå¦‚ä½•é€šè¿‡æ³¨æ„åŠ›é—¨æ§æœºåˆ¶è®©ç½‘ç»œå­¦ä¼šè‡ªåŠ¨èšç„¦é‡è¦åŒºåŸŸï¼Œåœ¨å°ç›®æ ‡åˆ†å‰²ä»»åŠ¡ä¸Šå–å¾—çªç ´ã€‚ä¸‹ä¸€ç¯‡å°†ä»‹ç»UNet++å’ŒUNet 3+å¦‚ä½•é€šè¿‡å¯†é›†è¿æ¥è¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚*

