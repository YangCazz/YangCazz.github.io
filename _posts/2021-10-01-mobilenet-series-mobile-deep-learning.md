---
layout: post
title: "MobileNetç³»åˆ—ï¼šç§»åŠ¨ç«¯çš„æ·±åº¦å­¦ä¹ é©å‘½"
date: 2021-10-01 10:00:00 +0800
categories: [æ·±åº¦å­¦ä¹ , è½»é‡åŒ–ç½‘ç»œ]
tags: [CNN, ç§»åŠ¨ç«¯, PyTorch]
excerpt: "æ·±å…¥è§£æMobileNetç³»åˆ—ï¼ˆV1-V3ï¼‰çš„æ¼”è¿›å†ç¨‹ã€‚ä»æ·±åº¦å¯åˆ†ç¦»å·ç§¯åˆ°é€†æ®‹å·®ç»“æ„ï¼Œä»ReLU6åˆ°H-Swishï¼Œæ¢ç´¢å¦‚ä½•è®¾è®¡é«˜æ•ˆçš„ç§»åŠ¨ç«¯æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚"
---

# MobileNetç³»åˆ—ï¼šç§»åŠ¨ç«¯çš„æ·±åº¦å­¦ä¹ é©å‘½

## å¼•è¨€

åœ¨ç»å†äº†GoogLeNetå¤šå¹´å¤šä¸ªç‰ˆæœ¬çš„é€’è¿›ç ”ç©¶åï¼Œæ·±åº¦å­¦ä¹ å„æ¨¡å‹ä¹‹é—´çš„ç«äº‰å¤§å¤šé›†ä¸­åœ¨**å¤§è§„æ¨¡è®¡ç®—**å’Œ**ç¡¬ä»¶ç®—åŠ›**ä¸Šã€‚2017å¹´ï¼ŒGoogleå›¢é˜Ÿè½¬è€Œå°†ç›®å…‰æŠ•å‘äº†æ·±åº¦å­¦ä¹ åœ¨**å°è§„æ¨¡è®¡ç®—é›†ç¾¤çš„éƒ¨ç½²**ä¸Šã€‚

**MobileNetï¼Œæ­£å¦‚å…¶åâ€”â€”å¯ä»¥åœ¨ç§»åŠ¨è®¾å¤‡ä¸Šéƒ¨ç½²çš„æ·±åº¦å­¦ä¹ ç½‘ç»œ**ã€‚Googleå›¢é˜Ÿé€šè¿‡åˆ›æ–°çš„ç½‘ç»œè®¾è®¡ï¼Œè®©ç®—åŠ›è¾ƒä½çš„è®¾å¤‡ï¼ˆå¦‚æ‰‹æœºå’Œå°å‹ç”µè„‘ï¼‰ä¹Ÿèƒ½å®Œæˆæ·±åº¦å­¦ä¹ ä»»åŠ¡ã€‚

## ç³»åˆ—æ¦‚è§ˆ

### è®ºæ–‡åˆ—è¡¨

* **[2017] MobileNet V1**ï¼š[MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications](https://arxiv.org/abs/1704.04861)
* **[2018] MobileNet V2**ï¼š[MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381)
* **[2019] MobileNet V3**ï¼š[Searching for MobileNetV3](https://arxiv.org/abs/1905.02244)

## 1. MobileNet V1 (2017)

### è®¾è®¡ç›®æ ‡

* âœ… å‡å°‘å‚æ•°é‡
* âœ… é™ä½è®¡ç®—é‡
* âœ… ä¿æŒåˆç†çš„ç²¾åº¦
* âœ… é€‚åˆç§»åŠ¨ç«¯éƒ¨ç½²

### æ ¸å¿ƒåˆ›æ–°ï¼šæ·±åº¦å¯åˆ†ç¦»å·ç§¯

MobileNet V1çš„æ ¸å¿ƒæ˜¯**æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆDepthwise Separable Convolutionï¼‰**ã€‚

#### æ ‡å‡†å·ç§¯çš„é—®é¢˜

æ ‡å‡†å·ç§¯çš„è®¡ç®—é‡ï¼š

$$
\text{Params} = K \times K \times M \times N
$$

$$
\text{FLOPs} = K \times K \times M \times N \times H \times W
$$

å…¶ä¸­ï¼š
* \(K\times K\)ï¼šå·ç§¯æ ¸å¤§å°
* \(M\)ï¼šè¾“å…¥é€šé“æ•°
* \(N\)ï¼šè¾“å‡ºé€šé“æ•°ï¼ˆå·ç§¯æ ¸ä¸ªæ•°ï¼‰
* \(H \times W\)ï¼šç‰¹å¾å›¾å°ºå¯¸

#### æ·±åº¦å¯åˆ†ç¦»å·ç§¯

![DW+PWå·ç§¯](/assets/images/deep-learning/MobileNet_v1_dw_pw.png)

**æ·±åº¦å¯åˆ†ç¦»å·ç§¯ = æ·±åº¦å·ç§¯ï¼ˆDWï¼‰ + é€ç‚¹å·ç§¯ï¼ˆPWï¼‰**

##### 1. æ·±åº¦å·ç§¯ï¼ˆDepthwise Convolution, DWï¼‰

**æ€æƒ³**ï¼šæ¯ä¸ªè¾“å…¥é€šé“ä½¿ç”¨ç‹¬ç«‹çš„å·ç§¯æ ¸ã€‚

```python
# DWå·ç§¯ï¼šæ¯ä¸ªé€šé“ç‹¬ç«‹å¤„ç†
nn.Conv2d(in_channels=M, out_channels=M, 
          kernel_size=3, groups=M)  # groups=Mæ˜¯å…³é”®
```

**è®¡ç®—é‡**ï¼š
$$
\text{FLOPs}_{DW} = K \times K \times M \times H \times W
$$

##### 2. é€ç‚¹å·ç§¯ï¼ˆPointwise Convolution, PWï¼‰

**æ€æƒ³**ï¼šä½¿ç”¨1Ã—1å·ç§¯è¿›è¡Œé€šé“é—´ä¿¡æ¯èåˆã€‚

```python
# PWå·ç§¯ï¼š1Ã—1å·ç§¯
nn.Conv2d(in_channels=M, out_channels=N, kernel_size=1)
```

**è®¡ç®—é‡**ï¼š
$$
\text{FLOPs}_{PW} = M \times N \times H \times W
$$

#### è®¡ç®—é‡å¯¹æ¯”

**æ€»è®¡ç®—é‡**ï¼š
$$
\text{FLOPs}_{DSC} = K^2 \cdot M \cdot H \cdot W + M \cdot N \cdot H \cdot W
$$

**å‹ç¼©æ¯”**ï¼š
$$
\frac{\text{FLOPs}_{DSC}}{\text{FLOPs}_{Standard}} = \frac{1}{N} + \frac{1}{K^2}
$$

**å½“\(K=3\)æ—¶**ï¼Œå‹ç¼©æ¯”çº¦ä¸º **1/9**ï¼

### ç½‘ç»œç»“æ„

![MobileNet V1ç»“æ„](/assets/images/deep-learning/MobileNet_v1.png)

```python
class DepthwiseSeparableConv(nn.Module):
    """æ·±åº¦å¯åˆ†ç¦»å·ç§¯æ¨¡å—"""
    def __init__(self, in_channels, out_channels, stride=1):
        super(DepthwiseSeparableConv, self).__init__()
        
        # Depthwiseå·ç§¯
        self.depthwise = nn.Sequential(
            nn.Conv2d(in_channels, in_channels, kernel_size=3, 
                     stride=stride, padding=1, groups=in_channels, bias=False),
            nn.BatchNorm2d(in_channels),
            nn.ReLU(inplace=True)
        )
        
        # Pointwiseå·ç§¯
        self.pointwise = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        return x
```

### æ¨¡å‹å¤ç°

* **ä»£ç åœ°å€**ï¼š[GitHub - DeepLearning/model_classification/MobileNet](https://github.com/YangCazz/DeepLearning/tree/master/model_classification/MobileNet)

## 2. MobileNet V2 (2018)

### æ ¸å¿ƒåˆ›æ–°

V2åœ¨V1çš„åŸºç¡€ä¸Šæå‡ºäº†ä¸¤ä¸ªé‡è¦æ¦‚å¿µï¼š
1. **Linear Bottleneck**ï¼ˆçº¿æ€§ç“¶é¢ˆï¼‰
2. **Inverted Residual**ï¼ˆé€†æ®‹å·®ç»“æ„ï¼‰

### é—®é¢˜ï¼šReLUå¯¹ä½ç»´ä¿¡æ¯çš„ç ´å

#### ReLUçš„éçº¿æ€§æŸå¤±

ReLUæ¿€æ´»å‡½æ•°ä¼šå°†è´Ÿå€¼å…¨éƒ¨ç½®é›¶ï¼š
$$
\text{ReLU}(x) = \max(0, x)
$$

**é—®é¢˜**ï¼šå½“ç‰¹å¾ç»´åº¦è¾ƒä½æ—¶ï¼ŒReLUä¼šä¸¢å¤±å¤§é‡ä¿¡æ¯ï¼

![ReLU6æ¿€æ´»å‡½æ•°](/assets/images/deep-learning/MobileNet_v2_ReLU6.png)

### è§£å†³æ–¹æ¡ˆ1ï¼šReLU6

**ReLU6å®šä¹‰**ï¼š
$$
\text{ReLU6}(x) = \min(\max(0, x), 6)
$$

```python
# ReLU6å®ç°
nn.ReLU6(inplace=True)
```

**ä¼˜åŠ¿**ï¼š
* åœ¨6å¤„æˆªæ–­ï¼Œé˜²æ­¢æ•°å€¼è¿‡å¤§
* å‡å°‘ç²¾åº¦æŸå¤±
* å¯¹ä½ç²¾åº¦è®¡ç®—å‹å¥½

### è§£å†³æ–¹æ¡ˆ2ï¼šé€†æ®‹å·®ç»“æ„

![é€†æ®‹å·®ç»“æ„å¯¹æ¯”](/assets/images/deep-learning/MobileNet_v2_Inverted_Residual.png)

#### ä¼ ç»Ÿæ®‹å·® vs é€†æ®‹å·®

| ç»´åº¦ | ä¼ ç»Ÿæ®‹å·®ï¼ˆResNetï¼‰ | é€†æ®‹å·®ï¼ˆMobileNet V2ï¼‰ |
|------|------------------|---------------------|
| è·¯å¾„ | é«˜ç»´â†’ä½ç»´â†’é«˜ç»´ | ä½ç»´â†’é«˜ç»´â†’ä½ç»´ |
| æ“ä½œæµç¨‹ | é™ç»´â†’å¤„ç†â†’å‡ç»´ | å‡ç»´â†’å¤„ç†â†’é™ç»´ |
| Shortcut | é«˜ç»´ | ä½ç»´ |
| æ ¸å¿ƒæ€æƒ³ | å‹ç¼©è¡¨ç¤º | æ‰©å±•è¡¨ç¤º |

#### ä¸ºä»€ä¹ˆè¦"é€†"ï¼Ÿ

1. **DWå·ç§¯ä¸æ”¹å˜é€šé“æ•°**ï¼šéœ€è¦å…ˆå‡ç»´æ‰èƒ½æå–æ›´ä¸°å¯Œçš„ç‰¹å¾
2. **ä½ç»´shortcutèŠ‚çœå†…å­˜**ï¼šä½ç»´çš„æ®‹å·®è¿æ¥æ›´é«˜æ•ˆ
3. **é«˜ç»´å¤„ç†æ›´æœ‰æ•ˆ**ï¼šåœ¨é«˜ç»´ç©ºé—´è¿›è¡Œç‰¹å¾æå–æ•ˆæœæ›´å¥½

### Inverted Residual Block

![Bottleneck Block](/assets/images/deep-learning/MobileNet_v2_Bottleneck.png)

```python
class InvertedResidual(nn.Module):
    """é€†æ®‹å·®æ¨¡å—"""
    def __init__(self, in_channels, out_channels, stride, expand_ratio):
        super(InvertedResidual, self).__init__()
        
        hidden_dim = in_channels * expand_ratio
        self.use_residual = stride == 1 and in_channels == out_channels
        
        layers = []
        
        # 1. å‡ç»´ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if expand_ratio != 1:
            layers.append(nn.Sequential(
                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False),
                nn.BatchNorm2d(hidden_dim),
                nn.ReLU6(inplace=True)
            ))
        
        # 2. Depthwiseå·ç§¯
        layers.append(nn.Sequential(
            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, 
                     stride=stride, padding=1, groups=hidden_dim, bias=False),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU6(inplace=True)
        ))
        
        # 3. é™ç»´ï¼ˆLinear Bottleneckï¼‰
        layers.append(nn.Sequential(
            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels),
            # æ³¨æ„ï¼šè¿™é‡Œæ²¡æœ‰ReLUï¼
        ))
        
        self.conv = nn.Sequential(*layers)
    
    def forward(self, x):
        if self.use_residual:
            return x + self.conv(x)
        else:
            return self.conv(x)
```

### Linear Bottleneck

**å…³é”®è®¾è®¡**ï¼šæœ€åçš„1Ã—1å·ç§¯å**ä¸ä½¿ç”¨ReLU**ï¼

**åŸå› **ï¼š
* è¾“å‡ºæ˜¯ä½ç»´çš„
* ReLUä¼šç ´åä½ç»´ä¿¡æ¯
* ä½¿ç”¨çº¿æ€§æ¿€æ´»ä¿ç•™æ›´å¤šä¿¡æ¯

### ä¸»è¦è´¡çŒ®

1. **é€†æ®‹å·®ç»“æ„**ï¼šæ›´é«˜æ•ˆçš„ç‰¹å¾æå–
2. **Linear Bottleneck**ï¼šä¿æŠ¤ä½ç»´ä¿¡æ¯
3. **ReLU6**ï¼šæ›´é€‚åˆç§»åŠ¨ç«¯çš„æ¿€æ´»å‡½æ•°
4. **æ›´å¥½çš„æ€§èƒ½**ï¼šå‚æ•°é‡å‡å°‘ï¼Œç²¾åº¦æå‡

## 3. MobileNet V3 (2019)

### æ ¸å¿ƒåˆ›æ–°

V3å¼•å…¥äº†ä¸‰ä¸ªä¸»è¦æ”¹è¿›ï¼š
1. **NASï¼ˆç¥ç»æ¶æ„æœç´¢ï¼‰**
2. **SEæ¨¡å—ï¼ˆSqueeze-and-Excitationï¼‰**
3. **H-Swishæ¿€æ´»å‡½æ•°**

### 1. NAS - ç¥ç»æ¶æ„æœç´¢

**æš´åŠ›ç¾å­¦**ï¼šä½¿ç”¨ä¼˜åŒ–ç®—æ³•è‡ªåŠ¨æœç´¢æœ€ä¼˜çš„ç½‘ç»œç»“æ„ã€‚

**æœç´¢ç©ºé—´**ï¼š
* å±‚æ•°
* å·ç§¯æ ¸å¤§å°
* æ‰©å±•æ¯”ä¾‹
* é€šé“æ•°

**ä»£ä»·**ï¼šéœ€è¦æå¤§çš„ç®—åŠ›ï¼

### 2. SEæ¨¡å— - é€šé“æ³¨æ„åŠ›

![SEæ¨¡å—](/assets/images/deep-learning/MobileNet_v3_SE.png)

**Squeeze-and-Excitation**ï¼šå­¦ä¹ é€šé“ä¹‹é—´çš„é‡è¦æ€§ã€‚

```python
class SEBlock(nn.Module):
    """SEæ³¨æ„åŠ›æ¨¡å—"""
    def __init__(self, channels, reduction=4):
        super(SEBlock, self).__init__()
        
        # Squeezeï¼šå…¨å±€å¹³å‡æ± åŒ–
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        
        # Excitationï¼šä¸¤å±‚å…¨è¿æ¥
        self.fc = nn.Sequential(
            nn.Linear(channels, channels // reduction),
            nn.ReLU(inplace=True),
            nn.Linear(channels // reduction, channels),
            nn.Hardsigmoid(inplace=True)  # V3ä½¿ç”¨Hard-Sigmoid
        )
    
    def forward(self, x):
        b, c, _, _ = x.size()
        
        # Squeeze
        y = self.avg_pool(x).view(b, c)
        
        # Excitation
        y = self.fc(y).view(b, c, 1, 1)
        
        # Scale
        return x * y.expand_as(x)
```

### 3. H-Swishæ¿€æ´»å‡½æ•°

#### Swishå‡½æ•°

**æ ‡å‡†Swish**ï¼š
$$
\text{Swish}(x) = x \cdot \sigma(\beta x)
$$

å…¶ä¸­ \(\sigma\) æ˜¯Sigmoidå‡½æ•°ã€‚

**é—®é¢˜**ï¼šSigmoidè®¡ç®—å¤æ‚ï¼Œä¸é€‚åˆç§»åŠ¨ç«¯ã€‚

#### Hard-Swish

**è¿‘ä¼¼Swish**ï¼š
$$
\text{H-Swish}(x) = x \cdot \frac{\text{ReLU6}(x + 3)}{6}
$$

**åˆ†æ®µè¡¨è¾¾å¼**ï¼š
$$
\text{H-Swish}(x) = \begin{cases}
0, & \text{if } x \leq -3 \\
x, & \text{if } x \geq 3 \\
\frac{x(x+3)}{6}, & \text{otherwise}
\end{cases}
$$

```python
class HardSwish(nn.Module):
    def forward(self, x):
        return x * F.relu6(x + 3, inplace=True) / 6
```

**ä¼˜åŠ¿**ï¼š
* è®¡ç®—ç®€å•ï¼ˆåªéœ€ReLU6ï¼‰
* ç¡¬ä»¶å‹å¥½
* æ•ˆæœæ¥è¿‘Swish

### MobileNet V3æ¶æ„

V3æä¾›ä¸¤ä¸ªç‰ˆæœ¬ï¼š
* **MobileNet V3-Large**ï¼šé«˜æ€§èƒ½ç‰ˆæœ¬
* **MobileNet V3-Small**ï¼šé«˜æ•ˆç‰ˆæœ¬

## MobileNetç³»åˆ—å¯¹æ¯”

| ç‰ˆæœ¬ | æ ¸å¿ƒæŠ€æœ¯ | å‚æ•°é‡(M) | è®¡ç®—é‡(MFLOPs) | Top-1å‡†ç¡®ç‡ |
|------|---------|----------|---------------|------------|
| V1 | DW+PWå·ç§¯ | 4.2 | 569 | 70.6% |
| V2 | é€†æ®‹å·®+Linear Bottleneck | 3.4 | 300 | 72.0% |
| V3-Large | NAS+SE+H-Swish | 5.4 | 219 | 75.2% |
| V3-Small | NAS+SE+H-Swish | 2.9 | 66 | 67.4% |

## è®¾è®¡å“²å­¦çš„æ¼”è¿›

### V1ï¼šåŸºç¡€è½»é‡åŒ–

* **ç›®æ ‡**ï¼šå‡å°‘è®¡ç®—é‡
* **æ–¹æ³•**ï¼šæ·±åº¦å¯åˆ†ç¦»å·ç§¯
* **ç»“æœ**ï¼šè®¡ç®—é‡é™åˆ°1/9

### V2ï¼šç‰¹å¾è¡¨è¾¾ä¼˜åŒ–

* **ç›®æ ‡**ï¼šä¿æŠ¤ä¿¡æ¯åŒæ—¶é™ä½è®¡ç®—é‡
* **æ–¹æ³•**ï¼šé€†æ®‹å·®+Linear Bottleneck
* **ç»“æœ**ï¼šç²¾åº¦æå‡ï¼Œè®¡ç®—é‡ç»§ç»­é™ä½

### V3ï¼šæè‡´ä¼˜åŒ–

* **ç›®æ ‡**ï¼šè‡ªåŠ¨åŒ–è®¾è®¡+æ€§èƒ½æè‡´åŒ–
* **æ–¹æ³•**ï¼šNAS+SE+æ–°æ¿€æ´»å‡½æ•°
* **ç»“æœ**ï¼šç²¾åº¦å’Œæ•ˆç‡çš„æœ€ä½³å¹³è¡¡

## å®è·µç»éªŒ

### 1. é€‰æ‹©åˆé€‚çš„ç‰ˆæœ¬

```python
# åœºæ™¯1ï¼šé«˜ç²¾åº¦è¦æ±‚
model = mobilenet_v3_large(pretrained=True)

# åœºæ™¯2ï¼šæè‡´è½»é‡
model = mobilenet_v3_small(pretrained=True)

# åœºæ™¯3ï¼šå¹³è¡¡é€‰æ‹©
model = mobilenet_v2(pretrained=True)
```

### 2. å®½åº¦ä¹˜æ•°

MobileNetæ”¯æŒé€šè¿‡å®½åº¦ä¹˜æ•°è°ƒæ•´æ¨¡å‹å¤§å°ï¼š

```python
# å®½åº¦ä¹˜æ•°Î±ï¼šè°ƒæ•´é€šé“æ•°
# Î±=1.0ï¼šæ ‡å‡†æ¨¡å‹
# Î±=0.75ï¼šå‡å°‘25%é€šé“
# Î±=0.5ï¼šå‡å°‘50%é€šé“

def adjust_channels(channels, width_mult=1.0):
    return int(channels * width_mult)
```

### 3. é‡åŒ–éƒ¨ç½²

```python
# åŠ¨æ€é‡åŒ–
import torch.quantization

model_fp32 = mobilenet_v3_small(pretrained=True)
model_int8 = torch.quantization.quantize_dynamic(
    model_fp32,
    {nn.Linear, nn.Conv2d},
    dtype=torch.qint8
)

# æ¨¡å‹å¤§å°å‡å°‘75%ï¼Œé€Ÿåº¦æå‡2-4å€
```

### 4. è¿ç§»å­¦ä¹ æŠ€å·§

```python
# å†»ç»“ç‰¹å¾æå–å±‚
model = mobilenet_v2(pretrained=True)

for param in model.features.parameters():
    param.requires_grad = False

# åªè®­ç»ƒåˆ†ç±»å™¨
model.classifier = nn.Sequential(
    nn.Dropout(0.2),
    nn.Linear(model.last_channel, num_classes)
)
```

## æ·±åº¦å¯åˆ†ç¦»å·ç§¯çš„åº”ç”¨

æ·±åº¦å¯åˆ†ç¦»å·ç§¯å·²æˆä¸ºè½»é‡åŒ–ç½‘ç»œçš„**æ ‡å‡†ç»„ä»¶**ï¼š

* âœ… **MobileNetç³»åˆ—**ï¼šå¼€åˆ›è€…
* âœ… **ShuffleNet**ï¼šç»“åˆç»„å·ç§¯
* âœ… **Xception**ï¼šæè‡´åº”ç”¨
* âœ… **EfficientNet**ï¼šNASä¼˜åŒ–

## ä¼˜ç¼ºç‚¹åˆ†æ

### ä¼˜ç‚¹

1. **å‚æ•°é‡å°‘**ï¼šé€‚åˆç§»åŠ¨ç«¯éƒ¨ç½²
2. **è®¡ç®—å¿«**ï¼šæ¨ç†é€Ÿåº¦å¿«
3. **çµæ´»æ€§é«˜**ï¼šå¯è°ƒæ•´å®½åº¦å’Œåˆ†è¾¨ç‡
4. **å¯æ‰©å±•**ï¼šæ˜“äºä¿®æ”¹å’Œä¼˜åŒ–

### ç¼ºç‚¹

1. **ç²¾åº¦ç•¥ä½**ï¼šç›¸æ¯”ResNetç­‰å¤§æ¨¡å‹
2. **å®ç°å¤æ‚**ï¼šç‰¹åˆ«æ˜¯V3çš„SEæ¨¡å—å’ŒNAS
3. **ç¡¬ä»¶ä¾èµ–**ï¼šéœ€è¦ç¡¬ä»¶æ”¯æŒDWå·ç§¯

## åº”ç”¨åœºæ™¯

MobileNetç³»åˆ—ç‰¹åˆ«é€‚åˆï¼š

* ğŸ“± **ç§»åŠ¨åº”ç”¨**ï¼šæ‰‹æœºAppä¸­çš„AIåŠŸèƒ½
* ğŸ¤– **åµŒå…¥å¼ç³»ç»Ÿ**ï¼šæ ‘è“æ´¾ã€IoTè®¾å¤‡
* ğŸ¥ **å®æ—¶è§†é¢‘å¤„ç†**ï¼šè§†é¢‘æµåˆ†æ
* ğŸš— **è¾¹ç¼˜è®¡ç®—**ï¼šè‡ªåŠ¨é©¾é©¶ã€æ™ºèƒ½ç›‘æ§

## æ€»ç»“

### æŠ€æœ¯æ¼”è¿›

```
V1: æ·±åº¦å¯åˆ†ç¦»å·ç§¯ï¼ˆåŸºç¡€è½»é‡åŒ–ï¼‰
  â†“
V2: é€†æ®‹å·®+Linear Bottleneckï¼ˆä¼˜åŒ–ç‰¹å¾è¡¨è¾¾ï¼‰
  â†“
V3: NAS+SE+H-Swishï¼ˆæè‡´ä¼˜åŒ–ï¼‰
```

### æ ¸å¿ƒæ€æƒ³

1. **æ·±åº¦å¯åˆ†ç¦»å·ç§¯æ˜¯å…³é”®**ï¼šå¤§å¹…é™ä½è®¡ç®—é‡
2. **é€†æ®‹å·®å¾ˆå·§å¦™**ï¼šæ›´é«˜æ•ˆçš„ç‰¹å¾æå–
3. **æ³¨æ„åŠ›æœºåˆ¶æœ‰ç”¨**ï¼šSEæ¨¡å—æå‡æ€§èƒ½
4. **è‡ªåŠ¨åŒ–è®¾è®¡æ˜¯è¶‹åŠ¿**ï¼šNASæ‰¾åˆ°æ›´ä¼˜ç»“æ„

### å½±å“

MobileNetç³»åˆ—ï¼š
* ğŸ“Š æ¨åŠ¨äº†ç§»åŠ¨ç«¯AIçš„å‘å±•
* ğŸ”§ æˆä¸ºè½»é‡åŒ–ç½‘ç»œçš„è®¾è®¡èŒƒå¼
* ğŸš€ å¹¿æ³›åº”ç”¨äºå„ç±»ç«¯ä¾§åœºæ™¯
* ğŸ“ å¯å‘äº†ä¼—å¤šåç»­ç ”ç©¶

## æ¨¡å‹å¤ç°

æˆ‘åœ¨PyTorchå¹³å°ä¸Šå¤ç°äº†MobileNetç³»åˆ—ï¼š

* **å¹³å°**ï¼šPyTorch
* **ä¸»è¦åº“**ï¼štorchvision, torch, matplotlib, tqdm
* **æ•°æ®é›†**ï¼šOxford Flower102èŠ±åˆ†ç±»æ•°æ®é›†
* **ä»£ç åœ°å€**ï¼š[GitHub - DeepLearning/model_classification/MobileNet](https://github.com/YangCazz/DeepLearning/tree/master/model_classification/MobileNet)

## å‚è€ƒèµ„æ–™

1. Howard, A. G., et al. (2017). MobileNets: Efficient Convolutional Neural Networks
2. Sandler, M., et al. (2018). MobileNetV2: Inverted Residuals and Linear Bottlenecks
3. Howard, A., et al. (2019). Searching for MobileNetV3
4. [æˆ‘çš„GitHubä»£ç ä»“åº“](https://github.com/YangCazz/DeepLearning)

---

*è¿™æ˜¯æ·±åº¦å­¦ä¹ ç»å…¸ç½‘ç»œç³»åˆ—çš„ç¬¬äº”ç¯‡ï¼Œä¸‹ä¸€ç¯‡å°†ä»‹ç»ShuffleNetç³»åˆ—ã€‚æ¬¢è¿å…³æ³¨ï¼*

