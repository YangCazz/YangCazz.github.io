---
layout: post
title: "FCNä¸UNetï¼šåŒ»å­¦å›¾åƒåˆ†å‰²çš„å¥ åŸºä¹‹ä½œ"
date: 2025-02-01
categories: [åŒ»å­¦å½±åƒ, å›¾åƒåˆ†å‰²]
tags: [æ·±åº¦å­¦ä¹ , UNet, FCN, åŒ»å­¦AI, è¯­ä¹‰åˆ†å‰²]
excerpt: "æ·±å…¥æ¢è®¨FCNå’ŒUNetä¸¤ä¸ªå¼€åˆ›æ€§ç½‘ç»œï¼Œç†è§£å…¨å·ç§¯ç½‘ç»œå’Œç¼–ç å™¨-è§£ç å™¨ç»“æ„å¦‚ä½•å¥ å®šç°ä»£åŒ»å­¦å›¾åƒåˆ†å‰²çš„åŸºç¡€ã€‚"
author: YangCazz
math: true
---

## ğŸ“‹ å¼•è¨€

åŒ»å­¦å›¾åƒåˆ†å‰²æ˜¯è®¡ç®—æœºè¾…åŠ©è¯Šæ–­ä¸­çš„æ ¸å¿ƒä»»åŠ¡ï¼Œæ—¨åœ¨ä»åŒ»å­¦å½±åƒï¼ˆå¦‚CTã€MRIã€Xå°„çº¿ç­‰ï¼‰ä¸­ç²¾ç¡®åˆ’åˆ†å‡ºæ„Ÿå…´è¶£åŒºåŸŸï¼ˆROIï¼‰ï¼Œå¦‚å™¨å®˜ã€ç—…ç¶æˆ–ç»„ç»‡ç»“æ„ã€‚ä¼ ç»Ÿæ–¹æ³•ä¾èµ–æ‰‹å·¥ç‰¹å¾å’Œå¤æ‚çš„å›¾åƒå¤„ç†æŠ€æœ¯ï¼Œä¸ä»…è€—æ—¶ä¸”ç²¾åº¦æœ‰é™ã€‚

2015å¹´ï¼Œä¸¤ä¸ªåˆ’æ—¶ä»£çš„ç½‘ç»œâ€”â€”**FCN**ï¼ˆFully Convolutional Networksï¼‰å’Œ**UNet**â€”â€”å½»åº•æ”¹å˜äº†è¿™ä¸€é¢†åŸŸï¼Œå¼€å¯äº†æ·±åº¦å­¦ä¹ åœ¨åŒ»å­¦å›¾åƒåˆ†å‰²ä¸­çš„åº”ç”¨æ–°çºªå…ƒã€‚

### ä¸ºä»€ä¹ˆåŒ»å­¦å›¾åƒåˆ†å‰²å¦‚æ­¤é‡è¦ï¼Ÿ

- **ç²¾å‡†è¯Šæ–­**ï¼šå‡†ç¡®åˆ†å‰²è‚¿ç˜¤è¾¹ç•Œè¾…åŠ©åˆ¶å®šæ²»ç–—æ–¹æ¡ˆ
- **æ‰‹æœ¯è§„åˆ’**ï¼š3Dé‡å»ºå™¨å®˜å¸®åŠ©å¤–ç§‘åŒ»ç”Ÿè§„åˆ’æ‰‹æœ¯è·¯å¾„
- **ç–—æ•ˆè¯„ä¼°**ï¼šé‡åŒ–ç—…ç¶å¤§å°å˜åŒ–ç›‘æµ‹æ²»ç–—æ•ˆæœ
- **ä¸´åºŠç ”ç©¶**ï¼šå¤§è§„æ¨¡æ•°æ®åˆ†ææ”¯æŒåŒ»å­¦ç ”ç©¶

### ä»åˆ†ç±»åˆ°åˆ†å‰²çš„æ¼”è¿›

æ·±åº¦å­¦ä¹ åœ¨å›¾åƒåˆ†ç±»ä»»åŠ¡ï¼ˆImageNetï¼‰ä¸Šå–å¾—å·¨å¤§æˆåŠŸåï¼Œç ”ç©¶è€…å¼€å§‹æ¢ç´¢å¦‚ä½•å°†å…¶åº”ç”¨äºæ›´ç²¾ç»†çš„åƒç´ çº§ä»»åŠ¡â€”â€”è¯­ä¹‰åˆ†å‰²ã€‚

**åˆ†ç±» vs. åˆ†å‰²**ï¼š
```
åˆ†ç±»ï¼ˆImage Classificationï¼‰ï¼š
è¾“å…¥ï¼šæ•´å¼ å›¾åƒ
è¾“å‡ºï¼šç±»åˆ«æ ‡ç­¾ (å¦‚ "çŒ«", "ç‹—")

åˆ†å‰²ï¼ˆSemantic Segmentationï¼‰ï¼š
è¾“å…¥ï¼šæ•´å¼ å›¾åƒ
è¾“å‡ºï¼šæ¯ä¸ªåƒç´ çš„ç±»åˆ«æ ‡ç­¾
```

---

## ğŸ¯ FCNï¼šå…¨å·ç§¯ç½‘ç»œçš„è¯ç”Ÿ

### è®ºæ–‡ä¿¡æ¯
- **æ ‡é¢˜**: Fully Convolutional Networks for Semantic Segmentation
- **ä½œè€…**: Jonathan Long, Evan Shelhamer, Trevor Darrell (UC Berkeley)
- **å‘è¡¨**: CVPR 2015
- **è®ºæ–‡é“¾æ¥**: [arXiv:1411.4038](https://arxiv.org/abs/1411.4038)
- **å®˜æ–¹ä»£ç **: [GitHub](https://github.com/shelhamer/fcn.berkeleyvision.org)

### æ ¸å¿ƒæ€æƒ³

**å…³é”®åˆ›æ–°**ï¼šå°†åˆ†ç±»ç½‘ç»œï¼ˆå¦‚VGGã€AlexNetï¼‰çš„å…¨è¿æ¥å±‚æ›¿æ¢ä¸ºå·ç§¯å±‚ï¼Œä½¿ç½‘ç»œèƒ½å¤Ÿæ¥å—ä»»æ„å°ºå¯¸çš„è¾“å…¥å¹¶è¾“å‡ºç©ºé—´åˆ†å‰²å›¾ã€‚

**Why "Fully Convolutional"?**

ä¼ ç»Ÿåˆ†ç±»ç½‘ç»œç»“æ„ï¼š
```
Input â†’ Conv layers â†’ FC layers â†’ Class scores
(HÃ—WÃ—3)  (ç‰¹å¾å›¾)      (å‘é‡)      (1Ã—1Ã—C)
```

FCNç»“æ„ï¼š
```
Input â†’ Conv layers â†’ Conv layers â†’ Pixel-wise prediction
(HÃ—WÃ—3)  (ä¸‹é‡‡æ ·)      (ä¸Šé‡‡æ ·)      (HÃ—WÃ—C)
```

### ç½‘ç»œæ¶æ„

FCNæå‡ºäº†ä¸‰ç§å˜ä½“ï¼š**FCN-32s**ã€**FCN-16s**ã€**FCN-8s**ï¼Œæ•°å­—è¡¨ç¤ºä¸Šé‡‡æ ·çš„æ­¥é•¿ã€‚

#### FCN-32sï¼ˆæœ€ç®€å•ç‰ˆæœ¬ï¼‰

```python
# ä¼ªä»£ç ç¤ºæ„
Input (HÃ—WÃ—3)
  â†“
VGG Conv layers (ä¸‹é‡‡æ ·32å€)
  â†“ Feature map (H/32 Ã— W/32 Ã— 4096)
  â†“
1Ã—1 Conv (é™ç»´åˆ°ç±»åˆ«æ•°C)
  â†“ (H/32 Ã— W/32 Ã— C)
  â†“
32Ã— Upsampling (è½¬ç½®å·ç§¯)
  â†“
Output (HÃ—WÃ—C)
```

#### FCN-16s å’Œ FCN-8sï¼ˆæ·»åŠ è·³è·ƒè¿æ¥ï¼‰

ä¸ºäº†æ¢å¤ç»†èŠ‚ï¼ŒFCN-16så’ŒFCN-8så¼•å…¥äº†**è·³è·ƒè¿æ¥**ï¼ˆSkip Connectionsï¼‰ï¼Œèåˆä¸åŒå±‚æ¬¡çš„ç‰¹å¾ã€‚

```
Pool3 (H/8 Ã— W/8) â”€â”€â”€â”€â”
                       â”œâ”€â†’ Fusion â†’ 8Ã— Upsample â†’ Output
Pool4 (H/16 Ã— W/16) â”€â”€â”¤
                       â”‚
Pool5 (H/32 Ã— W/32) â”€â”€â”˜
```

### æ•°å­¦å®šä¹‰

#### 1. è½¬ç½®å·ç§¯ï¼ˆTransposed Convolutionï¼‰

ä¹Ÿç§°ä¸ºåå·ç§¯ï¼ˆDeconvolutionï¼‰ï¼Œç”¨äºä¸Šé‡‡æ ·ç‰¹å¾å›¾ã€‚

è®¾è¾“å…¥ç‰¹å¾å›¾ \( X \in \mathbb{R}^{H \times W \times C} \)ï¼Œè½¬ç½®å·ç§¯çš„è¾“å‡ºä¸ºï¼š

$$
Y = f_{\text{deconv}}(X; W, s, p)
$$

å…¶ä¸­ï¼š
- \( W \) æ˜¯å·ç§¯æ ¸æƒé‡
- \( s \) æ˜¯æ­¥é•¿ï¼ˆstrideï¼‰
- \( p \) æ˜¯å¡«å……ï¼ˆpaddingï¼‰

è¾“å‡ºå°ºå¯¸è®¡ç®—ï¼š
$$
H_{\text{out}} = (H_{\text{in}} - 1) \times s + k - 2p
$$

**ç¤ºä¾‹**ï¼šæ­¥é•¿ä¸º2çš„3Ã—3è½¬ç½®å·ç§¯å¯ä»¥å°†ç‰¹å¾å›¾æ”¾å¤§2å€ã€‚

#### 2. è·³è·ƒè¿æ¥èåˆ

è®¾ä¸åŒå±‚çš„ç‰¹å¾å›¾ä¸º \( F_{\text{pool3}}, F_{\text{pool4}}, F_{\text{pool5}} \)ï¼Œèåˆæ–¹å¼ä¸ºï¼š

$$
F_{\text{fused}} = \text{Upsample}(F_{\text{pool5}}) + F_{\text{pool4}}
$$

é€æ­¥èåˆï¼š
$$
F_{\text{final}} = \text{Upsample}(F_{\text{fused}}) + F_{\text{pool3}}
$$

#### 3. æŸå¤±å‡½æ•°

åƒç´ çº§äº¤å‰ç†µæŸå¤±ï¼ˆPixel-wise Cross Entropyï¼‰ï¼š

$$
\mathcal{L} = -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{C} y_{i,c} \log(\hat{y}_{i,c})
$$

å…¶ä¸­ï¼š
- \( N \) æ˜¯åƒç´ æ€»æ•°
- \( C \) æ˜¯ç±»åˆ«æ•°
- \( y_{i,c} \) æ˜¯åƒç´  \( i \) çš„çœŸå®æ ‡ç­¾
- \( \hat{y}_{i,c} \) æ˜¯é¢„æµ‹æ¦‚ç‡

### FCNçš„å±€é™æ€§

1. **ç»†èŠ‚ä¸¢å¤±**ï¼šå³ä½¿æœ‰è·³è·ƒè¿æ¥ï¼Œ8å€ä¸‹é‡‡æ ·ä»ä¼šæŸå¤±ç»†èŠ‚
2. **è¾¹ç•Œæ¨¡ç³Š**ï¼šåˆ†å‰²è¾¹ç•Œä¸å¤Ÿç²¾ç¡®
3. **å°ç›®æ ‡å›°éš¾**ï¼šå¯¹å°å°ºå¯¸ç›®æ ‡åˆ†å‰²æ•ˆæœå·®
4. **è®¡ç®—æ•ˆç‡**ï¼šå…¨å·ç§¯å±‚å‚æ•°é‡è¾ƒå¤§

---

## ğŸ† UNetï¼šåŒ»å­¦å›¾åƒåˆ†å‰²çš„é‡Œç¨‹ç¢‘

### è®ºæ–‡ä¿¡æ¯
- **æ ‡é¢˜**: U-Net: Convolutional Networks for Biomedical Image Segmentation
- **ä½œè€…**: Olaf Ronneberger, Philipp Fischer, Thomas Brox (University of Freiburg)
- **å‘è¡¨**: MICCAI 2015
- **è®ºæ–‡é“¾æ¥**: [arXiv:1505.04597](https://arxiv.org/abs/1505.04597)
- **å®˜æ–¹ä»£ç **: 
  - [TensorFlowå®ç°](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)
  - [PyTorchå®ç°](https://github.com/milesial/Pytorch-UNet)

### ä¸ºä»€ä¹ˆUNetæ˜¯åŒ»å­¦å›¾åƒçš„å®Œç¾åŒ¹é…ï¼Ÿ

åŒ»å­¦å›¾åƒåˆ†å‰²é¢ä¸´ç‹¬ç‰¹æŒ‘æˆ˜ï¼š
1. **å°æ ·æœ¬é—®é¢˜**ï¼šåŒ»å­¦æ•°æ®æ ‡æ³¨æˆæœ¬é«˜ï¼Œæ•°æ®é‡æœ‰é™
2. **é«˜ç²¾åº¦è¦æ±‚**ï¼šä¸´åºŠåº”ç”¨éœ€è¦ç²¾ç¡®çš„åƒç´ çº§åˆ†å‰²
3. **ä¸Šä¸‹æ–‡é‡è¦**ï¼šéœ€è¦åŒæ—¶æ•æ‰å±€éƒ¨ç»†èŠ‚å’Œå…¨å±€ä¸Šä¸‹æ–‡
4. **å¤šå°ºåº¦ç‰¹å¾**ï¼šç—…ç¶å¤§å°å·®å¼‚å¤§ï¼Œéœ€è¦å¤šå°ºåº¦ä¿¡æ¯

**UNetçš„è®¾è®¡å®Œç¾è§£å†³äº†è¿™äº›é—®é¢˜ã€‚**

### æ ¸å¿ƒåˆ›æ–°

#### 1. å¯¹ç§°çš„Uå‹ç»“æ„

UNetå¾—åäºå…¶ç‹¬ç‰¹çš„Uå‹æ¶æ„ï¼š
```
        Contracting Path          Expanding Path
              (ç¼–ç å™¨)                (è§£ç å™¨)
                 
Input â”€â”€â†’ Convâ†’ Convâ†’ Pool â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Upâ†’ Convâ†’ Conv
  â†“                 â†“                             â†‘
572Ã—572           Pool                          Up
                   â†“         Bottleneck          â†‘
              Convâ†’Conv      (åº•éƒ¨)         Convâ†’Conv
                   â†“            â†“                â†‘
                  Pool    Convâ†’Conv            Up
                   â†“                            â†‘
              Convâ†’Conv â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Upâ†’ Convâ†’Conv
                   â†“                            â†‘
                  Pool                         Up
                   â†“                            â†‘
              Convâ†’Conv â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Upâ†’ Convâ†’Conv
                                                â†‘
                                           Output
                                         388Ã—388
```

**å·¦ä¾§ï¼ˆContracting Pathï¼‰**ï¼š
- é‡å¤åº”ç”¨ï¼š3Ã—3å·ç§¯ + ReLU + 2Ã—2æœ€å¤§æ± åŒ–
- æ¯æ¬¡ä¸‹é‡‡æ ·ï¼Œé€šé“æ•°ç¿»å€ï¼ˆ64 â†’ 128 â†’ 256 â†’ 512 â†’ 1024ï¼‰
- æ•æ‰ä¸Šä¸‹æ–‡ä¿¡æ¯

**å³ä¾§ï¼ˆExpanding Pathï¼‰**ï¼š
- é‡å¤åº”ç”¨ï¼š2Ã—2è½¬ç½®å·ç§¯ï¼ˆä¸Šé‡‡æ ·ï¼‰ + 3Ã—3å·ç§¯ + ReLU
- æ¯æ¬¡ä¸Šé‡‡æ ·ï¼Œé€šé“æ•°å‡åŠ
- æ¢å¤ç©ºé—´åˆ†è¾¨ç‡

#### 2. Skip Connectionsï¼ˆè·³è·ƒè¿æ¥ï¼‰

**è¿™æ˜¯UNetæœ€å…³é”®çš„åˆ›æ–°ï¼**

æ¯ä¸€å±‚çš„ç¼–ç å™¨ç‰¹å¾éƒ½è¢«**è£å‰ªå¹¶æ‹¼æ¥**åˆ°å¯¹åº”çš„è§£ç å™¨å±‚ï¼š

```python
# ä¼ªä»£ç 
def forward(x):
    # Encoder
    e1 = conv_block(x)      # 572Ã—572Ã—64
    e2 = down(e1)           # 280Ã—280Ã—128
    e3 = down(e2)           # 136Ã—136Ã—256
    e4 = down(e3)           # 64Ã—64Ã—512
    
    # Bottleneck
    bottleneck = down(e4)   # 28Ã—28Ã—1024
    
    # Decoder with skip connections
    d4 = up(bottleneck, e4) # 64Ã—64Ã—512  (æ‹¼æ¥e4)
    d3 = up(d4, e3)         # 136Ã—136Ã—256 (æ‹¼æ¥e3)
    d2 = up(d3, e2)         # 280Ã—280Ã—128 (æ‹¼æ¥e2)
    d1 = up(d2, e1)         # 572Ã—572Ã—64  (æ‹¼æ¥e1)
    
    output = final_conv(d1) # 388Ã—388Ã—2
    return output
```

**ä¸ºä»€ä¹ˆéœ€è¦è·³è·ƒè¿æ¥ï¼Ÿ**

1. **ç¼“è§£æ¢¯åº¦æ¶ˆå¤±**ï¼šä¸ºæ·±å±‚ç½‘ç»œæä¾›æ¢¯åº¦å¿«é€Ÿé€šé“
2. **èåˆå¤šå°ºåº¦ç‰¹å¾**ï¼šä½å±‚ç‰¹å¾ï¼ˆç»†èŠ‚ï¼‰+ é«˜å±‚ç‰¹å¾ï¼ˆè¯­ä¹‰ï¼‰
3. **ç²¾ç¡®å®šä½**ï¼šç¼–ç å™¨çš„ç©ºé—´ä¿¡æ¯å¸®åŠ©è§£ç å™¨æ¢å¤ç»†èŠ‚

### ç½‘ç»œæ¶æ„è¯¦è§£

#### åŸºæœ¬æ„å»ºå—

```python
class DoubleConv(nn.Module):
    """ä¸¤ä¸ª3Ã—3å·ç§¯å±‚"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, kernel_size=3),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        return self.conv(x)

class Down(nn.Module):
    """ä¸‹é‡‡æ ·ï¼šMaxPool + DoubleConv"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.pool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )
    
    def forward(self, x):
        return self.pool_conv(x)

class Up(nn.Module):
    """ä¸Šé‡‡æ ·ï¼šConvTranspose + Concat + DoubleConv"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, 
                                      kernel_size=2, stride=2)
        self.conv = DoubleConv(in_channels, out_channels)
    
    def forward(self, x1, x2):
        x1 = self.up(x1)
        
        # è£å‰ªx2ä»¥åŒ¹é…x1çš„å°ºå¯¸
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]
        x2 = F.pad(x2, [-diffX // 2, -diffX - diffX // 2,
                       -diffY // 2, -diffY - diffY // 2])
        
        # æ‹¼æ¥
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)
```

#### å®Œæ•´UNet

```python
class UNet(nn.Module):
    def __init__(self, n_channels=3, n_classes=2):
        super(UNet, self).__init__()
        
        # Encoder
        self.inc = DoubleConv(n_channels, 64)
        self.down1 = Down(64, 128)
        self.down2 = Down(128, 256)
        self.down3 = Down(256, 512)
        self.down4 = Down(512, 1024)
        
        # Decoder
        self.up1 = Up(1024, 512)
        self.up2 = Up(512, 256)
        self.up3 = Up(256, 128)
        self.up4 = Up(128, 64)
        
        # Output
        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)
    
    def forward(self, x):
        # Encoder
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)
        
        # Decoder with skip connections
        x = self.up1(x5, x4)
        x = self.up2(x, x3)
        x = self.up3(x, x2)
        x = self.up4(x, x1)
        
        # Output
        logits = self.outc(x)
        return logits
```

### æ•°å­¦å®šä¹‰

#### 1. ç¼–ç å™¨è·¯å¾„

è®¾è¾“å…¥å›¾åƒ \( X^{(0)} \in \mathbb{R}^{H \times W \times C} \)ï¼Œç¼–ç å™¨çš„ç¬¬ \( i \) å±‚è¾“å‡ºä¸ºï¼š

$$
X^{(i)} = \text{Pool}(\text{ReLU}(W_i^{(2)} * \text{ReLU}(W_i^{(1)} * X^{(i-1)})))
$$

å…¶ä¸­ \( * \) è¡¨ç¤ºå·ç§¯æ“ä½œã€‚

**ç‰¹å¾å›¾å°ºå¯¸å˜åŒ–**ï¼š
$$
H^{(i)} = \frac{H^{(i-1)}}{2}, \quad C^{(i)} = 2 \times C^{(i-1)}
$$

#### 2. è§£ç å™¨è·¯å¾„

è§£ç å™¨çš„ç¬¬ \( j \) å±‚è¾“å‡ºä¸ºï¼š

$$
Y^{(j)} = \text{Conv}([Z^{(j)}, X^{(n-j)}])
$$

å…¶ä¸­ï¼š
- \( Z^{(j)} = \text{Upsample}(Y^{(j-1)}) \) æ˜¯ä¸Šé‡‡æ ·ç»“æœ
- \( [ \cdot, \cdot ] \) è¡¨ç¤ºé€šé“ç»´åº¦çš„æ‹¼æ¥ï¼ˆconcatenationï¼‰
- \( X^{(n-j)} \) æ˜¯å¯¹åº”ç¼–ç å™¨å±‚çš„ç‰¹å¾ï¼ˆç»è¿‡è£å‰ªï¼‰

**ä¸Šé‡‡æ ·å…¬å¼**ï¼š
$$
Z^{(j)} = f_{\text{up}}(Y^{(j-1)}; W_{\text{up}})
$$

å…¶ä¸­ \( f_{\text{up}} \) æ˜¯2Ã—2è½¬ç½®å·ç§¯ï¼Œæ­¥é•¿ä¸º2ã€‚

#### 3. æŸå¤±å‡½æ•°

UNetåŸè®ºæ–‡ä½¿ç”¨**åŠ æƒäº¤å‰ç†µæŸå¤±**ï¼Œå¯¹è¾¹ç•Œåƒç´ èµ‹äºˆæ›´é«˜æƒé‡ï¼š

$$
\mathcal{L} = -\sum_{x \in \Omega} w(x) \log(p_{\ell(x)}(x))
$$

å…¶ä¸­ï¼š
- \( \Omega \) æ˜¯å›¾åƒåŸŸ
- \( \ell(x) \) æ˜¯åƒç´  \( x \) çš„çœŸå®æ ‡ç­¾
- \( p_{\ell(x)}(x) \) æ˜¯é¢„æµ‹è¯¥æ ‡ç­¾çš„æ¦‚ç‡
- \( w(x) \) æ˜¯æƒé‡å›¾ï¼Œç”¨äºå¼ºè°ƒè¾¹ç•Œ

**æƒé‡å›¾è®¡ç®—**ï¼š
$$
w(x) = w_c(x) + w_0 \cdot \exp\left(-\frac{(d_1(x) + d_2(x))^2}{2\sigma^2}\right)
$$

å…¶ä¸­ï¼š
- \( w_c(x) \) æ˜¯ç±»åˆ«å¹³è¡¡æƒé‡
- \( d_1(x) \) æ˜¯åˆ°æœ€è¿‘ç»†èƒè¾¹ç•Œçš„è·ç¦»
- \( d_2(x) \) æ˜¯åˆ°ç¬¬äºŒè¿‘è¾¹ç•Œçš„è·ç¦»
- \( w_0 = 10, \sigma \approx 5 \) åƒç´ 

**ç°ä»£å®è·µä¸­å¸¸ç”¨Dice Loss**ï¼š

$$
\mathcal{L}_{\text{Dice}} = 1 - \frac{2 \sum_{i=1}^{N} p_i g_i + \epsilon}{\sum_{i=1}^{N} p_i + \sum_{i=1}^{N} g_i + \epsilon}
$$

å…¶ä¸­ \( p_i \) æ˜¯é¢„æµ‹ï¼Œ\( g_i \) æ˜¯çœŸå€¼ï¼Œ\( \epsilon \) æ˜¯å¹³æ»‘é¡¹ã€‚

### æ•°æ®å¢å¼ºç­–ç•¥

**UNetæˆåŠŸçš„å…³é”®**ï¼šå¼ºå¤§çš„æ•°æ®å¢å¼ºï¼Œä½¿å¾—å³ä½¿åœ¨å°æ ·æœ¬æƒ…å†µä¸‹ä¹Ÿèƒ½è®­ç»ƒå‡ºé²æ£’çš„æ¨¡å‹ã€‚

```python
# å¸¸ç”¨å¢å¼ºæ–¹æ³•
transforms = [
    # å‡ ä½•å˜æ¢
    RandomRotation(degrees=30),
    RandomHorizontalFlip(p=0.5),
    RandomVerticalFlip(p=0.5),
    RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),
    ElasticTransform(alpha=50, sigma=5),  # å¼¹æ€§å½¢å˜
    
    # å¼ºåº¦å˜æ¢
    RandomBrightnessContrast(p=0.5),
    RandomGamma(p=0.5),
    
    # å™ªå£°
    GaussNoise(var_limit=(10.0, 50.0), p=0.3),
]
```

**å¼¹æ€§å½¢å˜**ï¼ˆElastic Deformationï¼‰å¯¹åŒ»å­¦å›¾åƒå°¤ä¸ºé‡è¦ï¼š

$$
T(x, y) = (x + \alpha \cdot \Delta x, y + \alpha \cdot \Delta y)
$$

å…¶ä¸­ \( \Delta x, \Delta y \) æ˜¯é«˜æ–¯å¹³æ»‘çš„éšæœºä½ç§»åœºã€‚

---

## ğŸ“Š FCN vs. UNet å¯¹æ¯”

| ç‰¹æ€§ | FCN | UNet |
|-----|-----|------|
| **æå‡ºæ—¶é—´** | 2015.3 (CVPR) | 2015.5 (MICCAI) |
| **åˆå§‹ç›®æ ‡** | é€šç”¨è¯­ä¹‰åˆ†å‰² | åŒ»å­¦å›¾åƒåˆ†å‰² |
| **æ¶æ„** | éå¯¹ç§°ï¼ˆç¼–ç å™¨ä¸ºä¸»ï¼‰ | å¯¹ç§°ï¼ˆUå‹ï¼‰ |
| **è·³è·ƒè¿æ¥** | ç›¸åŠ ï¼ˆAdditionï¼‰ | æ‹¼æ¥ï¼ˆConcatenationï¼‰ |
| **ç‰¹å¾èåˆ** | å•æ¬¡èåˆ | æ¯ä¸€å±‚éƒ½èåˆ |
| **ç»†èŠ‚ä¿ç•™** | è¾ƒå¼± | å¼º |
| **å‚æ•°é‡** | ç›¸å¯¹è¾ƒå¤§ | é€‚ä¸­ |
| **åŒ»å­¦åº”ç”¨** | è¾ƒå°‘ | **æå…¶å¹¿æ³›** |
| **åç»­å½±å“** | å¼€åˆ›å…¨å·ç§¯èŒƒå¼ | **åŒ»å­¦åˆ†å‰²æ ‡å‡†** |

### æ€§èƒ½å¯¹æ¯”ï¼ˆåœ¨ISBIç»†èƒåˆ†å‰²æŒ‘æˆ˜ä¸Šï¼‰

```
æ•°æ®é›†ï¼š30å¼ è®­ç»ƒå›¾åƒï¼ˆ512Ã—512ï¼‰

æ–¹æ³•          IOU    Dice   è¾¹ç•Œç²¾åº¦
----------------------------------------
ä¼ ç»Ÿæ–¹æ³•       0.77   0.87   ä¸­ç­‰
FCN-8s        0.83   0.91   è¾ƒå¥½
UNet          0.92   0.96   **ä¼˜ç§€**
```

---

## ğŸ¯ å®é™…åº”ç”¨åœºæ™¯

### 1. ç»†èƒåˆ†å‰²
- **ä»»åŠ¡**ï¼šåˆ†å‰²æ˜¾å¾®é•œå›¾åƒä¸­çš„ç»†èƒæ ¸
- **æŒ‘æˆ˜**ï¼šç»†èƒå¯†é›†ã€è¾¹ç•Œæ¨¡ç³Š
- **UNetä¼˜åŠ¿**ï¼šæƒé‡å›¾å¼ºè°ƒè¾¹ç•Œ

### 2. è„‘è‚¿ç˜¤åˆ†å‰²ï¼ˆBraTSï¼‰
- **ä»»åŠ¡**ï¼šä»MRIä¸­åˆ†å‰²è‚¿ç˜¤åŒºåŸŸ
- **æŒ‘æˆ˜**ï¼šå¤šæ¨¡æ€è¾“å…¥ï¼ˆT1ã€T2ã€FLAIRï¼‰
- **UNetä¼˜åŠ¿**ï¼šå¤šé€šé“è¾“å…¥æ”¯æŒ

### 3. å™¨å®˜åˆ†å‰²
- **ä»»åŠ¡**ï¼šCTä¸­çš„è‚è„ã€è‚¾è„ã€è„¾è„åˆ†å‰²
- **æŒ‘æˆ˜**ï¼šå™¨å®˜å¤§å°å·®å¼‚å¤§
- **UNetä¼˜åŠ¿**ï¼šå¤šå°ºåº¦ç‰¹å¾èåˆ

### 4. ç—…ç†å›¾åƒåˆ†å‰²
- **ä»»åŠ¡**ï¼šç»„ç»‡ç—…ç†å­¦å›¾åƒä¸­çš„è…ºä½“åˆ†å‰²
- **æŒ‘æˆ˜**ï¼šé«˜åˆ†è¾¨ç‡ã€å½¢æ€å¤šæ ·
- **UNetä¼˜åŠ¿**ï¼šå¯å¤„ç†å¤§å›¾åƒ

---

## ğŸ’¡ å®ç°æŠ€å·§ä¸æœ€ä½³å®è·µ

### 1. è¾“å…¥å°ºå¯¸é€‰æ‹©

**åŸå§‹UNet**ï¼š572Ã—572 â†’ 388Ã—388ï¼ˆValidå·ç§¯å¯¼è‡´å°ºå¯¸å‡å°ï¼‰

**ç°ä»£å®è·µ**ï¼šä½¿ç”¨**Sameå·ç§¯**ï¼ˆpadding=1ï¼‰ä¿æŒå°ºå¯¸ï¼š

```python
nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)  # Sameå·ç§¯
```

æ¨èè¾“å…¥å°ºå¯¸ï¼š
- 2Dåˆ‡ç‰‡ï¼š256Ã—256ã€512Ã—512
- å¤§å›¾åƒï¼šä½¿ç”¨æ»‘åŠ¨çª—å£æˆ–Patch-basedæ–¹æ³•

### 2. æŸå¤±å‡½æ•°é€‰æ‹©

```python
# ç»„åˆæŸå¤±
class CombinedLoss(nn.Module):
    def __init__(self, alpha=0.5):
        super().__init__()
        self.alpha = alpha
        self.ce = nn.CrossEntropyLoss()
        self.dice = DiceLoss()
    
    def forward(self, pred, target):
        return self.alpha * self.ce(pred, target) + \
               (1 - self.alpha) * self.dice(pred, target)
```

### 3. æ‰¹å½’ä¸€åŒ–ï¼ˆBatch Normalizationï¼‰

ç°ä»£UNeté€šå¸¸æ·»åŠ BNå±‚ï¼š

```python
self.conv = nn.Sequential(
    nn.Conv2d(in_ch, out_ch, 3, padding=1),
    nn.BatchNorm2d(out_ch),  # æ·»åŠ BN
    nn.ReLU(inplace=True),
    nn.Conv2d(out_ch, out_ch, 3, padding=1),
    nn.BatchNorm2d(out_ch),
    nn.ReLU(inplace=True)
)
```

### 4. æ·±åº¦ç›‘ç£ï¼ˆDeep Supervisionï¼‰

åœ¨ä¸­é—´å±‚æ·»åŠ è¾…åŠ©æŸå¤±ï¼š

```python
# åœ¨æ¯ä¸ªä¸Šé‡‡æ ·é˜¶æ®µè¾“å‡ºé¢„æµ‹
aux_output1 = aux_head(d4)  # ä½åˆ†è¾¨ç‡é¢„æµ‹
aux_output2 = aux_head(d3)
final_output = final_head(d1)  # æœ€ç»ˆé¢„æµ‹

# æ€»æŸå¤±
loss = loss_fn(final_output, target) + \
       0.3 * loss_fn(aux_output1, target_downsample) + \
       0.3 * loss_fn(aux_output2, target_downsample)
```

---

## ğŸ”¬ è®­ç»ƒç»†èŠ‚

### è¶…å‚æ•°é…ç½®

```python
# ä¼˜åŒ–å™¨
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

# å­¦ä¹ ç‡è°ƒåº¦
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='max', factor=0.5, patience=5, verbose=True
)

# è®­ç»ƒé…ç½®
config = {
    'batch_size': 8,
    'epochs': 100,
    'learning_rate': 1e-4,
    'weight_decay': 1e-5,
    'early_stopping_patience': 15,
}
```

### è®­ç»ƒå¾ªç¯

```python
for epoch in range(num_epochs):
    model.train()
    for images, masks in train_loader:
        optimizer.zero_grad()
        
        # å‰å‘ä¼ æ’­
        outputs = model(images)
        loss = criterion(outputs, masks)
        
        # åå‘ä¼ æ’­
        loss.backward()
        optimizer.step()
    
    # éªŒè¯
    dice_score = validate(model, val_loader)
    scheduler.step(dice_score)
    
    # æ—©åœ
    if early_stopping(dice_score):
        break
```

---

## ğŸ“ˆ æ€§èƒ½è¯„ä¼°æŒ‡æ ‡

### 1. Diceç³»æ•°ï¼ˆæœ€å¸¸ç”¨ï¼‰

$$
\text{Dice} = \frac{2|A \cap B|}{|A| + |B|} = \frac{2TP}{2TP + FP + FN}
$$

```python
def dice_coef(pred, target, smooth=1e-5):
    pred = pred.view(-1)
    target = target.view(-1)
    intersection = (pred * target).sum()
    return (2. * intersection + smooth) / \
           (pred.sum() + target.sum() + smooth)
```

### 2. IoUï¼ˆJaccard Indexï¼‰

$$
\text{IoU} = \frac{|A \cap B|}{|A \cup B|} = \frac{TP}{TP + FP + FN}
$$

### 3. Hausdorffè·ç¦»ï¼ˆè¾¹ç•Œè´¨é‡ï¼‰

$$
d_H(A, B) = \max\{\sup_{a \in A} \inf_{b \in B} d(a,b), \sup_{b \in B} \inf_{a \in A} d(a,b)\}
$$

---

## ğŸ“ æ€»ç»“ä¸å±•æœ›

### FCNçš„è´¡çŒ®
1. âœ… å¼€åˆ›äº†**å…¨å·ç§¯**èŒƒå¼ï¼Œä¸ºåç»­ç ”ç©¶å¥ å®šåŸºç¡€
2. âœ… æå‡º**è½¬ç½®å·ç§¯**ç”¨äºä¸Šé‡‡æ ·
3. âœ… å¼•å…¥**è·³è·ƒè¿æ¥**èåˆå¤šå°ºåº¦ç‰¹å¾
4. âŒ ä½†ç»†èŠ‚æ¢å¤èƒ½åŠ›æœ‰é™ï¼Œè¾¹ç•Œæ¨¡ç³Š

### UNetçš„ä¼˜åŠ¿
1. âœ… **å¯¹ç§°çš„Uå‹ç»“æ„**ï¼Œå®Œç¾å¹³è¡¡ç¼–ç å’Œè§£ç 
2. âœ… **æ‹¼æ¥å¼è·³è·ƒè¿æ¥**ï¼Œæœ€å¤§åŒ–ç‰¹å¾åˆ©ç”¨
3. âœ… **å°æ ·æœ¬å‹å¥½**ï¼Œé€‚åˆåŒ»å­¦æ•°æ®
4. âœ… **ç®€å•é«˜æ•ˆ**ï¼Œæ˜“äºå®ç°å’Œè®­ç»ƒ
5. âœ… **é€šç”¨æ€§å¼º**ï¼Œæˆä¸ºåŒ»å­¦åˆ†å‰²çš„äº‹å®æ ‡å‡†

### ä¸ºä»€ä¹ˆUNetå¦‚æ­¤æˆåŠŸï¼Ÿ

> "UNetçš„æˆåŠŸä¸åœ¨äºå¤æ‚çš„æŠ€å·§ï¼Œè€Œåœ¨äºç®€æ´ä¼˜é›…çš„è®¾è®¡å®Œç¾å¥‘åˆäº†åŒ»å­¦å›¾åƒåˆ†å‰²çš„éœ€æ±‚ã€‚" 

**å…³é”®å› ç´ **ï¼š
- **æ¶æ„ç®€å•**ï¼šå®¹æ˜“ç†è§£å’Œå®ç°
- **ç‰¹å¾èåˆ**ï¼šæœ‰æ•ˆç»“åˆä½å±‚ç»†èŠ‚å’Œé«˜å±‚è¯­ä¹‰
- **æ•°æ®å¢å¼º**ï¼šå……åˆ†åˆ©ç”¨æœ‰é™æ•°æ®
- **çµæ´»æ‰©å±•**ï¼šæ˜“äºæ”¹è¿›å’Œå®šåˆ¶

### åç»­å‘å±•æ–¹å‘

UNetä¸ºåç»­ç ”ç©¶æ‰“å¼€äº†å¤§é—¨ï¼š
- **æ®‹å·®è¿æ¥**ï¼šResUNetï¼ˆ2017ï¼‰
- **æ³¨æ„åŠ›æœºåˆ¶**ï¼šAttention UNetï¼ˆ2018ï¼‰
- **å¯†é›†è¿æ¥**ï¼šUNet++ï¼ˆ2018ï¼‰ã€UNet 3+ï¼ˆ2020ï¼‰
- **Transformer**ï¼šTransUNetï¼ˆ2021ï¼‰ã€Swin-UNetï¼ˆ2021ï¼‰
- **3Dæ‰©å±•**ï¼šV-Netï¼ˆ2016ï¼‰ã€3D UNet

> **ä¸‹ä¸€ç¯‡é¢„å‘Š**ï¼š[V-Netï¼š3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„çªç ´](/2025/02/05/vnet-3d-segmentation/) - æ¢ç´¢å¦‚ä½•å°†UNetæ‰©å±•åˆ°3DåŸŸï¼Œå¼•å…¥æ®‹å·®è¿æ¥å’ŒDice Lossã€‚

---

## ğŸ“š å‚è€ƒèµ„æ–™

### è®ºæ–‡
1. [FCN] Long, J., Shelhamer, E., & Darrell, T. (2015). Fully convolutional networks for semantic segmentation. *CVPR*.
2. [UNet] Ronneberger, O., Fischer, P., & Brox, T. (2015). U-net: Convolutional networks for biomedical image segmentation. *MICCAI*.

### ä»£ç å®ç°
- [FCNå®˜æ–¹ä»£ç ](https://github.com/shelhamer/fcn.berkeleyvision.org) - Caffe
- [UNet PyTorch](https://github.com/milesial/Pytorch-UNet) - æœ€æµè¡Œçš„PyTorchå®ç°
- [UNetå®˜æ–¹é¡µé¢](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)

### æ•°æ®é›†
- [ISBI Cell Tracking Challenge](http://celltrackingchallenge.net/)
- [Data Science Bowl 2018](https://www.kaggle.com/c/data-science-bowl-2018) - ç»†èƒæ ¸åˆ†å‰²

### æ‰©å±•é˜…è¯»
- [A survey on U-Net architectures](https://arxiv.org/abs/2004.04955)
- [Medical Image Segmentation using Deep Learning: A Survey](https://arxiv.org/abs/2009.13120)

---

## ğŸ”— ç³»åˆ—æ–‡ç« å¯¼èˆª

**åŒ»å­¦å½±åƒåˆ†å‰²ç½‘ç»œç³»åˆ—**ï¼š

1. ğŸ“ **FCNä¸UNetï¼šåŒ»å­¦åˆ†å‰²çš„å¥ åŸºä¹‹ä½œ**ï¼ˆæœ¬æ–‡ï¼‰
2. [V-Netï¼š3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„çªç ´](/2025/02/05/vnet-3d-segmentation/)
3. [Attention UNetï¼šæ³¨æ„åŠ›æœºåˆ¶çš„å¼•å…¥](/2025/02/10/attention-unet/)
4. [UNet++/UNet 3+ï¼šå¯†é›†è¿æ¥çš„åŠ›é‡](/2025/02/15/unet-plus-series/)
5. [TransUNetï¼šCNNä¸Transformerçš„èåˆ](/2025/02/20/transunet-hybrid-architecture/)
6. [Swin-UNetï¼šå±‚çº§åŒ–Transformer](/2025/02/25/swin-unet-hierarchical-transformer/)
7. [SAMä¸MedSAMï¼šåŸºç¡€æ¨¡å‹çš„åŒ»å­¦åº”ç”¨](/2025/03/05/sam-segment-anything/)
8. [nnU-Netï¼šè‡ªé€‚åº”åŒ»å­¦åˆ†å‰²æ¡†æ¶](/2025/03/15/nnunet-self-configuring-framework/)

---

*æœ¬æ–‡æ˜¯åŒ»å­¦å½±åƒåˆ†å‰²ç½‘ç»œç³»åˆ—çš„å¼€ç¯‡ï¼Œåç»­å°†æ·±å…¥æ¢è®¨å„ä¸ªç»å…¸ç½‘ç»œçš„åŸç†ã€å®ç°å’Œåº”ç”¨ã€‚æ¬¢è¿å…³æ³¨ï¼*

