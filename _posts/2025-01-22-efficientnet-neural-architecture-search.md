---
layout: post
title: "EfficientNetï¼šç¥ç»æ¶æ„æœç´¢çš„è‰ºæœ¯"
date: 2025-01-22
categories: [æ·±åº¦å­¦ä¹ , ç»å…¸ç½‘ç»œ]
tags: [CNN, EfficientNet, NAS, å¤åˆç¼©æ”¾, PyTorch]
excerpt: "æ·±å…¥è§£æGoogleçš„EfficientNetç³»åˆ—ï¼ˆV1-V2ï¼‰ã€‚æ¢ç´¢ç½‘ç»œæ·±åº¦ã€å®½åº¦ã€åˆ†è¾¨ç‡ä¸‰ç»´åº¦çš„å¤åˆç¼©æ”¾ç­–ç•¥ï¼Œä»¥åŠå¦‚ä½•é€šè¿‡NASæ‰¾åˆ°æœ€ä¼˜ç½‘ç»œæ¶æ„ã€‚"
---

# EfficientNetï¼šç¥ç»æ¶æ„æœç´¢çš„è‰ºæœ¯

## å¼•è¨€

åœ¨ä¹‹å‰çš„æ‰‹å·¥è®¾è®¡ç½‘ç»œä¸­ï¼ˆAlexNetã€VGGã€ResNetç­‰ï¼‰ï¼Œç»å¸¸æœ‰äººé—®ï¼š
* ä¸ºä»€ä¹ˆè¾“å…¥å›¾åƒåˆ†è¾¨ç‡è¦å›ºå®šä¸º224ï¼Ÿ
* ä¸ºä»€ä¹ˆå·ç§¯çš„ä¸ªæ•°è¦è®¾ç½®ä¸ºè¿™ä¸ªå€¼ï¼Ÿ
* ä¸ºä»€ä¹ˆç½‘ç»œçš„æ·±åº¦è®¾ä¸ºè¿™ä¹ˆæ·±ï¼Ÿ

å¦‚æœä½ é—®è®¾è®¡è€…ï¼Œä¼°è®¡å›å¤å°±å››ä¸ªå­—â€”â€”**å·¥ç¨‹ç»éªŒ**ã€‚

è€ŒEfficientNetåˆ™ç”¨**ç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰**æŠ€æœ¯æ¥ç³»ç»Ÿæ€§åœ°æœç´¢ç½‘ç»œçš„**å›¾åƒè¾“å…¥åˆ†è¾¨ç‡r**ã€**ç½‘ç»œæ·±åº¦depth**ä»¥åŠ**é€šé“å®½åº¦width**ä¸‰ä¸ªå‚æ•°çš„åˆç†åŒ–é…ç½®ã€‚

## ç³»åˆ—æ¦‚è§ˆ

### è®ºæ–‡åˆ—è¡¨

* **[2019] EfficientNet V1**ï¼š[EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](https://arxiv.org/abs/1905.11946)
* **[2021] EfficientNet V2**ï¼š[EfficientNetV2: Smaller Models and Faster Training](https://arxiv.org/abs/2104.00298)

## 1. EfficientNet V1 (2019)

### æ ¸å¿ƒé—®é¢˜

å¦‚ä½•ç³»ç»Ÿæ€§åœ°æ‰©å±•ç½‘ç»œè§„æ¨¡ä»¥æå‡æ€§èƒ½ï¼Ÿ

### ä¸‰ä¸ªç»´åº¦çš„å½±å“

![EfficientNet V1](/assets/images/deep-learning/EfficientNet_v1_SE_Inverted_Residual.png)

#### ç»´åº¦1ï¼šæ·±åº¦ï¼ˆDepthï¼‰

**å¢åŠ ç½‘ç»œæ·±åº¦**ï¼š

âœ… **ä¼˜ç‚¹**ï¼š
* è·å¾—æ›´ä¸°å¯Œã€å¤æ‚çš„ç‰¹å¾
* æ›´å¥½çš„è¿ç§»æ€§å’Œé²æ£’æ€§
* èƒ½å¤Ÿæ›´å¥½åœ°åº”ç”¨åˆ°å…¶å®ƒä»»åŠ¡

âŒ **ç¼ºç‚¹**ï¼š
* è¿‡æ·±ä¼šæ¢¯åº¦æ¶ˆå¤±
* è®­ç»ƒå›°éš¾
* å®¹æ˜“è¿‡æ‹Ÿåˆ

#### ç»´åº¦2ï¼šå®½åº¦ï¼ˆWidthï¼‰

**å¢åŠ ç½‘ç»œå®½åº¦**ï¼ˆé€šé“æ•°ï¼‰ï¼š

âœ… **ä¼˜ç‚¹**ï¼š
* è·å¾—ç²’åº¦æ›´é«˜çš„ç‰¹å¾
* æ›´å¤šä¿¡æ¯é‡ï¼Œæ›´å®¹æ˜“è®­ç»ƒ
* æ•è·æ›´ç»†ç²’åº¦çš„æ¨¡å¼

âŒ **ç¼ºç‚¹**ï¼š
* å®½åº¦å¾ˆå¤§ä½†æ·±åº¦è¿‡æµ…çš„ç½‘ç»œéš¾ä»¥å­¦åˆ°æ›´æ·±å±‚æ¬¡çš„ç‰¹å¾
* æ€§èƒ½æå‡å¾ˆå¿«é¥±å’Œ

#### ç»´åº¦3ï¼šåˆ†è¾¨ç‡ï¼ˆResolutionï¼‰

**å¢åŠ è¾“å…¥åˆ†è¾¨ç‡**ï¼š

âœ… **ä¼˜ç‚¹**ï¼š
* æ½œåœ¨è·å¾—æ›´é«˜ç²’åº¦çš„Feature Maps
* æ•è·æ›´ç»†èŠ‚çš„æ¨¡å¼
* å¯¹å°ç›®æ ‡æ›´å‹å¥½

âŒ **ç¼ºç‚¹**ï¼š
* è¿‡é«˜çš„åˆ†è¾¨ç‡ï¼Œæ”¶ç›Šé€’å‡
* è®¡ç®—é‡æ€¥å‰§å¢åŠ 

### å¤åˆç¼©æ”¾ç­–ç•¥

**æ ¸å¿ƒæ€æƒ³**ï¼š**åŒæ—¶**ä¼˜åŒ–æ·±åº¦ã€å®½åº¦å’Œåˆ†è¾¨ç‡ã€‚

#### æ•°å­¦è¡¨è¾¾

$$
\text{depth}: d = \alpha^{\phi}
$$

$$
\text{width}: w = \beta^{\phi}
$$

$$
\text{resolution}: r = \gamma^{\phi}
$$

çº¦æŸæ¡ä»¶ï¼š
$$
\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2
$$

$$
\alpha \geq 1, \beta \geq 1, \gamma \geq 1
$$

å…¶ä¸­ï¼š
* \(\phi\)ï¼šå¤åˆç³»æ•°ï¼ˆç”¨æˆ·æŒ‡å®šï¼‰
* \(\alpha, \beta, \gamma\)ï¼šé€šè¿‡ç½‘æ ¼æœç´¢å¾—åˆ°

#### ä¸ºä»€ä¹ˆæ˜¯è¿™ä¸ªçº¦æŸï¼Ÿ

* **æ·±åº¦åŠ å€**ï¼šè®¡ç®—é‡çº¦ä¸º2å€ï¼ˆ\(\alpha\)ï¼‰
* **å®½åº¦åŠ å€**ï¼šè®¡ç®—é‡çº¦ä¸º4å€ï¼ˆ\(\beta^2\)ï¼‰  
* **åˆ†è¾¨ç‡åŠ å€**ï¼šè®¡ç®—é‡çº¦ä¸º4å€ï¼ˆ\(\gamma^2\)ï¼‰

çº¦æŸç¡®ä¿æ€»è®¡ç®—é‡çº¦ä¸º \(2^{\phi}\) å€ã€‚

### MBConv Block

![MBConv Block](/assets/images/deep-learning/EfficientNet_v1_SE_Inverted_Residual_2.png)

EfficientNetåŸºäº**MBConv**ï¼ˆMobile Inverted Bottleneck Convolutionï¼‰ï¼š

```python
class MBConvBlock(nn.Module):
    """MBConvæ¨¡å— = é€†æ®‹å·® + SEæ³¨æ„åŠ›"""
    def __init__(self, in_channels, out_channels, expand_ratio, 
                 kernel_size, stride, se_ratio=0.25):
        super(MBConvBlock, self).__init__()
        
        hidden_dim = in_channels * expand_ratio
        self.use_residual = stride == 1 and in_channels == out_channels
        
        layers = []
        
        # 1. Expansion (å‡ç»´)
        if expand_ratio != 1:
            layers.append(nn.Sequential(
                nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False),
                nn.BatchNorm2d(hidden_dim),
                nn.Swish()  # Swishæ¿€æ´»å‡½æ•°
            ))
        
        # 2. Depthwiseå·ç§¯
        layers.append(nn.Sequential(
            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=kernel_size, 
                     stride=stride, padding=kernel_size//2, 
                     groups=hidden_dim, bias=False),
            nn.BatchNorm2d(hidden_dim),
            nn.Swish()
        ))
        
        # 3. SEæ³¨æ„åŠ›æ¨¡å—
        if se_ratio is not None:
            squeeze_channels = max(1, int(in_channels * se_ratio))
            layers.append(SEBlock(hidden_dim, squeeze_channels))
        
        # 4. Projection (é™ç»´)
        layers.append(nn.Sequential(
            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels)
            # æ³¨æ„ï¼šæ²¡æœ‰æ¿€æ´»å‡½æ•°ï¼ˆLinear Bottleneckï¼‰
        ))
        
        self.conv = nn.Sequential(*layers)
        self.dropout = nn.Dropout(p=0.2) if self.use_residual else None
    
    def forward(self, x):
        if self.use_residual:
            return x + self.dropout(self.conv(x))
        else:
            return self.conv(x)
```

### Swishæ¿€æ´»å‡½æ•°

**å®šä¹‰**ï¼š
$$
\text{Swish}(x) = x \cdot \sigma(x)
$$

```python
class Swish(nn.Module):
    def forward(self, x):
        return x * torch.sigmoid(x)
```

**ç‰¹ç‚¹**ï¼š
* å¹³æ»‘ã€éå•è°ƒ
* æ€§èƒ½ä¼˜äºReLU
* è®¡ç®—ç¨å¤æ‚

### EfficientNet-B0åˆ°B7

| æ¨¡å‹ | \(\phi\) | å‚æ•°é‡ | FLOPs | Top-1å‡†ç¡®ç‡ |
|------|------|--------|-------|-----------|
| B0 | 0 | 5.3M | 0.39B | 77.1% |
| B1 | 0.5 | 7.8M | 0.70B | 79.1% |
| B2 | 1 | 9.2M | 1.0B | 80.1% |
| B3 | 2 | 12M | 1.8B | 81.6% |
| B4 | 3 | 19M | 4.2B | 82.9% |
| B5 | 4 | 30M | 9.9B | 83.6% |
| B6 | 5 | 43M | 19B | 84.0% |
| B7 | 6 | 66M | 37B | 84.3% |

### æ€§èƒ½å¯¹æ¯”

åœ¨ç›¸åŒå‡†ç¡®ç‡ä¸‹ï¼š

| æ¨¡å‹ | å‚æ•°é‡ | FLOPs | Top-1å‡†ç¡®ç‡ |
|------|--------|-------|-----------|
| ResNet-152 | 60M | 11.3B | 77.8% |
| GPipe | 556M | 128B | 84.3% |
| **EfficientNet-B1** | **7.8M** | **0.70B** | **79.1%** |
| **EfficientNet-B7** | **66M** | **37B** | **84.3%** |

**EfficientNet-B7**ï¼š
* å‚æ•°é‡æ˜¯GPipeçš„**1/8.4**
* æ¨ç†é€Ÿåº¦å¿«**6.1å€**
* è¾¾åˆ°ç›¸åŒç²¾åº¦ï¼

### æ¨¡å‹å¤ç°

* **ä»£ç åœ°å€**ï¼š[GitHub - DeepLearning/model_classification/EfficientNet](https://github.com/YangCazz/DeepLearning/tree/master/model_classification/EfficientNet)

## 2. EfficientNet V2 (2021)

### V1çš„é—®é¢˜

![EfficientNet V2](/assets/images/deep-learning/EfficientNet_v2.png)

1. **è®­ç»ƒé€Ÿåº¦æ…¢**ï¼šåœ¨å¤§å°ºå¯¸å›¾åƒä¸Šè®­ç»ƒå¾ˆæ…¢
2. **DWå·ç§¯é€Ÿåº¦æ…¢**ï¼šæµ…å±‚DWå·ç§¯æ— æ³•åˆ©ç”¨ç¡¬ä»¶åŠ é€Ÿ
3. **æ‰©å±•æ€§é—®é¢˜**ï¼šç®€å•æ”¾å¤§æ¨¡å‹æ•ˆæœä¸ä½³

### æ ¸å¿ƒåˆ›æ–°

#### 1. Fused-MBConv

![Fused-MBConv](/assets/images/deep-learning/EfficientNet_v2_Fused_MBConv.png)

**æµ…å±‚ä½¿ç”¨Fused-MBConvï¼Œæ·±å±‚ä½¿ç”¨MBConv**

```python
class FusedMBConvBlock(nn.Module):
    """èåˆçš„MBConvï¼šå°†DW+PWèåˆä¸ºæ ‡å‡†å·ç§¯"""
    def __init__(self, in_channels, out_channels, expand_ratio, 
                 kernel_size, stride):
        super(FusedMBConvBlock, self).__init__()
        
        hidden_dim = in_channels * expand_ratio
        self.use_residual = stride == 1 and in_channels == out_channels
        
        # Expansion + å¸¸è§„å·ç§¯ï¼ˆä»£æ›¿DW+PWï¼‰
        self.conv1 = nn.Sequential(
            nn.Conv2d(in_channels, hidden_dim, kernel_size=kernel_size, 
                     stride=stride, padding=kernel_size//2, bias=False),
            nn.BatchNorm2d(hidden_dim),
            nn.SiLU()
        )
        
        # Projection
        self.conv2 = nn.Sequential(
            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels)
        )
    
    def forward(self, x):
        out = self.conv1(x)
        out = self.conv2(out)
        
        if self.use_residual:
            return x + out
        return out
```

**ä¸ºä»€ä¹ˆæµ…å±‚ç”¨Fused-MBConvï¼Ÿ**
* æµ…å±‚ç‰¹å¾ç®€å•ï¼Œä¸éœ€è¦å¤æ‚çš„åˆ†ç¦»å·ç§¯
* æ ‡å‡†å·ç§¯å¯ä»¥æ›´å¥½åˆ©ç”¨ç¡¬ä»¶åŠ é€Ÿ
* å‡å°‘å†…å­˜è®¿é—®ï¼Œæé«˜é€Ÿåº¦

#### 2. Progressive Learning

**æ¸è¿›å¼å­¦ä¹ ç­–ç•¥**ï¼š

**é˜¶æ®µ1ï¼ˆEarlyï¼‰**ï¼š
* ä½¿ç”¨è¾ƒå°çš„å›¾åƒå°ºå¯¸ï¼ˆå¦‚128Ã—128ï¼‰
* ä½¿ç”¨è¾ƒå¼±çš„æ•°æ®å¢å¼º
* å¿«é€Ÿå­¦ä¹ ç®€å•æ¨¡å¼

**é˜¶æ®µ2ï¼ˆLateï¼‰**ï¼š
* é€æ¸å¢å¤§å›¾åƒå°ºå¯¸ï¼ˆå¦‚224Ã—224ï¼Œç”šè‡³æ›´å¤§ï¼‰
* å¢å¼ºæ•°æ®å¢å¼ºå¼ºåº¦
* å­¦ä¹ æ›´å¤æ‚çš„æ¨¡å¼

```python
# æ¸è¿›å¼å­¦ä¹ ä¼ªä»£ç 
for epoch in range(total_epochs):
    # åŠ¨æ€è°ƒæ•´å›¾åƒå¤§å°
    if epoch < total_epochs // 3:
        image_size = 128
        aug_strength = 'weak'
    elif epoch < 2 * total_epochs // 3:
        image_size = 224
        aug_strength = 'medium'
    else:
        image_size = 380
        aug_strength = 'strong'
    
    train_one_epoch(image_size, aug_strength)
```

**ä¼˜åŠ¿**ï¼š
* æ—©æœŸå¿«é€Ÿæ”¶æ•›
* åæœŸç²¾ç»†è°ƒæ•´
* è®­ç»ƒé€Ÿåº¦æå‡æ˜¾è‘—

### V1 vs V2

| ç‰¹æ€§ | V1 | V2 |
|------|----|----|
| æµ…å±‚ç»“æ„ | MBConv | Fused-MBConv |
| æ·±å±‚ç»“æ„ | MBConv | MBConv |
| æ¿€æ´»å‡½æ•° | Swish | SiLU (Swish) |
| è®­ç»ƒç­–ç•¥ | å›ºå®šå°ºå¯¸ | Progressive Learning |
| è®­ç»ƒé€Ÿåº¦ | è¾ƒæ…¢ | å¿«3-9å€ |
| å‚æ•°æ•ˆç‡ | é«˜ | æ›´é«˜ |

### æ€§èƒ½å¯¹æ¯”

| æ¨¡å‹ | å‚æ•°é‡ | FLOPs | è®­ç»ƒé€Ÿåº¦ | Top-1å‡†ç¡®ç‡ |
|------|--------|-------|---------|-----------|
| EfficientNet-B7 | 66M | 37B | 1Ã— | 84.3% |
| EfficientNet V2-M | 54M | 24B | **2.3Ã—** | 85.1% |
| EfficientNet V2-L | 119M | 56B | **3.0Ã—** | 85.7% |

**V2ä¸ä»…æ›´å‡†ï¼Œè€Œä¸”è®­ç»ƒæ›´å¿«ï¼**

## NASï¼ˆç¥ç»æ¶æ„æœç´¢ï¼‰

### ä»€ä¹ˆæ˜¯NASï¼Ÿ

**ä¼ ç»Ÿæ–¹æ³•**ï¼šæ‰‹å·¥è®¾è®¡ â†’ å®éªŒ â†’ è°ƒæ•´ â†’ å†å®éªŒ

**NASæ–¹æ³•**ï¼šå®šä¹‰æœç´¢ç©ºé—´ â†’ è‡ªåŠ¨æœç´¢ â†’ æ‰¾åˆ°æœ€ä¼˜æ¶æ„

### æœç´¢ç©ºé—´

åœ¨EfficientNetä¸­ï¼ŒNASæœç´¢çš„å‚æ•°åŒ…æ‹¬ï¼š
* å±‚æ•°
* æ¯å±‚çš„å·ç§¯æ ¸å¤§å°ï¼ˆ3Ã—3 or 5Ã—5ï¼‰
* æ‰©å±•æ¯”ä¾‹ï¼ˆexpand_ratioï¼‰
* SEæ¨¡å—çš„ç¼©å‡æ¯”ä¾‹

### NASçš„æˆæœ¬

**å·¨å¤§çš„è®¡ç®—é‡**ï¼

ä»¥EfficientNet-B0ä¸ºä¾‹ï¼š
* æœç´¢æ—¶é—´ï¼š**æ•°åƒGPUå°æ—¶**
* æˆæœ¬ï¼šæ•°ä¸‡ç¾å…ƒ

**ä½†æ˜¯**ï¼š
* æœç´¢ä¸€æ¬¡ï¼Œå—ç›Šæ— ç©·
* æ‰¾åˆ°çš„æ¶æ„å¯ä»¥å¤ç”¨

## å®è·µç»éªŒ

### 1. é€‰æ‹©åˆé€‚çš„ç‰ˆæœ¬

```python
from torchvision.models import efficientnet_b0, efficientnet_b7, efficientnet_v2_s

# ç§»åŠ¨ç«¯/è¾¹ç¼˜è®¾å¤‡
model = efficientnet_b0(pretrained=True)

# æœåŠ¡å™¨/é«˜æ€§èƒ½åœºæ™¯
model = efficientnet_b7(pretrained=True)

# å¹³è¡¡é€‰æ‹©ï¼ˆV2ï¼‰
model = efficientnet_v2_s(pretrained=True)
```

### 2. è¿ç§»å­¦ä¹ 

```python
import torch.nn as nn
from torchvision import models

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
model = models.efficientnet_b0(pretrained=True)

# ä¿®æ”¹åˆ†ç±»å™¨
num_classes = 10
model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)

# å†»ç»“ç‰¹å¾æå–å±‚
for param in model.features.parameters():
    param.requires_grad = False
```

### 3. æ··åˆç²¾åº¦è®­ç»ƒ

```python
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

for data, target in train_loader:
    optimizer.zero_grad()
    
    with autocast():
        output = model(data)
        loss = criterion(output, target)
    
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

### 4. æ¸è¿›å¼å­¦ä¹ å®ç°

```python
def get_progressive_image_size(epoch, total_epochs):
    """æ ¹æ®epochè¿”å›å›¾åƒå¤§å°"""
    progress = epoch / total_epochs
    
    if progress < 0.3:
        return 128
    elif progress < 0.6:
        return 192
    elif progress < 0.9:
        return 256
    else:
        return 300

# åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨
for epoch in range(num_epochs):
    image_size = get_progressive_image_size(epoch, num_epochs)
    # æ›´æ–°æ•°æ®åŠ è½½å™¨çš„transform...
```

## è®¾è®¡å“²å­¦

### å‚æ•°å°‘ â‰  é€Ÿåº¦å¿«

EfficientNetå¼ºè°ƒï¼š
* è¦å…³æ³¨**å®é™…æ¨ç†é€Ÿåº¦**
* è¦å…³æ³¨**è®­ç»ƒæ•ˆç‡**
* è¦å…³æ³¨**ç¡¬ä»¶é€‚é…æ€§**

### å¤åˆç¼©æ”¾çš„æ™ºæ…§

å•ç‹¬å¢åŠ ä»»ä¸€ç»´åº¦éƒ½ä¼šé‡åˆ°ç“¶é¢ˆï¼š
* åªå¢åŠ æ·±åº¦ â†’ æ¢¯åº¦æ¶ˆå¤±
* åªå¢åŠ å®½åº¦ â†’ å­¦ä¸åˆ°å¤æ‚ç‰¹å¾
* åªå¢åŠ åˆ†è¾¨ç‡ â†’ æ”¶ç›Šé€’å‡

**åŒæ—¶å¹³è¡¡ä¸‰ä¸ªç»´åº¦** â†’ è·å¾—æœ€ä½³æ€§èƒ½ï¼

## æ€»ç»“

### EfficientNet V1çš„è´¡çŒ®

1. **å¤åˆç¼©æ”¾ç­–ç•¥**ï¼šç³»ç»Ÿæ€§åœ°æ‰©å±•ç½‘ç»œ
2. **NASä¼˜åŒ–**ï¼šè‡ªåŠ¨æœç´¢æœ€ä¼˜æ¶æ„
3. **MBConv Block**ï¼šé«˜æ•ˆçš„åŸºç¡€æ¨¡å—
4. **å‚æ•°æ•ˆç‡**ï¼šè¾¾åˆ°SOTAçš„åŒæ—¶å¤§å¹…å‡å°‘å‚æ•°

### EfficientNet V2çš„è´¡çŒ®

1. **Fused-MBConv**ï¼šä¼˜åŒ–æµ…å±‚ç»“æ„
2. **Progressive Learning**ï¼šåŠ é€Ÿè®­ç»ƒ
3. **æ›´å¥½çš„æ€§èƒ½**ï¼šæ›´å‡†ã€æ›´å¿«ã€æ›´é«˜æ•ˆ

### å…³é”®å¯ç¤º

* **ç³»ç»Ÿæ€§è®¾è®¡å¾ˆé‡è¦**ï¼šä¸‰ä¸ªç»´åº¦è¦å¹³è¡¡
* **NASæ˜¯æœªæ¥è¶‹åŠ¿**ï¼šè‡ªåŠ¨åŒ–ä¼˜äºæ‰‹å·¥
* **è®­ç»ƒæ•ˆç‡åŒæ ·é‡è¦**ï¼šä¸åªå…³æ³¨æ¨ç†
* **å®è·µå‡ºçœŸçŸ¥**ï¼šç†è®ºè¦ç»“åˆå®é™…

## å½±å“

EfficientNetç³»åˆ—ï¼š
* ğŸ“Š åˆ·æ–°äº†ImageNetå‡†ç¡®ç‡è®°å½•
* ğŸ”§ æˆä¸ºå·¥ä¸šç•Œé¦–é€‰Backboneä¹‹ä¸€
* ğŸš€ å¹¿æ³›åº”ç”¨äºå„ç±»è§†è§‰ä»»åŠ¡
* ğŸ“ å¯å‘äº†AutoMLåœ¨ç½‘ç»œè®¾è®¡ä¸­çš„åº”ç”¨

**EfficientNetè¯æ˜äº†ï¼šå¥½çš„ç½‘ç»œè®¾è®¡éœ€è¦ç†è®ºã€å®éªŒå’Œè‡ªåŠ¨åŒ–çš„å®Œç¾ç»“åˆï¼**

## å‚è€ƒèµ„æ–™

1. Tan, M., & Le, Q. V. (2019). EfficientNet: Rethinking Model Scaling
2. Tan, M., & Le, Q. V. (2021). EfficientNetV2: Smaller Models and Faster Training
3. [æˆ‘çš„GitHubä»£ç ä»“åº“](https://github.com/YangCazz/DeepLearning)
4. [EfficientNetè®ºæ–‡è§£è¯»](https://arxiv.org/abs/1905.11946)

---

*è¿™æ˜¯æ·±åº¦å­¦ä¹ ç»å…¸ç½‘ç»œç³»åˆ—çš„ç¬¬ä¸ƒç¯‡ï¼Œä¸‹ä¸€ç¯‡å°†ä»‹ç»Attentionæœºåˆ¶ã€‚æ¬¢è¿å…³æ³¨ï¼*

