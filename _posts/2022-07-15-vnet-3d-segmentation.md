---
layout: post
title: "V-Netï¼š3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„çªç ´"
date: 2022-07-15 10:00:00 +0800
categories: [åŒ»å­¦å½±åƒ, å›¾åƒåˆ†å‰²]
tags: [UNet, åŒ»å­¦å›¾åƒ, 3Dåˆ†å‰²]
excerpt: "æ¢ç´¢V-Netå¦‚ä½•å°†UNetæ‰©å±•åˆ°3DåŸŸï¼Œé€šè¿‡æ®‹å·®è¿æ¥å’ŒDice Losså®ç°å‰åˆ—è…ºMRIçš„ç²¾ç¡®ä½“ç§¯åˆ†å‰²ã€‚"
author: YangCazz
math: true
---

## ğŸ“‹ å¼•è¨€

åœ¨ä¸Šä¸€ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†[FCNå’ŒUNet](/2025/02/01/fcn-unet-foundation/)å¦‚ä½•å¥ å®š2DåŒ»å­¦å›¾åƒåˆ†å‰²çš„åŸºç¡€ã€‚ç„¶è€Œï¼ŒåŒ»å­¦æˆåƒé€šå¸¸æ˜¯**ä¸‰ç»´çš„**ï¼ˆå¦‚CTã€MRIæ‰«æï¼‰ï¼Œä»…å¤„ç†å•ä¸ª2Dåˆ‡ç‰‡ä¼šä¸¢å¤±é‡è¦çš„ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

**V-Net**ï¼ˆ2016ï¼‰æ˜¯ç¬¬ä¸€ä¸ªæˆåŠŸçš„ç«¯åˆ°ç«¯3DåŒ»å­¦å›¾åƒåˆ†å‰²ç½‘ç»œï¼Œå®ƒä¸ä»…å°†UNetæ‰©å±•åˆ°3Dï¼Œè¿˜å¼•å…¥äº†å¤šé¡¹å…³é”®åˆ›æ–°ï¼š
- âœ… **3Då·ç§¯**ï¼šç›´æ¥å¤„ç†ä½“ç§¯æ•°æ®
- âœ… **æ®‹å·®è¿æ¥**ï¼šæ·±å±‚ç½‘ç»œçš„æœ‰æ•ˆè®­ç»ƒ
- âœ… **Dice Loss**ï¼šç›´æ¥ä¼˜åŒ–åˆ†å‰²æŒ‡æ ‡

### ä¸ºä»€ä¹ˆéœ€è¦3Dåˆ†å‰²ï¼Ÿ

**2Dåˆ‡ç‰‡åˆ†å‰²çš„å±€é™æ€§**ï¼š
```
2Dæ–¹æ³•ï¼šé€å±‚å¤„ç†
CT Volume (512Ã—512Ã—200) â†’ 200ä¸ª2Dåˆ‡ç‰‡ â†’ åˆ†åˆ«åˆ†å‰² â†’ å †å 
é—®é¢˜ï¼š
  âŒ ä¸¢å¤±å±‚é—´å…³ç³»
  âŒ ä¸è¿ç»­æ€§ï¼ˆé”¯é½¿çŠ¶è¾¹ç•Œï¼‰
  âŒ æ— æ³•åˆ©ç”¨3Dä¸Šä¸‹æ–‡
  âŒ å°ç—…ç¶å¯èƒ½è¢«é—æ¼
```

**3Dåˆ†å‰²çš„ä¼˜åŠ¿**ï¼š
```
3Dæ–¹æ³•ï¼šæ•´ä½“å¤„ç†
CT Volume (512Ã—512Ã—200) â†’ ç›´æ¥3Dåˆ†å‰² â†’ è¿ç»­ä½“ç§¯
ä¼˜åŠ¿ï¼š
  âœ… ä¿ç•™ç©ºé—´è¿ç»­æ€§
  âœ… åˆ©ç”¨3Dä¸Šä¸‹æ–‡ä¿¡æ¯
  âœ… æ›´å‡†ç¡®çš„ä½“ç§¯æµ‹é‡
  âœ… æ›´å¹³æ»‘çš„åˆ†å‰²è¾¹ç•Œ
```

**å…¸å‹åº”ç”¨åœºæ™¯**ï¼š
- å™¨å®˜ä½“ç§¯æµ‹é‡ï¼ˆè‚è„ã€è‚¾è„ï¼‰
- è‚¿ç˜¤ç”Ÿé•¿ç›‘æµ‹
- æ‰‹æœ¯è§„åˆ’ï¼ˆ3Dé‡å»ºï¼‰
- æ”¾ç–—é¶åŒºå‹¾ç”»

---

## ğŸ¯ V-Netï¼šæ ¸å¿ƒåˆ›æ–°

### è®ºæ–‡ä¿¡æ¯
- **æ ‡é¢˜**: V-Net: Fully Convolutional Neural Networks for Volumetric Medical Image Segmentation
- **ä½œè€…**: Fausto Milletari, Nassir Navab, Seyed-Ahmad Ahmadi (TU Munich)
- **å‘è¡¨**: 3DV 2016 (International Conference on 3D Vision)
- **è®ºæ–‡é“¾æ¥**: [arXiv:1606.04797](https://arxiv.org/abs/1606.04797)
- **å®˜æ–¹ä»£ç **: [PyTorchå®ç°](https://github.com/mattmacy/vnet.pytorch)

### ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°

#### 1. 3Då·ç§¯æ¶æ„

ä»2Dåˆ°3Dçš„æ‰©å±•çœ‹ä¼¼ç®€å•ï¼Œå®åˆ™é¢ä¸´è¯¸å¤šæŒ‘æˆ˜ï¼š

**2Då·ç§¯ vs. 3Då·ç§¯**ï¼š

$$
\text{2D Conv: } \quad Y(x, y, c) = \sum_{i,j,k} W(i, j, k) \cdot X(x+i, y+j, k) + b
$$

$$
\text{3D Conv: } \quad Y(x, y, z, c) = \sum_{i,j,k,l} W(i, j, k, l) \cdot X(x+i, y+j, z+k, l) + b
$$

**å‚æ•°é‡å¯¹æ¯”**ï¼š
```
2D: 3Ã—3å·ç§¯æ ¸ â†’ 9ä¸ªå‚æ•°/é€šé“
3D: 3Ã—3Ã—3å·ç§¯æ ¸ â†’ 27ä¸ªå‚æ•°/é€šé“ï¼ˆ3å€ï¼ï¼‰

ç¤ºä¾‹ï¼š64é€šé“â†’128é€šé“
2D: 9 Ã— 64 Ã— 128 = 73,728
3D: 27 Ã— 64 Ã— 128 = 221,184ï¼ˆ3å€å‚æ•°é‡ï¼‰
```

**è®¡ç®—é‡å¯¹æ¯”**ï¼š
```
Input: 128Ã—128Ã—128
2Då¤„ç†128å±‚: 128 Ã— (128Ã—128Ã—9) = 201M FLOPs
3Dæ•´ä½“å¤„ç†: 128Ã—128Ã—128Ã—27 = 566M FLOPsï¼ˆçº¦3å€ï¼‰
```

**å†…å­˜æŒ‘æˆ˜**ï¼š
```
2D: 128Ã—128Ã—64 = 1M â†’ 4MBï¼ˆfloat32ï¼‰
3D: 128Ã—128Ã—128Ã—64 = 128M â†’ 512MBï¼ˆ128å€ï¼ï¼‰
```

#### 2. æ®‹å·®è¿æ¥ï¼ˆResidual Connectionsï¼‰

V-Netå€Ÿé‰´äº†ResNetçš„æ€æƒ³ï¼Œåœ¨æ¯ä¸ªé˜¶æ®µå¼•å…¥æ®‹å·®è¿æ¥ï¼Œä½¿å¾—å¯ä»¥è®­ç»ƒæ›´æ·±çš„ç½‘ç»œã€‚

**æ ‡å‡†å·ç§¯å— vs. æ®‹å·®å—**ï¼š

```python
# æ ‡å‡†å·ç§¯å—
def conv_block(x):
    x = Conv3D(x)
    x = BN(x)
    x = ReLU(x)
    return x

# æ®‹å·®å—
def residual_block(x):
    residual = x  # ä¿å­˜è¾“å…¥
    x = Conv3D(x)
    x = BN(x)
    x = ReLU(x)
    x = Conv3D(x)
    x = BN(x)
    x = x + residual  # æ®‹å·®è¿æ¥
    x = ReLU(x)
    return x
```

**æ•°å­¦è¡¨ç¤º**ï¼š

è®¾è¾“å…¥ä¸º \( x \)ï¼Œæ®‹å·®å—çš„è¾“å‡ºä¸ºï¼š

$$
y = \mathcal{F}(x, \{W_i\}) + x
$$

å…¶ä¸­ \( \mathcal{F}(x, \{W_i\}) \) æ˜¯æ®‹å·®æ˜ å°„ï¼ˆå·ç§¯å±‚å­¦ä¹ çš„éƒ¨åˆ†ï¼‰ã€‚

**ä¸ºä»€ä¹ˆéœ€è¦æ®‹å·®è¿æ¥ï¼Ÿ**

1. **ç¼“è§£æ¢¯åº¦æ¶ˆå¤±**ï¼š
   
   $$
   \frac{\partial \mathcal{L}}{\partial x} = \frac{\partial \mathcal{L}}{\partial y} \left(1 + \frac{\partial \mathcal{F}}{\partial x}\right)
   $$
   
   å³ä½¿ \( \frac{\partial \mathcal{F}}{\partial x} \to 0 \)ï¼Œæ¢¯åº¦ä»è‡³å°‘ä¸º \( \frac{\partial \mathcal{L}}{\partial y} \)ã€‚

2. **å­¦ä¹ æ’ç­‰æ˜ å°„æ›´å®¹æ˜“**ï¼šç½‘ç»œå¯ä»¥å­¦ä¹  \( \mathcal{F}(x) = 0 \)ï¼Œä½¿ \( y = x \)ã€‚

3. **ç‰¹å¾é‡ç”¨**ï¼šä½å±‚ç‰¹å¾å¯ä»¥ç›´æ¥ä¼ é€’åˆ°é«˜å±‚ã€‚

#### 3. Dice Loss

è¿™æ˜¯V-Netæœ€é‡è¦çš„è´¡çŒ®ä¹‹ä¸€ï¼ä¼ ç»Ÿçš„åƒç´ çº§äº¤å‰ç†µå­˜åœ¨ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼š

**é—®é¢˜ç¤ºä¾‹**ï¼š
```
å‰åˆ—è…ºMRIä½“ç§¯åˆ†å‰²
Total voxels: 128Ã—128Ã—128 = 2,097,152
Prostate voxels: ~50,000 (2.4%)
Background voxels: ~2,047,152 (97.6%)

äº¤å‰ç†µæŸå¤±ä¼šè¢«èƒŒæ™¯ä¸»å¯¼ï¼
```

**Dice Lossç›´æ¥ä¼˜åŒ–Diceç³»æ•°**ï¼š

$$
\mathcal{L}_{\text{Dice}} = 1 - \frac{2 \sum_{i=1}^{N} p_i g_i}{\sum_{i=1}^{N} p_i + \sum_{i=1}^{N} g_i}
$$

å…¶ä¸­ï¼š
- \( p_i \in [0, 1] \) æ˜¯åƒç´  \( i \) çš„é¢„æµ‹æ¦‚ç‡ï¼ˆSigmoidè¾“å‡ºï¼‰
- \( g_i \in \{0, 1\} \) æ˜¯çœŸå®æ ‡ç­¾
- \( N \) æ˜¯ä½“ç´ æ€»æ•°

**ä¸ºä»€ä¹ˆDice Lossæœ‰æ•ˆï¼Ÿ**

1. **ç±»åˆ«ä¸å¹³è¡¡é²æ£’**ï¼šåªå…³æ³¨å‰æ™¯å’ŒèƒŒæ™¯çš„é‡å ï¼Œä¸å—ç±»åˆ«æ¯”ä¾‹å½±å“
2. **ç›´æ¥ä¼˜åŒ–ç›®æ ‡**ï¼šDiceç³»æ•°æ˜¯è¯„ä»·æŒ‡æ ‡ï¼Œç›´æ¥ä¼˜åŒ–å®ƒ
3. **å¹³æ»‘å¯å¯¼**ï¼šæ¦‚ç‡å½¢å¼ä½¿å…¶å¯å¾®åˆ†

**Dice Lossçš„æ¢¯åº¦**ï¼š

å¯¹ \( p_i \) æ±‚å¯¼ï¼š

$$
\frac{\partial \mathcal{L}_{\text{Dice}}}{\partial p_i} = -2 \left[ \frac{g_i(\sum p_j + \sum g_j) - 2\sum p_j g_j}{(\sum p_j + \sum g_j)^2} \right]
$$

---

## ğŸ—ï¸ V-Netç½‘ç»œæ¶æ„

### æ•´ä½“ç»“æ„

V-Neté‡‡ç”¨ä¸UNetç›¸ä¼¼çš„ç¼–ç å™¨-è§£ç å™¨ç»“æ„ï¼Œä½†å…¨éƒ¨ä½¿ç”¨3Då·ç§¯ï¼š

```
                  Contracting Path          Expanding Path
                      (ç¼–ç å™¨)                 (è§£ç å™¨)

Input â”€â”€â†’ ResBlockâ”€â”€â†’ Down â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Upâ”€â”€â†’ ResBlock
128Â³Ã—1         64        64                    64        64
                â”‚                                         â”‚
                â†“                                         â†‘
            ResBlockâ”€â”€â†’ Down â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Upâ”€â”€â†’ ResBlock
            64Ã—64Â³        128              128       128
                â”‚                                         â”‚
                â†“                                         â†‘
            ResBlockâ”€â”€â†’ Down â”€â”€â”€â”€â”€â”€â”€â”€â†’ Upâ”€â”€â†’ ResBlock
            64Ã—32Â³        256          256       256
                â”‚                                         â”‚
                â†“          Bottleneck                    â†‘
            ResBlockâ”€â”€â†’ ResBlock â”€â”€â”€â†’ ResBlock
            32Ã—16Â³        512          512

                                                    â†“
                                             Output (128Â³Ã—2)
```

**å…³é”®å‚æ•°**ï¼š
- **è¾“å…¥å°ºå¯¸**: 128Ã—128Ã—128Ã—1ï¼ˆå•é€šé“MRIï¼‰
- **è¾“å‡ºå°ºå¯¸**: 128Ã—128Ã—128Ã—2ï¼ˆå‰æ™¯/èƒŒæ™¯ï¼‰
- **ä¸‹é‡‡æ ·**: 4æ¬¡2Ã—2Ã—2æ± åŒ–ï¼ˆæˆ–æ­¥é•¿å·ç§¯ï¼‰
- **é€šé“æ•°**: 64 â†’ 128 â†’ 256 â†’ 512
- **æ®‹å·®å—**: æ¯ä¸ªé˜¶æ®µ1-3ä¸ªæ®‹å·®å—

### è¯¦ç»†æ¨¡å—è®¾è®¡

#### 1. æ®‹å·®å—ï¼ˆResidual Blockï¼‰

```python
class ResidualBlock3D(nn.Module):
    def __init__(self, channels, num_conv=2):
        super().__init__()
        layers = []
        for i in range(num_conv):
            layers.append(nn.Conv3d(channels, channels, 
                                   kernel_size=5, padding=2))
            if i < num_conv - 1:  # æœ€åä¸€ä¸ªå·ç§¯åä¸åŠ æ¿€æ´»
                layers.append(nn.ReLU(inplace=True))
        
        self.conv = nn.Sequential(*layers)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        residual = x
        out = self.conv(x)
        out += residual  # æ®‹å·®è¿æ¥
        out = self.relu(out)
        return out
```

**V-Netä½¿ç”¨5Ã—5Ã—5å·ç§¯**ï¼ˆè€Œéå¸¸è§çš„3Ã—3Ã—3ï¼‰ï¼Œå¢åŠ æ„Ÿå—é‡ï¼š
```
æ„Ÿå—é‡ï¼š
3Ã—3Ã—3å·ç§¯: 3Ã—3Ã—3 = 27ä¸ªä½“ç´ 
5Ã—5Ã—5å·ç§¯: 5Ã—5Ã—5 = 125ä¸ªä½“ç´ ï¼ˆçº¦5å€ï¼‰
```

#### 2. ä¸‹é‡‡æ ·ï¼ˆDownsamplingï¼‰

V-Netä½¿ç”¨**æ­¥é•¿å·ç§¯**ï¼ˆè€Œéæ± åŒ–ï¼‰è¿›è¡Œä¸‹é‡‡æ ·ï¼š

```python
class DownConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.down = nn.Conv3d(in_channels, out_channels,
                             kernel_size=2, stride=2)  # æ­¥é•¿2
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        return self.relu(self.down(x))
```

**ä¸ºä»€ä¹ˆç”¨æ­¥é•¿å·ç§¯ï¼Ÿ**
- âœ… å¯å­¦ä¹ çš„ä¸‹é‡‡æ ·ï¼ˆæ± åŒ–å›ºå®šï¼‰
- âœ… åŒæ—¶é™ä½åˆ†è¾¨ç‡å’Œå¢åŠ é€šé“æ•°
- âœ… å‡å°‘ä¿¡æ¯ä¸¢å¤±

#### 3. ä¸Šé‡‡æ ·ï¼ˆUpsamplingï¼‰

```python
class UpConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.up = nn.ConvTranspose3d(in_channels, out_channels,
                                     kernel_size=2, stride=2)
        self.relu = nn.ReLU(inplace=True)
    
    def forward(self, x):
        return self.relu(self.up(x))
```

#### 4. è·³è·ƒè¿æ¥ï¼ˆSkip Connectionsï¼‰

V-Netä½¿ç”¨**ç›¸åŠ **æ–¹å¼èåˆç‰¹å¾ï¼ˆè€ŒUNetä½¿ç”¨æ‹¼æ¥ï¼‰ï¼š

```python
def forward(self, x_encoder, x_decoder):
    # UNetæ–¹å¼: æ‹¼æ¥
    # x = torch.cat([x_encoder, x_decoder], dim=1)
    
    # V-Netæ–¹å¼: ç›¸åŠ 
    x = x_encoder + x_decoder
    return x
```

**ç›¸åŠ  vs. æ‹¼æ¥**ï¼š
```
ç›¸åŠ ï¼ˆAdditionï¼‰:
- é€šé“æ•°ä¸å˜
- å‚æ•°é‡æ›´å°‘
- è¦æ±‚è¾“å…¥é€šé“æ•°ç›¸åŒ

æ‹¼æ¥ï¼ˆConcatenationï¼‰:
- é€šé“æ•°ç¿»å€
- ä¿ç•™æ›´å¤šä¿¡æ¯
- å‚æ•°é‡æ›´å¤§
```

### å®Œæ•´V-Netå®ç°

```python
class VNet(nn.Module):
    def __init__(self, in_channels=1, num_classes=2):
        super(VNet, self).__init__()
        
        # Encoder (å·¦ä¾§ä¸‹é‡‡æ ·è·¯å¾„)
        self.enc1 = ResidualBlock3D(16, num_conv=1)
        self.down1 = DownConv(16, 32)
        
        self.enc2 = ResidualBlock3D(32, num_conv=2)
        self.down2 = DownConv(32, 64)
        
        self.enc3 = ResidualBlock3D(64, num_conv=3)
        self.down3 = DownConv(64, 128)
        
        self.enc4 = ResidualBlock3D(128, num_conv=3)
        self.down4 = DownConv(128, 256)
        
        # Bottleneck
        self.bottleneck = ResidualBlock3D(256, num_conv=3)
        
        # Decoder (å³ä¾§ä¸Šé‡‡æ ·è·¯å¾„)
        self.up4 = UpConv(256, 128)
        self.dec4 = ResidualBlock3D(128, num_conv=3)
        
        self.up3 = UpConv(128, 64)
        self.dec3 = ResidualBlock3D(64, num_conv=3)
        
        self.up2 = UpConv(64, 32)
        self.dec2 = ResidualBlock3D(32, num_conv=2)
        
        self.up1 = UpConv(32, 16)
        self.dec1 = ResidualBlock3D(16, num_conv=1)
        
        # æœ€ç»ˆè¾“å‡º
        self.output = nn.Conv3d(16, num_classes, kernel_size=1)
        
        # åˆå§‹åŒ–
        self._initialize_weights()
    
    def forward(self, x):
        # Encoder
        e1 = self.enc1(x)      # 128Â³Ã—16
        d1 = self.down1(e1)    # 64Â³Ã—32
        
        e2 = self.enc2(d1)     # 64Â³Ã—32
        d2 = self.down2(e2)    # 32Â³Ã—64
        
        e3 = self.enc3(d2)     # 32Â³Ã—64
        d3 = self.down3(e3)    # 16Â³Ã—128
        
        e4 = self.enc4(d3)     # 16Â³Ã—128
        d4 = self.down4(e4)    # 8Â³Ã—256
        
        # Bottleneck
        b = self.bottleneck(d4)  # 8Â³Ã—256
        
        # Decoder with skip connections
        u4 = self.up4(b)       # 16Â³Ã—128
        u4 = u4 + e4           # è·³è·ƒè¿æ¥ï¼ˆç›¸åŠ ï¼‰
        d4 = self.dec4(u4)     # 16Â³Ã—128
        
        u3 = self.up3(d4)      # 32Â³Ã—64
        u3 = u3 + e3
        d3 = self.dec3(u3)     # 32Â³Ã—64
        
        u2 = self.up2(d3)      # 64Â³Ã—32
        u2 = u2 + e2
        d2 = self.dec2(u2)     # 64Â³Ã—32
        
        u1 = self.up1(d2)      # 128Â³Ã—16
        u1 = u1 + e1
        d1 = self.dec1(u1)     # 128Â³Ã—16
        
        # è¾“å‡º
        out = self.output(d1)  # 128Â³Ã—2
        return out
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv3d):
                nn.init.kaiming_normal_(m.weight, 
                                       mode='fan_out', 
                                       nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
```

---

## ğŸ“ æ•°å­¦å®šä¹‰

### 1. 3Då·ç§¯æ“ä½œ

è®¾3Dè¾“å…¥ç‰¹å¾å›¾ \( X \in \mathbb{R}^{D \times H \times W \times C_{\text{in}}} \)ï¼Œå·ç§¯æ ¸ \( W \in \mathbb{R}^{k \times k \times k \times C_{\text{in}} \times C_{\text{out}}} \)ï¼Œè¾“å‡ºä¸ºï¼š

$$
Y(d, h, w, c_{\text{out}}) = \sum_{c_{\text{in}}=1}^{C_{\text{in}}} \sum_{i=0}^{k-1} \sum_{j=0}^{k-1} \sum_{l=0}^{k-1} W(i, j, l, c_{\text{in}}, c_{\text{out}}) \cdot X(d+i, h+j, w+l, c_{\text{in}}) + b_{c_{\text{out}}}
$$

**è¾“å‡ºå°ºå¯¸**ï¼ˆpadding=\(p\), stride=\(s\)ï¼‰ï¼š

$$
D_{\text{out}} = \left\lfloor \frac{D + 2p - k}{s} \right\rfloor + 1
$$

åŒç†é€‚ç”¨äº \( H \) å’Œ \( W \) ç»´åº¦ã€‚

### 2. Dice Lossæ¨å¯¼

Diceç³»æ•°å®šä¹‰ï¼š

$$
\text{Dice}(P, G) = \frac{2|P \cap G|}{|P| + |G|}
$$

å¯¹äºæ¦‚ç‡é¢„æµ‹ï¼Œè½¯Diceç³»æ•°ä¸ºï¼š

$$
\text{Soft Dice} = \frac{2\sum_{i=1}^{N} p_i g_i + \epsilon}{\sum_{i=1}^{N} p_i + \sum_{i=1}^{N} g_i + \epsilon}
$$

å…¶ä¸­ \( \epsilon = 10^{-5} \) æ˜¯å¹³æ»‘é¡¹ï¼Œé˜²æ­¢åˆ†æ¯ä¸º0ã€‚

**Dice Loss**ï¼š

$$
\mathcal{L}_{\text{Dice}} = 1 - \text{Soft Dice} = 1 - \frac{2\sum p_i g_i + \epsilon}{\sum p_i + \sum g_i + \epsilon}
$$

**æ¢¯åº¦è®¡ç®—**ï¼š

è®¾ \( S = \sum p_i, T = \sum g_i, I = \sum p_i g_i \)ï¼Œåˆ™ï¼š

$$
\frac{\partial \mathcal{L}_{\text{Dice}}}{\partial p_i} = -2 \left[ \frac{g_i(S + T + \epsilon) - 2I}{(S + T + \epsilon)^2} \right]
$$

**PyTorchå®ç°**ï¼š

```python
class DiceLoss(nn.Module):
    def __init__(self, smooth=1e-5):
        super(DiceLoss, self).__init__()
        self.smooth = smooth
    
    def forward(self, pred, target):
        """
        pred: (B, C, D, H, W) - é¢„æµ‹æ¦‚ç‡ï¼ˆSigmoid/Softmaxåï¼‰
        target: (B, C, D, H, W) - çœŸå®æ ‡ç­¾ï¼ˆone-hotç¼–ç ï¼‰
        """
        # å±•å¹³
        pred = pred.view(-1)
        target = target.view(-1)
        
        # è®¡ç®—Dice
        intersection = (pred * target).sum()
        union = pred.sum() + target.sum()
        
        dice = (2. * intersection + self.smooth) / \
               (union + self.smooth)
        
        return 1 - dice

# å¤šç±»åˆ«Dice Loss
class MultiClassDiceLoss(nn.Module):
    def __init__(self, num_classes, smooth=1e-5):
        super().__init__()
        self.num_classes = num_classes
        self.smooth = smooth
    
    def forward(self, pred, target):
        """
        pred: (B, C, D, H, W)
        target: (B, D, H, W) - ç±»åˆ«ç´¢å¼•
        """
        # è½¬ä¸ºone-hot
        target_one_hot = F.one_hot(target, self.num_classes)
        target_one_hot = target_one_hot.permute(0, 4, 1, 2, 3).float()
        
        # Softmax
        pred = F.softmax(pred, dim=1)
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„Dice
        dice_per_class = []
        for c in range(self.num_classes):
            pred_c = pred[:, c, ...]
            target_c = target_one_hot[:, c, ...]
            
            intersection = (pred_c * target_c).sum()
            union = pred_c.sum() + target_c.sum()
            dice_c = (2. * intersection + self.smooth) / \
                     (union + self.smooth)
            dice_per_class.append(dice_c)
        
        # å¹³å‡Dice
        mean_dice = sum(dice_per_class) / self.num_classes
        return 1 - mean_dice
```

### 3. æ®‹å·®å—çš„æ•°å­¦è¡¨ç¤º

è®¾è¾“å…¥ \( x \)ï¼Œæ®‹å·®å—åŒ…å«ä¸¤ä¸ªå·ç§¯å±‚ï¼Œè¾“å‡ºä¸ºï¼š

$$
\begin{aligned}
h_1 &= \text{ReLU}(\text{BN}(W_1 * x + b_1)) \\
h_2 &= \text{BN}(W_2 * h_1 + b_2) \\
y &= \text{ReLU}(h_2 + x)
\end{aligned}
$$

**æ’ç­‰æ˜ å°„**ï¼š

åœ¨æœ€ä¼˜æƒ…å†µä¸‹ï¼Œå¦‚æœ \( W_1, W_2 \) å­¦ä¹ åˆ° \( W_1 * W_2 \approx 0 \)ï¼Œåˆ™ \( y \approx x \)ï¼Œç½‘ç»œå¯ä»¥ä¿æŒæ’ç­‰æ˜ å°„ã€‚

---

## ğŸ“ è®­ç»ƒç­–ç•¥

### 1. æ•°æ®é¢„å¤„ç†

```python
def preprocess_mri(volume):
    """å‰åˆ—è…ºMRIé¢„å¤„ç†"""
    # 1. å¼ºåº¦å½’ä¸€åŒ–
    volume = (volume - volume.mean()) / volume.std()
    
    # 2. è£å‰ªåˆ°ROI
    volume = crop_to_roi(volume, margin=10)
    
    # 3. è°ƒæ•´å°ºå¯¸
    volume = resize(volume, (128, 128, 128))
    
    # 4. èŒƒå›´é™åˆ¶
    volume = np.clip(volume, -3, 3)
    
    return volume
```

### 2. æ•°æ®å¢å¼º

3Dæ•°æ®å¢å¼ºæ¯”2Dæ›´å¤æ‚ï¼š

```python
# 3Dæ•°æ®å¢å¼º
transforms_3d = Compose([
    # å‡ ä½•å˜æ¢
    RandomRotation3D(degrees=10),  # 3Dæ—‹è½¬
    RandomFlip3D(axis=[0, 1, 2], p=0.5),  # ä¸‰ä¸ªè½´ç¿»è½¬
    RandomAffine3D(
        translate=(0.05, 0.05, 0.05),  # å¹³ç§»
        scale=(0.9, 1.1),               # ç¼©æ”¾
        shear=(5, 5, 5)                 # å‰ªåˆ‡
    ),
    
    # å¼¹æ€§å½¢å˜
    ElasticDeformation3D(
        alpha=50,
        sigma=5,
        p=0.3
    ),
    
    # å¼ºåº¦å˜æ¢
    RandomGamma(gamma_range=(0.8, 1.2)),
    RandomBrightnessContrast(
        brightness_limit=0.2,
        contrast_limit=0.2
    ),
    
    # å™ªå£°
    GaussianNoise3D(sigma_range=(0.01, 0.05)),
])
```

### 3. è®­ç»ƒé…ç½®

```python
# æ¨¡å‹
model = VNet(in_channels=1, num_classes=2).cuda()

# æŸå¤±å‡½æ•°
criterion = DiceLoss()

# ä¼˜åŒ–å™¨ï¼ˆåŸè®ºæ–‡ä½¿ç”¨SGD + Momentumï¼‰
optimizer = torch.optim.SGD(
    model.parameters(),
    lr=0.01,
    momentum=0.99,
    weight_decay=1e-5
)

# å­¦ä¹ ç‡è°ƒåº¦
scheduler = torch.optim.lr_scheduler.StepLR(
    optimizer,
    step_size=20,
    gamma=0.5
)

# è®­ç»ƒå‚æ•°
config = {
    'batch_size': 2,  # 3Dæ•°æ®å†…å­˜å ç”¨å¤§ï¼Œbatchå°
    'epochs': 100,
    'patch_size': (128, 128, 128),
    'num_workers': 4,
}
```

### 4. è®­ç»ƒå¾ªç¯

```python
for epoch in range(num_epochs):
    model.train()
    epoch_loss = 0
    
    for batch_idx, (volumes, masks) in enumerate(train_loader):
        volumes = volumes.cuda()  # (B, 1, D, H, W)
        masks = masks.cuda()      # (B, D, H, W)
        
        # å‰å‘ä¼ æ’­
        outputs = model(volumes)  # (B, 2, D, H, W)
        
        # è®¡ç®—æŸå¤±
        loss = criterion(outputs, masks)
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        
        # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        
        optimizer.step()
        
        epoch_loss += loss.item()
    
    # éªŒè¯
    dice_score = validate(model, val_loader)
    print(f'Epoch {epoch}: Loss={epoch_loss/len(train_loader):.4f}, '
          f'Dice={dice_score:.4f}')
    
    scheduler.step()
```

### 5. æ¨ç†ç­–ç•¥

**æ»‘åŠ¨çª—å£ï¼ˆSliding Windowï¼‰**ï¼š

ç”±äºå†…å­˜é™åˆ¶ï¼Œå¤§ä½“ç§¯é€šå¸¸éœ€è¦åˆ†å—å¤„ç†ï¼š

```python
def sliding_window_inference(model, volume, window_size=(128, 128, 128), 
                             overlap=0.5):
    """
    æ»‘åŠ¨çª—å£æ¨ç†
    
    Args:
        volume: (D, H, W) è¾“å…¥ä½“ç§¯
        window_size: çª—å£å¤§å°
        overlap: é‡å ç‡
    """
    D, H, W = volume.shape
    d, h, w = window_size
    
    # è®¡ç®—æ­¥é•¿
    stride_d = int(d * (1 - overlap))
    stride_h = int(h * (1 - overlap))
    stride_w = int(w * (1 - overlap))
    
    # åˆå§‹åŒ–è¾“å‡º
    output = np.zeros((2, D, H, W))  # 2ç±»
    count = np.zeros((D, H, W))  # è®¡æ•°ï¼ˆç”¨äºå¹³å‡ï¼‰
    
    # æ»‘åŠ¨çª—å£
    for z in range(0, D - d + 1, stride_d):
        for y in range(0, H - h + 1, stride_h):
            for x in range(0, W - w + 1, stride_w):
                # æå–patch
                patch = volume[z:z+d, y:y+h, x:x+w]
                patch = torch.from_numpy(patch[None, None, ...]).float().cuda()
                
                # æ¨ç†
                with torch.no_grad():
                    pred = model(patch)  # (1, 2, d, h, w)
                    pred = F.softmax(pred, dim=1)[0].cpu().numpy()
                
                # ç´¯åŠ åˆ°è¾“å‡º
                output[:, z:z+d, y:y+h, x:x+w] += pred
                count[z:z+d, y:y+h, x:x+w] += 1
    
    # å¹³å‡ï¼ˆå¤„ç†é‡å åŒºåŸŸï¼‰
    output = output / (count + 1e-5)
    
    # å–æœ€å¤§æ¦‚ç‡ç±»åˆ«
    seg = np.argmax(output, axis=0)
    return seg
```

---

## ğŸ“Š å®éªŒç»“æœ

### æ•°æ®é›†ï¼šPROMISE12

**PROMISE12** (Prostate MR Image Segmentation 2012) æ˜¯å‰åˆ—è…ºMRIåˆ†å‰²çš„æ ‡å‡†æ•°æ®é›†ï¼š

- **è®­ç»ƒé›†**: 50ä¾‹æ‚£è€…
- **æµ‹è¯•é›†**: 30ä¾‹æ‚£è€…
- **æ¨¡æ€**: T2åŠ æƒMRI
- **åˆ†è¾¨ç‡**: çº¦0.6Ã—0.6Ã—3.6 mmÂ³
- **æ ‡æ³¨**: å‰åˆ—è…ºç²¾ç¡®è½®å»“

### æ€§èƒ½æŒ‡æ ‡

| æ–¹æ³• | Diceç³»æ•° | Hausdorffè·ç¦» (mm) |
|------|---------|-------------------|
| ä¼ ç»Ÿæ–¹æ³•ï¼ˆAtlas-basedï¼‰ | 0.82 | 8.5 |
| 2D UNetï¼ˆé€å±‚ï¼‰ | 0.85 | 7.2 |
| **V-Net** | **0.89** | **5.8** |

**å…³é”®è§‚å¯Ÿ**ï¼š
- âœ… V-Netæ¯”2Dæ–¹æ³•æå‡4%çš„Dice
- âœ… è¾¹ç•Œæ›´å¹³æ»‘ï¼ˆHausdorffè·ç¦»é™ä½20%ï¼‰
- âœ… 3Dè¿ç»­æ€§æ˜¾è‘—æ”¹å–„

### æ¶ˆèå®éªŒ

| é…ç½® | Dice |  Delta |
|------|------|--------|
| åŸºç¡€3D UNet | 0.87 | - |
| + æ®‹å·®è¿æ¥ | 0.88 | +0.01 |
| + Dice Loss | **0.89** | **+0.02** |

**ç»“è®º**ï¼š
- æ®‹å·®è¿æ¥æå‡1%ï¼ˆæ¢¯åº¦æµæ”¹å–„ï¼‰
- **Dice Lossæå‡2%**ï¼ˆç›´æ¥ä¼˜åŒ–ç›®æ ‡æŒ‡æ ‡ï¼‰

---

## ğŸ’¡ V-Netçš„ä¼˜åŠ¿ä¸å±€é™

### âœ… ä¼˜åŠ¿

1. **ç«¯åˆ°ç«¯3Då¤„ç†**
   - ä¿ç•™ç©ºé—´è¿ç»­æ€§
   - åˆ©ç”¨3Dä¸Šä¸‹æ–‡
   - æ›´å‡†ç¡®çš„ä½“ç§¯æµ‹é‡

2. **æ®‹å·®è¿æ¥**
   - æ”¯æŒæ›´æ·±ç½‘ç»œ
   - æ¢¯åº¦æµç•…é€š
   - ç‰¹å¾é‡ç”¨

3. **Dice Loss**
   - ç±»åˆ«ä¸å¹³è¡¡é²æ£’
   - ç›´æ¥ä¼˜åŒ–è¯„ä»·æŒ‡æ ‡
   - è®­ç»ƒç¨³å®š

4. **ç®€æ´é«˜æ•ˆ**
   - æ¶æ„æ¸…æ™°
   - æ˜“äºå®ç°
   - è®­ç»ƒç›¸å¯¹å®¹æ˜“

### âŒ å±€é™

1. **å†…å­˜æ¶ˆè€—å¤§**
   ```
   ç¤ºä¾‹ï¼šbatch_size=1, 128Â³Ã—64é€šé“
   å†…å­˜éœ€æ±‚ï¼š128Â³Ã—64Ã—4å­—èŠ‚ â‰ˆ 512MBï¼ˆå•å±‚ç‰¹å¾å›¾ï¼ï¼‰
   å®Œæ•´ç½‘ç»œï¼šæ•°GBæ˜¾å­˜
   ```
   
   **è§£å†³æ–¹æ¡ˆ**ï¼š
   - é™ä½è¾“å…¥åˆ†è¾¨ç‡
   - ä½¿ç”¨æ»‘åŠ¨çª—å£
   - æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆGradient Checkpointingï¼‰

2. **è®¡ç®—é‡å¤§**
   ```
   V-Net vs. 2D UNetï¼ˆç›¸åŒå‚æ•°ï¼‰
   è®¡ç®—é‡ï¼šçº¦100å€
   è®­ç»ƒæ—¶é—´ï¼šæ•°å°æ—¶ vs. æ•°å¤©
   ```

3. **æ•°æ®éœ€æ±‚**
   - 3Dæ ‡æ³¨æˆæœ¬é«˜
   - æ ·æœ¬é‡é€šå¸¸æœ‰é™
   - å®¹æ˜“è¿‡æ‹Ÿåˆ

4. **å„å‘å¼‚æ€§é—®é¢˜**
   ```
   CT/MRIåˆ†è¾¨ç‡é€šå¸¸ä¸å‡åŒ€ï¼š
   XYå¹³é¢ï¼š0.6Ã—0.6 mm
   Zè½´ï¼š   3-5 mmï¼ˆåšå±‚ï¼‰
   
   â†’ 3Ã—3Ã—3å·ç§¯åœ¨ä¸åŒæ–¹å‘æ„Ÿå—é‡ä¸åŒ
   ```

---

## ğŸš€ åç»­æ”¹è¿›ä¸å˜ç§

V-Netæ¿€å‘äº†å¤§é‡åç»­å·¥ä½œï¼š

### 1. 3D UNet (2016)

ç®€åŒ–ç‰ˆV-Netï¼Œå»é™¤æ®‹å·®è¿æ¥ï¼Œä½¿ç”¨3Ã—3Ã—3å·ç§¯ï¼š

```python
# æ›´è½»é‡çš„3D UNet
class UNet3D(nn.Module):
    def __init__(self):
        # ä½¿ç”¨æ ‡å‡†å·ç§¯å—ï¼ˆéæ®‹å·®ï¼‰
        # 3Ã—3Ã—3å·ç§¯ï¼ˆè€Œé5Ã—5Ã—5ï¼‰
        # æ‹¼æ¥å¼skip connections
```

**è®ºæ–‡**: [3D U-Net: Learning Dense Volumetric Segmentation](https://arxiv.org/abs/1606.06650)

### 2. nnU-Net

è‡ªé€‚åº”é…ç½®çš„3Dåˆ†å‰²æ¡†æ¶ï¼ŒåŸºäºV-Net/3D UNetï¼š

```python
# è‡ªåŠ¨é€‰æ‹©
if dataset.anisotropy > 3:
    model = UNet2D()  # ä½¿ç”¨2D
else:
    model = UNet3D()  # ä½¿ç”¨3D
```

**è®ºæ–‡**: [nnU-Net: Self-adapting Framework](https://arxiv.org/abs/1809.10486)

### 3. HD-Net (High-Resolution Decoder)

å¤šåˆ†è¾¨ç‡è§£ç å™¨ï¼Œä¿ç•™æ›´å¤šç»†èŠ‚ï¼š

```python
# å¹¶è¡Œå¤šå°ºåº¦è§£ç 
low_res_out = decoder_low(features)
mid_res_out = decoder_mid(features)
high_res_out = decoder_high(features)
final = fuse([low_res_out, mid_res_out, high_res_out])
```

### 4. CoTr (Contextual Transformer)

ç»“åˆTransformerå’Œ3Då·ç§¯ï¼š

```python
# ç¼–ç å™¨ï¼š3D Convï¼ˆå±€éƒ¨ï¼‰
# Bottleneckï¼šTransformerï¼ˆå…¨å±€ï¼‰
# è§£ç å™¨ï¼š3D Convï¼ˆæ¢å¤ï¼‰
```

---

## ğŸ¯ å®è·µå»ºè®®

### 1. ä½•æ—¶ä½¿ç”¨V-Netï¼Ÿ

**é€‚åˆåœºæ™¯**ï¼š
- âœ… 3DåŒ»å­¦å›¾åƒï¼ˆCTã€MRIï¼‰
- âœ… å™¨å®˜/ç—…ç¶åˆ†å‰²
- âœ… éœ€è¦ä½“ç§¯æµ‹é‡
- âœ… æœ‰å……è¶³æ˜¾å­˜ï¼ˆâ‰¥16GBï¼‰

**ä¸é€‚åˆåœºæ™¯**ï¼š
- âŒ 2Då›¾åƒï¼ˆç”¨UNetæ›´å¥½ï¼‰
- âŒ å®æ—¶åº”ç”¨ï¼ˆå¤ªæ…¢ï¼‰
- âŒ æ˜¾å­˜æœ‰é™ï¼ˆ<8GBï¼‰
- âŒ æå¤§ä½“ç§¯ï¼ˆ>512Â³ï¼‰

### 2. è¶…å‚æ•°è°ƒä¼˜

```python
# å…³é”®è¶…å‚æ•°
config = {
    # ç½‘ç»œç»“æ„
    'initial_channels': 16,  # åˆå§‹é€šé“æ•°
    'depth': 4,              # ä¸‹é‡‡æ ·æ¬¡æ•°
    'kernel_size': 5,        # 5Ã—5Ã—5ï¼ˆåŸè®ºæ–‡ï¼‰æˆ–3Ã—3Ã—3
    
    # è®­ç»ƒ
    'batch_size': 2,         # æ˜¾å­˜å…è®¸çš„æœ€å¤§å€¼
    'learning_rate': 0.01,   # SGD: 0.01, Adam: 1e-4
    'optimizer': 'SGD',      # SGD+Momentumæ›´ç¨³å®š
    'momentum': 0.99,
    
    # æ•°æ®å¢å¼º
    'augmentation_prob': 0.8,  # é«˜æ¦‚ç‡å¢å¼º
    'elastic_deform': True,    # å¼¹æ€§å½¢å˜é‡è¦
    
    # æŸå¤±å‡½æ•°
    'loss': 'dice',          # æˆ– 'dice+ce'ç»„åˆ
}
```

### 3. å†…å­˜ä¼˜åŒ–æŠ€å·§

```python
# 1. æ··åˆç²¾åº¦è®­ç»ƒ
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()

with autocast():  # è‡ªåŠ¨ä½¿ç”¨FP16
    outputs = model(inputs)
    loss = criterion(outputs, targets)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()

# 2. æ¢¯åº¦æ£€æŸ¥ç‚¹
from torch.utils.checkpoint import checkpoint

def forward_with_checkpoint(self, x):
    # åªä¿å­˜æ£€æŸ¥ç‚¹ï¼Œé‡æ–°è®¡ç®—ä¸­é—´æ¿€æ´»
    x = checkpoint(self.enc1, x)
    x = checkpoint(self.enc2, x)
    # ...
    return x

# 3. å‡å°‘é€šé“æ•°
# 16â†’32â†’64â†’128ï¼ˆè€Œé64â†’128â†’256â†’512ï¼‰
```

---

## ğŸ“– æ€»ç»“

V-Netåœ¨2016å¹´å¼€åˆ›æ€§åœ°å°†UNetæ‰©å±•åˆ°3Dï¼Œå¹¶å¼•å…¥äº†ä¸¤é¡¹å…³é”®åˆ›æ–°ï¼š

1. **æ®‹å·®è¿æ¥** - ä½¿æ·±å±‚3Dç½‘ç»œå¯è®­ç»ƒ
2. **Dice Loss** - ç›´æ¥ä¼˜åŒ–åˆ†å‰²æŒ‡æ ‡ï¼Œå¯¹ç±»åˆ«ä¸å¹³è¡¡é²æ£’

è™½ç„¶è®¡ç®—å’Œå†…å­˜éœ€æ±‚å¤§ï¼Œä½†åœ¨3DåŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡ä¸Šï¼ŒV-Netä»ç„¶æ˜¯**åŸºç¡€å’Œæ ‡å‡†æ–¹æ³•**ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼š
> ä¸æ˜¯ç®€å•åœ°å°†2Dæ–¹æ³•æ‰©å±•åˆ°3Dï¼Œè€Œæ˜¯é’ˆå¯¹3Dæ•°æ®çš„ç‰¹ç‚¹ï¼ˆç©ºé—´è¿ç»­æ€§ã€è®¡ç®—å¤æ‚åº¦ï¼‰è¿›è¡Œä¸“é—¨è®¾è®¡ã€‚

**ä¸‹ä¸€ç¯‡é¢„å‘Š**ï¼š[Attention UNet - æ³¨æ„åŠ›æœºåˆ¶çš„å¼•å…¥](/2025/02/10/attention-unet/) - æ¢ç´¢å¦‚ä½•é€šè¿‡æ³¨æ„åŠ›é—¨æ§æœºåˆ¶è¿›ä¸€æ­¥æå‡UNetçš„åˆ†å‰²æ€§èƒ½ã€‚

---

## ğŸ“š å‚è€ƒèµ„æ–™

### è®ºæ–‡
1. [V-Net] Milletari, F., Navab, N., & Ahmadi, S. A. (2016). V-net: Fully convolutional neural networks for volumetric medical image segmentation. *3DV*.
2. [3D UNet] Ã‡iÃ§ek, Ã–., et al. (2016). 3D U-Net: learning dense volumetric segmentation from sparse annotation. *MICCAI*.
3. [ResNet] He, K., et al. (2016). Deep residual learning for image recognition. *CVPR*.

### ä»£ç å®ç°
- [V-Net PyTorch](https://github.com/mattmacy/vnet.pytorch) - å®Œæ•´å®ç°
- [3D UNet PyTorch](https://github.com/wolny/pytorch-3dunet) - å¦ä¸€ä¸ªä¼˜ç§€å®ç°
- [MONAI](https://github.com/Project-MONAI/MONAI) - åŒ»å­¦å›¾åƒæ·±åº¦å­¦ä¹ æ¡†æ¶ï¼ˆåŒ…å«V-Netï¼‰

### æ•°æ®é›†
- [PROMISE12](https://promise12.grand-challenge.org/) - å‰åˆ—è…ºMRIåˆ†å‰²
- [BraTS](http://braintumorsegmentation.org/) - è„‘è‚¿ç˜¤åˆ†å‰²
- [Medical Segmentation Decathlon](http://medicaldecathlon.com/) - 10ä¸ªå™¨å®˜åˆ†å‰²ä»»åŠ¡

### å·¥å…·åº“
- [MONAI](https://monai.io/) - PyTorchåŒ»å­¦å½±åƒåº“
- [TorchIO](https://torchio.readthedocs.io/) - 3DåŒ»å­¦å›¾åƒå¤„ç†
- [NiBabel](https://nipy.org/nibabel/) - åŒ»å­¦å›¾åƒæ ¼å¼è¯»å–

---

## ğŸ”— ç³»åˆ—æ–‡ç« å¯¼èˆª

**åŒ»å­¦å½±åƒåˆ†å‰²ç½‘ç»œç³»åˆ—**ï¼š

1. [FCNä¸UNetï¼šåŒ»å­¦åˆ†å‰²çš„å¥ åŸºä¹‹ä½œ](/2025/02/01/fcn-unet-foundation/)
2. ğŸ“ **V-Netï¼š3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„çªç ´**ï¼ˆæœ¬æ–‡ï¼‰
3. [Attention UNetï¼šæ³¨æ„åŠ›æœºåˆ¶çš„å¼•å…¥](/2025/02/10/attention-unet/)
4. [UNet++/UNet 3+ï¼šå¯†é›†è¿æ¥çš„åŠ›é‡](/2025/02/15/unet-plus-series/)
5. [TransUNetï¼šCNNä¸Transformerçš„èåˆ](/2025/02/20/transunet-hybrid-architecture/)
6. [Swin-UNetï¼šå±‚çº§åŒ–Transformer](/2025/02/25/swin-unet-hierarchical-transformer/)
7. [SAMä¸MedSAMï¼šåŸºç¡€æ¨¡å‹çš„åŒ»å­¦åº”ç”¨](/2025/03/05/sam-segment-anything/)
8. [nnU-Netï¼šè‡ªé€‚åº”åŒ»å­¦åˆ†å‰²æ¡†æ¶](/2025/03/15/nnunet-self-configuring-framework/)

---

*æœ¬æ–‡æ·±å…¥æ¢è®¨äº†V-Netå¦‚ä½•å°†åŒ»å­¦å›¾åƒåˆ†å‰²æ‰©å±•åˆ°3DåŸŸï¼Œä»¥åŠæ®‹å·®è¿æ¥å’ŒDice Lossçš„å…³é”®ä½œç”¨ã€‚ä¸‹ä¸€ç¯‡å°†ä»‹ç»æ³¨æ„åŠ›æœºåˆ¶å¦‚ä½•è¿›ä¸€æ­¥æå‡åˆ†å‰²æ€§èƒ½ã€‚*

