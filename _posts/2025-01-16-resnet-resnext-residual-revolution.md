---
layout: post
title: "ResNetä¸ResNeXtï¼šæ®‹å·®ç½‘ç»œçš„é©å‘½"
date: 2025-01-16
categories: [æ·±åº¦å­¦ä¹ , ç»å…¸ç½‘ç»œ]
tags: [CNN, ResNet, ResNeXt, æ®‹å·®å­¦ä¹ , PyTorch]
excerpt: "æ·±å…¥è§£ææ®‹å·®ç½‘ç»œResNetçš„è®¾è®¡å“²å­¦ï¼šå¦‚ä½•é€šè¿‡ç®€å•çš„æ®‹å·®è¿æ¥è§£å†³æ·±åº¦ç½‘ç»œçš„é€€åŒ–é—®é¢˜ï¼Ÿä»¥åŠResNeXtå¦‚ä½•å°†Inceptionæ€æƒ³èå…¥æ®‹å·®ç»“æ„ã€‚"
---

# ResNetä¸ResNeXtï¼šæ®‹å·®ç½‘ç»œçš„é©å‘½

## å¼•è¨€

åœ¨AlexNetä¹‹åï¼Œæ·±åº¦å­¦ä¹ ç ”ç©¶è€…é€æ¸å½¢æˆäº†ä¸€ä¸ªè§‚å¿µï¼š**"ç½‘ç»œè¶Šæ·±æ•ˆæœè¶Šå¥½"**ã€‚VGGå’ŒGoogLeNetéƒ½åœ¨æ¢ç´¢æ›´æ·±çš„ç½‘ç»œã€‚ç„¶è€Œï¼Œç ”ç©¶è€…å¾ˆå¿«å‘ç°äº†ä¸€ä¸ªä»¤äººå›°æƒ‘çš„ç°è±¡ï¼š**ç½‘ç»œæ·±åº¦åˆ°è¾¾ä¸€å®šç¨‹åº¦åï¼Œæ€§èƒ½ä¸å‡åé™**ã€‚

è¿™ä¸æ˜¯è¿‡æ‹Ÿåˆï¼Œä¹Ÿä¸æ˜¯æ¢¯åº¦æ¶ˆå¤±ï¼Œè€Œæ˜¯ä¸€ç§æ–°çš„é—®é¢˜â€”â€”**é€€åŒ–(Degradation)**ã€‚2015å¹´ï¼Œä½•å‡¯æ˜å›¢é˜Ÿæå‡ºçš„**æ®‹å·®å­¦ä¹ (Residual Learning)**ï¼Œä¼˜é›…åœ°è§£å†³äº†è¿™ä¸ªé—®é¢˜ã€‚

## 1. ResNet (2015)

### åŸºæœ¬ä¿¡æ¯

* **å›¢é˜Ÿ**ï¼šMicrosoft Research Asia
* **ä½œè€…**ï¼šä½•å‡¯æ˜ã€å¼ ç¥¥é›¨ç­‰
* **è®ºæ–‡**ï¼š[Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)
* **DOI**ï¼šarXiv:1512.03385
* **æ—¶é—´**ï¼š2015å¹´

### è¾‰ç…Œæˆç»©

* ğŸ¥‡ ImageNet 2015 åˆ†ç±»ä»»åŠ¡ç¬¬ä¸€å
* ğŸ¥‡ ImageNet 2015 ç›®æ ‡æ£€æµ‹ä»»åŠ¡ç¬¬ä¸€å
* ğŸ¥‡ COCO 2015 ç›®æ ‡æ£€æµ‹ä»»åŠ¡ç¬¬ä¸€å
* ğŸ¥‡ COCO 2015 å›¾åƒåˆ†å‰²ä»»åŠ¡ç¬¬ä¸€å

## é€€åŒ–é—®é¢˜

### ä»€ä¹ˆæ˜¯é€€åŒ–ï¼Ÿ

![ResNetç»“æ„å›¾](/assets/images/deep-learning/ResNet.png)

**å®éªŒè§‚å¯Ÿ**ï¼š
* 20å±‚ç½‘ç»œï¼šè®­ç»ƒè¯¯å·®8%ï¼Œæµ‹è¯•è¯¯å·®10%
* 56å±‚ç½‘ç»œï¼šè®­ç»ƒè¯¯å·®15%ï¼Œæµ‹è¯•è¯¯å·®18%

**è¿™ä¸æ˜¯è¿‡æ‹Ÿåˆ**ï¼å› ä¸ºè®­ç»ƒè¯¯å·®ä¹Ÿå˜å¤§äº†ã€‚

### ç†è®ºåˆ†æ

å‡è®¾æµ…å±‚ç½‘ç»œå·²ç»èƒ½è¾¾åˆ°ä¸é”™çš„æ•ˆæœï¼Œé‚£ä¹ˆæ·±å±‚ç½‘ç»œç†è®ºä¸Šè‡³å°‘åº”è¯¥èƒ½åšåˆ°ï¼š
* å‰é¢å‡ å±‚ï¼šå­¦ä¹ æœ‰ç”¨çš„ç‰¹å¾
* åé¢å‡ å±‚ï¼šå­¦ä¹ **æ’ç­‰æ˜ å°„(Identity Mapping)**

$$
H(x) = x
$$

ä½†å®é™…ä¸Šï¼Œæ·±å±‚ç½‘ç»œå¾ˆéš¾å­¦åˆ°è¿™ç§æ’ç­‰æ˜ å°„ï¼Œå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚

## æ®‹å·®å­¦ä¹ 

### æ ¸å¿ƒæ€æƒ³

ä¸å…¶è®©ç½‘ç»œå­¦ä¹ å®Œæ•´çš„æ˜ å°„ \(H(x)\)ï¼Œä¸å¦‚è®©å®ƒå­¦ä¹ æ®‹å·® \(F(x) = H(x) - x\)ã€‚

**æ®‹å·®ç»“æ„**ï¼š
$$
H(x) = F(x) + x
$$

**ä¼˜åŠ¿**ï¼š
* å¦‚æœæ’ç­‰æ˜ å°„æ˜¯æœ€ä¼˜è§£ï¼Œç½‘ç»œåªéœ€å­¦ä¹  \(F(x) = 0\)
* å­¦ä¹  \(F(x) = 0\) æ¯”å­¦ä¹  \(H(x) = x\) å®¹æ˜“å¾—å¤š

### æ®‹å·®æ¨¡å—

![æ®‹å·®æ¨¡å—](/assets/images/deep-learning/ResNet_Residual.png)

#### Basic Block (ResNet-18/34)

```python
import torch.nn as nn

class BasicBlock(nn.Module):
    """ResNetåŸºç¡€æ®‹å·®å—ï¼Œç”¨äºResNet-18/34"""
    expansion = 1
    
    def __init__(self, in_channels, out_channels, stride=1):
        super(BasicBlock, self).__init__()
        
        # ä¸»è·¯å¾„
        self.conv1 = nn.Conv2d(in_channels, out_channels, 
                              kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        
        self.conv2 = nn.Conv2d(out_channels, out_channels, 
                              kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        # æ®‹å·®è¿æ¥ï¼ˆshortcutï¼‰
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 
                         kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
    
    def forward(self, x):
        identity = x
        
        # ä¸»è·¯å¾„
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        out = self.conv2(out)
        out = self.bn2(out)
        
        # æ®‹å·®è¿æ¥
        out += self.shortcut(identity)
        out = self.relu(out)
        
        return out
```

#### Bottleneck Block (ResNet-50/101/152)

```python
class Bottleneck(nn.Module):
    """ResNetç“¶é¢ˆæ®‹å·®å—ï¼Œç”¨äºResNet-50/101/152"""
    expansion = 4
    
    def __init__(self, in_channels, out_channels, stride=1):
        super(Bottleneck, self).__init__()
        
        # ä¸»è·¯å¾„ï¼š1Ã—1é™ç»´ â†’ 3Ã—3å¤„ç† â†’ 1Ã—1å‡ç»´
        self.conv1 = nn.Conv2d(in_channels, out_channels, 
                              kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        
        self.conv2 = nn.Conv2d(out_channels, out_channels, 
                              kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, 
                              kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)
        
        self.relu = nn.ReLU(inplace=True)
        
        # æ®‹å·®è¿æ¥
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels * self.expansion:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels * self.expansion, 
                         kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels * self.expansion)
            )
    
    def forward(self, x):
        identity = x
        
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)
        
        out = self.conv3(out)
        out = self.bn3(out)
        
        out += self.shortcut(identity)
        out = self.relu(out)
        
        return out
```

## ResNetæ¶æ„

### ä¸åŒæ·±åº¦çš„é…ç½®

| æ¨¡å‹ | å±‚æ•° | å‚æ•°é‡ | FLOPs | Top-1é”™è¯¯ç‡ | Top-5é”™è¯¯ç‡ |
|------|------|--------|-------|------------|------------|
| ResNet-18 | 18 | 11.7M | 1.8G | 30.2% | 10.9% |
| ResNet-34 | 34 | 21.8M | 3.7G | 26.7% | 8.6% |
| ResNet-50 | 50 | 25.6M | 4.1G | 24.0% | 7.1% |
| ResNet-101 | 101 | 44.5M | 7.8G | 22.4% | 6.2% |
| ResNet-152 | 152 | 60.2M | 11.6G | 21.7% | 5.9% |

### ResNet vs VGG

ResNetç›¸æ¯”VGGçš„ä¼˜åŠ¿ï¼š

| æŒ‡æ ‡ | ResNet-34 | VGG-19 |
|------|-----------|--------|
| å‚æ•°é‡ | 21.8M | 144M |
| è®¡ç®—é‡ | 3.7G | 19.6G |
| å‡†ç¡®ç‡ | æ›´é«˜ | è¾ƒä½ |

**ResNet-34çš„è®¡ç®—é‡çº¦ä¸ºVGG-19çš„18%ï¼Œä½†å‡†ç¡®ç‡å´è¿œé«˜äºåè€…ï¼**

## ä¸»è¦è´¡çŒ®

### 1. æ®‹å·®å­¦ä¹ æ¡†æ¶

æå‡ºäº†ä¼˜é›…çš„æ®‹å·®å­¦ä¹ æ¡†æ¶ï¼Œè§£å†³äº†æ·±åº¦ç½‘ç»œçš„é€€åŒ–é—®é¢˜ã€‚

### 2. è¶…æ·±ç½‘ç»œ

çªç ´äº†200å±‚ï¼Œè¯æ˜äº†æ®‹å·®è¿æ¥èƒ½æ”¯æŒææ·±çš„ç½‘ç»œã€‚

### 3. ç®€åŒ–è®¾è®¡

* é‡‡ç”¨BatchNormåŠ é€Ÿè®­ç»ƒ
* ä¸¢å¼ƒDropoutç»“æ„
* ç»“æ„ç®€å•ç»Ÿä¸€

### 4. é«˜æ•ˆæ€§

å‚æ•°é‡å’Œè®¡ç®—é‡éƒ½è¿œå°äºVGGï¼Œä½†æ•ˆæœæ›´å¥½ã€‚

## æ®‹å·®è¿æ¥çš„æ•°å­¦è§£é‡Š

### å‰å‘ä¼ æ’­

$$
x_{l+1} = x_l + \mathcal{F}(x_l, \mathcal{W}_l)
$$

### åå‘ä¼ æ’­

$$
\frac{\partial \mathcal{L}}{\partial x_l} = \frac{\partial \mathcal{L}}{\partial x_{l+1}} \left(1 + \frac{\partial \mathcal{F}}{\partial x_l}\right)
$$

**å…³é”®ç‚¹**ï¼šæ¢¯åº¦ä¸­æœ‰ä¸€ä¸ªæ’å®šçš„"1"ï¼Œç¡®ä¿æ¢¯åº¦èƒ½å¤Ÿé¡ºç•…ä¼ æ’­ã€‚

### å¤šå±‚å åŠ 

å¯¹äºLå±‚çš„ResNetï¼š

$$
x_L = x_l + \sum_{i=l}^{L-1} \mathcal{F}(x_i, \mathcal{W}_i)
$$

**ä»»ä½•æµ…å±‚éƒ½ä¸æ·±å±‚æœ‰ç›´æ¥è¿æ¥ï¼Œæ¢¯åº¦å¯ä»¥ç›´æ¥ä¼ æ’­ï¼**

## æ¨¡å‹å¤ç°

æˆ‘åœ¨PyTorchå¹³å°ä¸Šå¤ç°äº†ResNetæ¨¡å‹ï¼š

* **å¹³å°**ï¼šPyTorch
* **ä¸»è¦åº“**ï¼štorchvision, torch, matplotlib, tqdm
* **æ•°æ®é›†**ï¼šOxford Flower102èŠ±åˆ†ç±»æ•°æ®é›†
* **ä»£ç åœ°å€**ï¼š[GitHub - DeepLearning/model_classification/ResNet_ResNeXt](https://github.com/YangCazz/DeepLearning/tree/master/model_classification/ResNet_ResNeXt)

## 2. ResNeXt (2016)

### åŸºæœ¬ä¿¡æ¯

* **å›¢é˜Ÿ**ï¼šMicrosoft Research Asiaï¼ˆåŒæ ·æ˜¯ä½•å‡¯æ˜å›¢é˜Ÿï¼‰
* **è®ºæ–‡**ï¼š[Aggregated Residual Transformations for Deep Neural Networks](https://arxiv.org/abs/1611.05431)
* **DOI**ï¼šarXiv:1611.05431
* **æ—¶é—´**ï¼š2016å¹´

### æ ¸å¿ƒæ€æƒ³

ResNeXtæ˜¯ResNetçš„å‡çº§ç‰ˆï¼Œèå…¥äº†GoogLeNetçš„Inceptionæ€æƒ³ï¼Œä½†é‡‡ç”¨äº†æ›´è§„æ•´çš„è®¾è®¡ã€‚

![ResNeXtç»“æ„](/assets/images/deep-learning/ResNeXt.png)

### Split-Transform-Merge

**æ•°å­¦è¡¨è¾¾**ï¼š
$$
\mathcal{F}(x) = \sum_{i=1}^{C} \mathcal{T}_i(x)
$$

åŠ ä¸Šæ®‹å·®è¿æ¥ï¼š
$$
y = x + \sum_{i=1}^{C} \mathcal{T}_i(x)
$$

å…¶ä¸­Cè¢«ç§°ä¸º**åŸºæ•°(Cardinality)**ã€‚

### ResNeXtæ¨¡å—

![ResNeXtæ®‹å·®æ¨¡å—](/assets/images/deep-learning/ResNeXt_Residual.png)

```python
class ResNeXtBlock(nn.Module):
    """ResNeXtæ®‹å·®å—"""
    expansion = 2
    
    def __init__(self, in_channels, out_channels, cardinality=32, stride=1):
        super(ResNeXtBlock, self).__init__()
        
        # åˆ†ç»„å·ç§¯çš„é€šé“æ•°
        D = out_channels // 2  # bottleneck width
        
        # ä¸»è·¯å¾„
        self.conv1 = nn.Conv2d(in_channels, D * cardinality, 
                              kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(D * cardinality)
        
        # åˆ†ç»„å·ç§¯ï¼šå…³é”®åˆ›æ–°
        self.conv2 = nn.Conv2d(D * cardinality, D * cardinality, 
                              kernel_size=3, stride=stride, padding=1,
                              groups=cardinality, bias=False)
        self.bn2 = nn.BatchNorm2d(D * cardinality)
        
        self.conv3 = nn.Conv2d(D * cardinality, out_channels * self.expansion, 
                              kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)
        
        self.relu = nn.ReLU(inplace=True)
        
        # æ®‹å·®è¿æ¥
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels * self.expansion:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels * self.expansion, 
                         kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels * self.expansion)
            )
    
    def forward(self, x):
        identity = x
        
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        # åˆ†ç»„å·ç§¯
        out = self.conv2(out)
        out = self.bn2(out)
        out = self.relu(out)
        
        out = self.conv3(out)
        out = self.bn3(out)
        
        out += self.shortcut(identity)
        out = self.relu(out)
        
        return out
```

### å…³é”®åˆ›æ–°ï¼šç»„å·ç§¯

**ç»„å·ç§¯(Grouped Convolution)**ï¼š

å°†è¾“å…¥é€šé“åˆ†æˆCç»„ï¼Œæ¯ç»„ç‹¬ç«‹è¿›è¡Œå·ç§¯ï¼Œæœ€åæ‹¼æ¥ã€‚

```python
# PyTorchä¸­çš„ç»„å·ç§¯
nn.Conv2d(in_channels=64, out_channels=64, 
          kernel_size=3, groups=32)
# ç›¸å½“äº32ä¸ªç‹¬ç«‹çš„å°å·ç§¯
```

**ä¼˜åŠ¿**ï¼š
* å‡å°‘å‚æ•°é‡
* å¢åŠ ç‰¹å¾å¤šæ ·æ€§
* æå‡æ€§èƒ½

### ResNeXt vs ResNet vs Inception

| ç‰¹æ€§ | ResNet | Inception | ResNeXt |
|------|--------|-----------|---------|
| è®¾è®¡æ–¹å¼ | äººå·¥è®¾è®¡ | äººå·¥è®¾è®¡ï¼ˆå¤æ‚ï¼‰ | è‡ªåŠ¨åŒ–ï¼ˆè§„æ•´ï¼‰ |
| åˆ†æ”¯ç»“æ„ | å•è·¯å¾„ | å¤šå°ºåº¦ï¼ˆä¸åŒï¼‰ | å¤šè·¯å¾„ï¼ˆç›¸åŒï¼‰ |
| å‚æ•°è°ƒèŠ‚ | æ·±åº¦ã€å®½åº¦ | å¤æ‚ | åŸºæ•°(Cardinality) |
| å®ç°éš¾åº¦ | ç®€å• | å¤æ‚ | ä¸­ç­‰ |

## æ€§èƒ½å¯¹æ¯”

### ResNet vs ResNeXt

åœ¨ç›¸åŒå‚æ•°é‡ä¸‹ï¼š

| æ¨¡å‹ | å‚æ•°é‡ | Top-1é”™è¯¯ç‡ | Top-5é”™è¯¯ç‡ |
|------|--------|------------|------------|
| ResNet-50 | 25.6M | 24.0% | 7.1% |
| ResNeXt-50 (32Ã—4d) | 25.0M | 22.9% | 6.5% |

**ç»“è®º**ï¼šå¢åŠ åŸºæ•°(Cardinality)æ¯”å¢åŠ æ·±åº¦æˆ–å®½åº¦æ›´æœ‰æ•ˆï¼

## ResNetçš„å˜ä½“

ResNetæå‡ºåï¼Œæ¶Œç°å‡ºè®¸å¤šå˜ä½“ï¼š

1. **Pre-activation ResNet**ï¼šè°ƒæ•´æ¿€æ´»å‡½æ•°ä½ç½®
2. **Wide ResNet**ï¼šå¢åŠ ç½‘ç»œå®½åº¦
3. **ResNeXt**ï¼šå¢åŠ åŸºæ•°
4. **SE-ResNet**ï¼šåŠ å…¥é€šé“æ³¨æ„åŠ›
5. **ResNeSt**ï¼šåˆ†ç»„æ³¨æ„åŠ›

## å®è·µç»éªŒ

### 1. æ®‹å·®è¿æ¥çš„å®ç°ç»†èŠ‚

```python
# âŒ é”™è¯¯çš„å®ç°
out = self.conv(x) + x  # å¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®š

# âœ… æ­£ç¡®çš„å®ç°
identity = x
out = self.conv(x)
out = out + identity  # å…ˆä¿å­˜identityï¼Œå†ç›¸åŠ 
```

### 2. é¢„è®­ç»ƒæ¨¡å‹çš„ä½¿ç”¨

```python
import torchvision.models as models

# åŠ è½½é¢„è®­ç»ƒçš„ResNet
model = models.resnet50(pretrained=True)

# ä¿®æ”¹æœ€åä¸€å±‚ç”¨äºè‡ªå·±çš„ä»»åŠ¡
num_classes = 10
model.fc = nn.Linear(model.fc.in_features, num_classes)

# å†»ç»“å‰é¢çš„å±‚ï¼Œåªè®­ç»ƒæœ€åä¸€å±‚
for param in model.parameters():
    param.requires_grad = False
model.fc.weight.requires_grad = True
model.fc.bias.requires_grad = True
```

### 3. å­¦ä¹ ç‡ç­–ç•¥

```python
# ResNeté€‚åˆä½¿ç”¨ä½™å¼¦é€€ç«å­¦ä¹ ç‡
from torch.optim.lr_scheduler import CosineAnnealingLR

optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)
scheduler = CosineAnnealingLR(optimizer, T_max=200)
```

## ä¸ºä»€ä¹ˆæ®‹å·®ç½‘ç»œå¦‚æ­¤æˆåŠŸï¼Ÿ

### 1. è§£å†³é€€åŒ–é—®é¢˜

é€šè¿‡æ®‹å·®è¿æ¥ï¼Œç½‘ç»œå¯ä»¥è½»æ¾å­¦ä¹ æ’ç­‰æ˜ å°„ã€‚

### 2. æ¢¯åº¦ä¼ æ’­é¡ºç•…

æ®‹å·®è¿æ¥æä¾›äº†æ¢¯åº¦çš„"é«˜é€Ÿå…¬è·¯"ï¼Œç¼“è§£æ¢¯åº¦æ¶ˆå¤±ã€‚

### 3. é›†æˆå­¦ä¹ çš„è§†è§’

ResNetå¯ä»¥çœ‹ä½œæ˜¯å¤šä¸ªä¸åŒæ·±åº¦ç½‘ç»œçš„é›†æˆã€‚

### 4. ç®€å•è€Œæœ‰æ•ˆ

è®¾è®¡ç®€å•ï¼Œæ˜“äºå®ç°ï¼Œæ•ˆæœå“è¶Šã€‚

## æ€»ç»“

### ResNetçš„ä¸»è¦è´¡çŒ®

1. **æ®‹å·®å­¦ä¹ **ï¼šä¼˜é›…åœ°è§£å†³é€€åŒ–é—®é¢˜
2. **è¶…æ·±ç½‘ç»œ**ï¼šæˆåŠŸè®­ç»ƒ152å±‚ç”šè‡³1000å±‚ç½‘ç»œ
3. **é«˜æ•ˆæ€§**ï¼šå‚æ•°å°‘ã€è®¡ç®—å¿«ã€æ•ˆæœå¥½
4. **é€šç”¨æ€§**ï¼šåœ¨å„ç±»è§†è§‰ä»»åŠ¡ä¸Šéƒ½è¡¨ç°ä¼˜å¼‚

### ResNeXtçš„ä¸»è¦è´¡çŒ®

1. **è§„æ•´çš„å¤šè·¯å¾„è®¾è®¡**ï¼šç®€åŒ–äº†Inceptionçš„å¤æ‚æ€§
2. **åŸºæ•°ç»´åº¦**ï¼šæä¾›äº†æ–°çš„ç½‘ç»œè®¾è®¡ç»´åº¦
3. **æ›´å¥½çš„æ€§èƒ½**ï¼šåœ¨ç›¸åŒå‚æ•°ä¸‹è¶…è¶ŠResNet

### å…³é”®å¯ç¤º

* **ç®€å•çš„æƒ³æ³•å¾€å¾€æœ€æœ‰æ•ˆ**ï¼šæ®‹å·®è¿æ¥çš„æ€æƒ³æå…¶ç®€å•
* **æ·±åº¦å¾ˆé‡è¦**ï¼šæ®‹å·®è¿æ¥ä½¿å¾—ææ·±ç½‘ç»œæˆä¸ºå¯èƒ½
* **å¤šè·¯å¾„æœ‰å¸®åŠ©**ï¼šResNeXtè¯æ˜äº†å¤šè·¯å¾„çš„ä»·å€¼
* **è®¾è®¡éœ€è¦è§„æ•´**ï¼šç»Ÿä¸€çš„è®¾è®¡æ›´å®¹æ˜“æ‰©å±•

## å½±å“ä¸åº”ç”¨

ResNetè‡ªæå‡ºä»¥æ¥ï¼š
* ğŸ“Š è¢«å¼•ç”¨è¶…è¿‡10ä¸‡æ¬¡
* ğŸ† è·å¾—CVPR 2016æœ€ä½³è®ºæ–‡å¥–
* ğŸ”§ æˆä¸ºè®¡ç®—æœºè§†è§‰çš„æ ‡å‡†Backbone
* ğŸš€ å¹¿æ³›åº”ç”¨äºç›®æ ‡æ£€æµ‹ã€åˆ†å‰²ã€è¯†åˆ«ç­‰ä»»åŠ¡

**ResNetæ˜¯æ·±åº¦å­¦ä¹ å†å²ä¸Šæœ€å…·å½±å“åŠ›çš„å·¥ä½œä¹‹ä¸€ï¼**

## å‚è€ƒèµ„æ–™

1. He, K., et al. (2015). Deep Residual Learning for Image Recognition
2. Xie, S., et al. (2016). Aggregated Residual Transformations for Deep Neural Networks
3. [æˆ‘çš„GitHubä»£ç ä»“åº“](https://github.com/YangCazz/DeepLearning)
4. [ResNetè®ºæ–‡è§£è¯»](https://arxiv.org/abs/1512.03385)
5. [ResNeXtè®ºæ–‡è§£è¯»](https://arxiv.org/abs/1611.05431)

---

*è¿™æ˜¯æ·±åº¦å­¦ä¹ ç»å…¸ç½‘ç»œç³»åˆ—çš„ç¬¬å››ç¯‡ï¼Œä¸‹ä¸€ç¯‡å°†ä»‹ç»MobileNetç³»åˆ—ã€‚æ¬¢è¿å…³æ³¨ï¼*

