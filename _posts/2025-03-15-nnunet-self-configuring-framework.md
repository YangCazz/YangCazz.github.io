---
layout: post
title: "nnU-Netï¼šè‡ªé…ç½®åŒ»å­¦åˆ†å‰²æ¡†æ¶ï¼Œè®©UNetå‘æŒ¥æè‡´"
date: 2025-03-15
categories: [åŒ»å­¦å½±åƒ, å›¾åƒåˆ†å‰²]
tags: [æ·±åº¦å­¦ä¹ , nnU-Net, è‡ªé€‚åº”, AutoML, åŒ»å­¦åˆ†å‰²æ¡†æ¶]
excerpt: "æ·±å…¥è§£ænnU-Netå¦‚ä½•é€šè¿‡è‡ªé€‚åº”é…ç½®æ¶ˆé™¤æ‰‹å·¥è°ƒå‚ï¼Œä»…ç”¨æ ‡å‡†UNetå°±åœ¨23ä¸ªåŒ»å­¦åˆ†å‰²ä»»åŠ¡ä¸Šè¾¾åˆ°SOTAï¼Œæˆä¸ºåŒ»å­¦å›¾åƒåˆ†å‰²çš„äº‹å®æ ‡å‡†ã€‚"
author: YangCazz
math: true
---

## ğŸ“‹ å¼•è¨€

åœ¨å‰é¢çš„æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å­¦ä¹ äº†ä¼—å¤šUNetå˜ç§ï¼š[Attention UNet](/2025/02/10/attention-unet/)ã€[UNet++](/2025/02/15/unet-plus-series/)ã€[TransUNet](/2025/02/20/transunet-hybrid-architecture/)ã€[Swin-UNet](/2025/02/25/swin-unet-hierarchical-transformer/)ç­‰ã€‚è¿™äº›æ–¹æ³•é€šè¿‡æ¶æ„åˆ›æ–°ä¸æ–­åˆ·æ–°SOTAã€‚

ä½†åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå´é¢ä¸´ä¸€ä¸ªå°´å°¬çš„ç°å®ï¼š

**"ç®—æ³•è®ºæ–‡å¾ˆé…·ï¼Œä½†æˆ‘çš„ä»»åŠ¡æ€ä¹ˆè°ƒå‚ï¼Ÿ"**

```
å…¸å‹ç ”ç©¶è€…çš„å›°å¢ƒï¼š

ä»»åŠ¡ï¼šåˆ†å‰²æ–°å™¨å®˜ï¼ˆå¦‚å‰åˆ—è…ºMRIï¼‰

é—®é¢˜æ¸…å•ï¼š
â“ Patch sizeç”¨å¤šå¤§ï¼Ÿ128? 192? 256?
â“ Batch sizeè®¾å¤šå°‘ï¼Ÿ2? 4? 8?
â“ å­¦ä¹ ç‡ä»ä½•å¼€å§‹ï¼Ÿ1e-3? 1e-4?
â“ æ•°æ®å¢å¼ºç”¨ä»€ä¹ˆï¼Ÿæ—‹è½¬ï¼Ÿå¼¹æ€§å˜å½¢ï¼Ÿ
â“ ç½‘ç»œæ·±åº¦ï¼Ÿ3å±‚ï¼Ÿ4å±‚ï¼Ÿ5å±‚ï¼Ÿ
â“ æŸå¤±å‡½æ•°ï¼ŸDice? CE? ç»„åˆï¼Ÿ

è°ƒå‚å‘¨æœŸï¼š
- å°è¯•1ï¼šDice=0.65ï¼ˆpatchå¤ªå°ï¼‰
- å°è¯•2ï¼šDice=0.70ï¼ˆå­¦ä¹ ç‡å¤ªå¤§ï¼‰
- å°è¯•3ï¼šDice=0.75ï¼ˆæ•°æ®å¢å¼ºä¸è¶³ï¼‰
- ...
- å°è¯•20ï¼šDice=0.82ï¼ˆç»ˆäºæ”¶æ•›ï¼‰

è€—æ—¶ï¼š2-3ä¸ªæœˆï¼ˆç»éªŒ+è¿æ°”ï¼‰
```

**nnU-Net**ï¼ˆno-new-UNetï¼Œ2018-2021ï¼‰æå‡ºäº†é¢ è¦†æ€§æ€è·¯ï¼š

> **ä¸æ˜¯å‘æ˜æ–°æ¶æ„ï¼Œè€Œæ˜¯è‡ªåŠ¨é…ç½®æ ‡å‡†UNet**

æ ¸å¿ƒç†å¿µï¼š
- âœ… **è‡ªé€‚åº”é…ç½®**ï¼šæ ¹æ®æ•°æ®ç‰¹æ€§è‡ªåŠ¨è°ƒæ•´æ‰€æœ‰è¶…å‚æ•°
- âœ… **æ— éœ€è°ƒå‚**ï¼šæ‹¿åˆ°æ•°æ®ï¼Œä¸€é”®è¿è¡Œï¼Œè¾¾åˆ°SOTA
- âœ… **é²æ£’æ€§å¼º**ï¼šåœ¨23ä¸ªåŒ»å­¦åˆ†å‰²æŒ‘æˆ˜èµ›ä¸­å‡ååˆ—å‰èŒ…
- âœ… **å¯å¤ç°**ï¼šæ¶ˆé™¤"è°ƒå‚è‰ºæœ¯"ï¼Œç§‘å­¦ä¸”ç³»ç»Ÿ

---

## ğŸ¯ nnU-Netï¼šæ ¸å¿ƒæ€æƒ³

### è®ºæ–‡ä¿¡æ¯
- **æ ‡é¢˜**: nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation
- **ä½œè€…**: Fabian Isensee, et al. (DKFZ, German Cancer Research Center)
- **å‘è¡¨**: Nature Methods 2021
- **è®ºæ–‡é“¾æ¥**: [arXiv:1809.10486](https://arxiv.org/abs/1809.10486)
- **å®˜æ–¹ä»£ç **: [GitHub](https://github.com/MIC-DKFZ/nnUNet)
- **æˆå°±**: Medical Segmentation Decathlonå† å†›ï¼ˆ2018ï¼‰

### ä»€ä¹ˆæ˜¯Self-Configuringï¼Ÿ

**è‡ªé…ç½®ï¼ˆSelf-Configuringï¼‰**ï¼šæ ¹æ®æ•°æ®é›†å±æ€§ï¼Œè‡ªåŠ¨æ¨æ–­æœ€ä¼˜è¶…å‚æ•°ã€‚

```
è¾“å…¥ï¼š
- è®­ç»ƒæ•°æ®ï¼ˆå›¾åƒ + æ ‡æ³¨ï¼‰
- æ•°æ®é›†æŒ‡çº¹ï¼ˆfingerprintï¼‰ï¼š
  â”œâ”€ æ¨¡æ€ï¼ˆCT/MRI/...ï¼‰
  â”œâ”€ åˆ†è¾¨ç‡ï¼ˆspacingï¼‰
  â”œâ”€ å›¾åƒå°ºå¯¸
  â”œâ”€ å‰æ™¯/èƒŒæ™¯æ¯”ä¾‹
  â””â”€ ç±»åˆ«æ•°é‡

nnU-Netè‡ªåŠ¨é…ç½®ï¼š
â”œâ”€ é¢„å¤„ç†ï¼ˆé‡é‡‡æ ·ã€å½’ä¸€åŒ–ï¼‰
â”œâ”€ ç½‘ç»œæ¶æ„ï¼ˆ2D/3D/Cascadeï¼‰
â”œâ”€ Patch size
â”œâ”€ Batch size
â”œâ”€ è®­ç»ƒç­–ç•¥ï¼ˆä¼˜åŒ–å™¨ã€å­¦ä¹ ç‡ï¼‰
â”œâ”€ æ•°æ®å¢å¼º
â””â”€ åå¤„ç†

è¾“å‡ºï¼š
- è®­ç»ƒå¥½çš„æ¨¡å‹
- æœ€ä¼˜é…ç½®æ–‡ä»¶
```

### è®¾è®¡å“²å­¦

nnU-Netçš„ä¸‰å¤§åŸåˆ™ï¼š

1. **No Novelty, Just Engineering**
   - ä¸è¿½æ±‚æ–°é¢–æ¶æ„
   - ç”¨æ ‡å‡†UNet + æœ€ä½³å®è·µ

2. **Domain Knowledge Rules**
   - åˆ©ç”¨åŒ»å­¦å›¾åƒçš„å…ˆéªŒçŸ¥è¯†
   - é’ˆå¯¹ä¸åŒåœºæ™¯é€‰æ‹©é…ç½®

3. **Empirical > Heuristic**
   - åŸºäºå¤§é‡å®éªŒæ€»ç»“è§„åˆ™
   - éæ‰‹å·¥è®¾è®¡çš„å¯å‘å¼

---

## ğŸ—ï¸ nnU-Netæ¶æ„

### æ•´ä½“æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ­¥éª¤1ï¼šæ•°æ®é›†åˆ†æï¼ˆDataset Fingerprintï¼‰    â”‚
â”‚  - æå–spacingã€å°ºå¯¸ã€å¼ºåº¦åˆ†å¸ƒç­‰ç‰¹å¾        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ­¥éª¤2ï¼šè§„åˆ™æ¨æ–­ï¼ˆRule-based Inferenceï¼‰     â”‚
â”‚  - æ ¹æ®fingerprintç¡®å®šé…ç½®                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ­¥éª¤3ï¼šä¸‰ç§é…ç½®ï¼ˆ3 Configurationsï¼‰         â”‚
â”‚  - 2D UNet                                  â”‚
â”‚  - 3D Full Resolution UNet                  â”‚
â”‚  - 3D Low Resolution + 3D Cascade           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ­¥éª¤4ï¼š5æŠ˜äº¤å‰éªŒè¯è®­ç»ƒ                      â”‚
â”‚  - æ¯ç§é…ç½®è®­ç»ƒ5ä¸ªæ¨¡å‹                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ­¥éª¤5ï¼šé›†æˆé¢„æµ‹ï¼ˆEnsembleï¼‰                 â”‚
â”‚  - å¹³å‡å¤šä¸ªé…ç½®å’ŒæŠ˜çš„é¢„æµ‹                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®é›†æŒ‡çº¹ï¼ˆDataset Fingerprintï¼‰

**è‡ªåŠ¨æå–çš„å…³é”®ç‰¹å¾**ï¼š

```python
def extract_fingerprint(dataset):
    fingerprint = {
        # åŸºæœ¬ä¿¡æ¯
        'modality': get_modality(dataset),  # CT, MRI, etc.
        'num_classes': count_classes(dataset),
        'num_samples': len(dataset),
        
        # ç©ºé—´ç‰¹æ€§
        'median_spacing': np.median([img.spacing for img in dataset], axis=0),
        'median_shape': np.median([img.shape for img in dataset], axis=0),
        'size_reduction': compute_size_reduction_by_cropping(dataset),
        
        # å¼ºåº¦ç‰¹æ€§
        'intensity_properties': {
            'mean': np.mean(...),
            'std': np.std(...),
            'percentiles': np.percentile(..., [0.5, 50, 99.5])
        },
        
        # ç±»åˆ«ç‰¹æ€§
        'class_locations': get_class_locations(dataset),
        'foreground_ratio': compute_foreground_ratio(dataset)
    }
    return fingerprint
```

**ç¤ºä¾‹**ï¼š

```
æ•°æ®é›†ï¼šLiver Tumor CT
Fingerprintï¼š
{
    'modality': 'CT',
    'num_classes': 3,  # èƒŒæ™¯ã€è‚è„ã€è‚¿ç˜¤
    'median_spacing': [0.7, 0.7, 5.0] mm,  # X, Y, Z
    'median_shape': [512, 512, 130],
    'foreground_ratio': {
        'liver': 0.25,  # è‚è„å 25%
        'tumor': 0.02   # è‚¿ç˜¤å 2%
    }
}

â†’ nnU-Netæ¨æ–­ï¼š
  - ä½¿ç”¨3D UNetï¼ˆZè½´spacingå¤§ï¼Œ3Då»ºæ¨¡é‡è¦ï¼‰
  - Patch size: 128Ã—128Ã—128
  - å¼ºæ•°æ®å¢å¼ºï¼ˆè‚¿ç˜¤å°ï¼Œéœ€è¦å¢å¼ºï¼‰
  - ä¸‹é‡‡æ ·å› å­: (2, 2, 1)ï¼ˆZè½´ä¿ç•™æ›´å¤šç»†èŠ‚ï¼‰
```

### ä¸‰ç§ç½‘ç»œé…ç½®

nnU-Netä¸ºæ¯ä¸ªæ•°æ®é›†è®­ç»ƒ**3ç§é…ç½®**ï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ï¼š

#### 1. 2D UNet

```python
class UNet2D(nn.Module):
    """æ ‡å‡†2D UNet"""
    def __init__(self, in_channels, num_classes, base_num_features=32):
        super().__init__()
        
        # ç¼–ç å™¨
        self.conv1 = StackedConvLayers(in_channels, base_num_features)
        self.conv2 = StackedConvLayers(base_num_features, base_num_features * 2)
        self.conv3 = StackedConvLayers(base_num_features * 2, base_num_features * 4)
        self.conv4 = StackedConvLayers(base_num_features * 4, base_num_features * 8)
        
        # Bottleneck
        self.bottleneck = StackedConvLayers(base_num_features * 8, base_num_features * 16)
        
        # è§£ç å™¨ï¼ˆçœç•¥ï¼‰
        # ...
    
    def forward(self, x):
        # ... æ ‡å‡†UNetå‰å‘ä¼ æ’­
        pass


class StackedConvLayers(nn.Module):
    """nnU-Netçš„æ ‡å‡†å·ç§¯å—"""
    def __init__(self, in_ch, out_ch, kernel_size=3, num_convs=2):
        super().__init__()
        layers = []
        for i in range(num_convs):
            layers.append(nn.Conv2d(
                in_ch if i == 0 else out_ch,
                out_ch,
                kernel_size,
                padding=kernel_size // 2
            ))
            layers.append(nn.InstanceNorm2d(out_ch))  # ä½¿ç”¨Instance Norm
            layers.append(nn.LeakyReLU(0.01, inplace=True))
        
        self.convs = nn.Sequential(*layers)
    
    def forward(self, x):
        return self.convs(x)
```

**é€‚ç”¨åœºæ™¯**ï¼š
- Zè½´spacingå¾ˆå¤§ï¼ˆå¦‚CTï¼ŒZæ–¹å‘åˆ†è¾¨ç‡ä½ï¼‰
- å†…å­˜å—é™

#### 2. 3D Full Resolution UNet

```python
class UNet3D(nn.Module):
    """3D UNetï¼ˆå…¨åˆ†è¾¨ç‡ï¼‰"""
    def __init__(self, in_channels, num_classes, base_num_features=32):
        super().__init__()
        
        # ç¼–ç å™¨ï¼ˆ3Då·ç§¯ï¼‰
        self.conv1 = StackedConvLayers3D(in_channels, base_num_features)
        self.pool1 = nn.Conv3d(base_num_features, base_num_features, 
                               kernel_size=3, stride=2, padding=1)
        
        # ... æ›´æ·±çš„ç¼–ç å™¨
        
    def forward(self, x):
        # 3Då‰å‘ä¼ æ’­
        pass
```

**é€‚ç”¨åœºæ™¯**ï¼š
- å„å‘åŒæ€§spacingï¼ˆX/Y/Zåˆ†è¾¨ç‡ç›¸è¿‘ï¼‰
- GPUå†…å­˜å……è¶³
- éœ€è¦3Dä¸Šä¸‹æ–‡ï¼ˆå¦‚MRIï¼‰

#### 3. 3D Cascadeï¼ˆçº§è”ï¼‰

```
ç¬¬ä¸€é˜¶æ®µï¼š3D Low Resolution UNet
- è¾“å…¥ï¼šä¸‹é‡‡æ ·çš„æ•´å¼ å›¾åƒ
- è¾“å‡ºï¼šç²—ç³™çš„åˆ†å‰²mask

ç¬¬äºŒé˜¶æ®µï¼š3D Full Resolution UNet
- è¾“å…¥ï¼šåŸå§‹å›¾åƒ + ç¬¬ä¸€é˜¶æ®µmask
- è¾“å‡ºï¼šç²¾ç»†åŒ–çš„mask
```

```python
class Cascade3D:
    def __init__(self):
        self.stage1 = UNet3D(...)  # ä½åˆ†è¾¨ç‡
        self.stage2 = UNet3D(...)  # é«˜åˆ†è¾¨ç‡
    
    def predict(self, image):
        # é˜¶æ®µ1ï¼šä¸‹é‡‡æ ·é¢„æµ‹
        image_lowres = downsample(image, factor=2)
        mask_lowres = self.stage1(image_lowres)
        mask_upsampled = upsample(mask_lowres, target_size=image.shape)
        
        # é˜¶æ®µ2ï¼šç²¾ç»†åŒ–
        input_stage2 = torch.cat([image, mask_upsampled], dim=1)
        mask_final = self.stage2(input_stage2)
        
        return mask_final
```

**é€‚ç”¨åœºæ™¯**ï¼š
- é«˜åˆ†è¾¨ç‡å›¾åƒï¼ˆå¦‚512Ã—512Ã—512ï¼‰
- å†…å­˜ä¸è¶³ä»¥è®­ç»ƒå…¨åˆ†è¾¨ç‡3D UNet
- éœ€è¦å¹³è¡¡å…¨å±€ä¸Šä¸‹æ–‡å’Œå±€éƒ¨ç»†èŠ‚

### è‡ªé€‚åº”é…ç½®è§„åˆ™

#### Patch Sizeè‡ªåŠ¨æ¨æ–­

```python
def determine_patch_size(median_shape, median_spacing, target_spacing):
    """æ ¹æ®å›¾åƒå°ºå¯¸å’Œspacingç¡®å®špatch size"""
    
    # ç›®æ ‡ï¼šä½¿ç”¨çº¦128Ã—128Ã—128çš„patchï¼ˆGPUå†…å­˜å¹³è¡¡ï¼‰
    reference_patch = np.array([128, 128, 128])
    
    # è®¡ç®—é‡é‡‡æ ·åçš„å°ºå¯¸
    new_shape = np.round(median_shape * median_spacing / target_spacing).astype(int)
    
    # è°ƒæ•´patch sizeï¼Œç¡®ä¿ä¸è¶…è¿‡å›¾åƒå°ºå¯¸
    patch_size = np.minimum(reference_patch, new_shape)
    
    # ç¡®ä¿æ˜¯2çš„å€æ•°ï¼ˆæ–¹ä¾¿poolingï¼‰
    patch_size = np.round(patch_size / 16) * 16
    
    return patch_size.astype(int)

# ç¤ºä¾‹
median_shape = [512, 512, 130]
median_spacing = [0.7, 0.7, 5.0]
target_spacing = [1.0, 1.0, 1.0]  # é‡é‡‡æ ·åˆ°1mm

patch_size = determine_patch_size(median_shape, median_spacing, target_spacing)
# è¾“å‡ºï¼š[192, 192, 128]
```

#### Batch Sizeè‡ªåŠ¨è°ƒæ•´

```python
def determine_batch_size(network_type, patch_size, gpu_memory=11):
    """æ ¹æ®GPUå†…å­˜å’Œpatch sizeç¡®å®šbatch size"""
    
    # ä¼°ç®—å•ä¸ªæ ·æœ¬çš„å†…å­˜å ç”¨
    if network_type == '2D':
        memory_per_sample = patch_size[0] * patch_size[1] * 4 / (1024**2)  # MB
        max_batch_size = 12
    elif network_type == '3D':
        memory_per_sample = np.prod(patch_size) * 4 / (1024**2)
        max_batch_size = 2
    
    # æ ¹æ®GPUå†…å­˜è°ƒæ•´
    available_memory = gpu_memory * 1024  # GB -> MB
    estimated_batch_size = int(available_memory * 0.6 / memory_per_sample)
    
    batch_size = min(estimated_batch_size, max_batch_size)
    batch_size = max(batch_size, 2)  # è‡³å°‘2
    
    return batch_size
```

#### æ•°æ®å¢å¼ºç­–ç•¥

```python
def get_augmentation_pipeline(dataset_properties):
    """è‡ªé€‚åº”æ•°æ®å¢å¼º"""
    
    transforms = []
    
    # åŸºç¡€å¢å¼ºï¼ˆæ€»æ˜¯ä½¿ç”¨ï¼‰
    transforms.append(A.RandomRotate90(p=0.5))
    transforms.append(A.Flip(p=0.5))
    
    # å¼¹æ€§å˜å½¢ï¼ˆ3Dæ•°æ®ï¼‰
    if dataset_properties['is_3d']:
        transforms.append(A.ElasticTransform(
            alpha=30,
            sigma=5,
            p=0.3
        ))
    
    # æ—‹è½¬ï¼ˆæ ¹æ®æ¨¡æ€è°ƒæ•´ï¼‰
    if dataset_properties['modality'] == 'CT':
        # CTå¯¹æ—‹è½¬æ•æ„Ÿåº¦ä½
        transforms.append(A.Rotate(limit=30, p=0.5))
    elif dataset_properties['modality'] == 'MRI':
        # MRIæ›´æ•æ„Ÿ
        transforms.append(A.Rotate(limit=15, p=0.3))
    
    # å¼ºåº¦å¢å¼º
    transforms.append(A.RandomBrightnessContrast(p=0.3))
    transforms.append(A.RandomGamma(p=0.3))
    
    # ç¼©æ”¾ï¼ˆæ ¹æ®spacingå„å‘å¼‚æ€§ï¼‰
    anisotropy = np.max(dataset_properties['spacing']) / np.min(dataset_properties['spacing'])
    if anisotropy > 2:
        # å„å‘å¼‚æ€§å¤§ï¼Œé™åˆ¶Zè½´ç¼©æ”¾
        transforms.append(A.RandomScale(scale_limit=(0.7, 1.3), p=0.2))
    else:
        # å„å‘åŒæ€§ï¼Œè‡ªç”±ç¼©æ”¾
        transforms.append(A.RandomScale(scale_limit=(0.5, 1.5), p=0.5))
    
    return A.Compose(transforms)
```

---

## ğŸ“Š æ€§èƒ½è¡¨ç°

### Medical Segmentation Decathlon

**10ä¸ªä»»åŠ¡ï¼Œ10ç§æ¨¡æ€ï¼Œ2000+ç—…ä¾‹**

| ä»»åŠ¡ | æ¨¡æ€ | nnU-Net Dice | ç¬¬äºŒå | æå‡ |
|------|------|-------------|--------|------|
| è„‘è‚¿ç˜¤ | MRI | **0.68** | 0.63 | +5% |
| å¿ƒè„ | MRI | **0.93** | 0.90 | +3% |
| è‚è„ | CT | **0.96** | 0.94 | +2% |
| æµ·é©¬ä½“ | MRI | **0.90** | 0.88 | +2% |
| å‰åˆ—è…º | MRI | **0.76** | 0.71 | +5% |
| è‚ºéƒ¨ | CT | **0.69** | 0.66 | +3% |
| èƒ°è…º | CT | **0.62** | 0.56 | +6% |
| è‚è¡€ç®¡ | CT | **0.68** | 0.64 | +4% |
| è„¾è„ | CT | **0.96** | 0.95 | +1% |
| ç»“è‚ ç™Œ | CT | **0.56** | 0.51 | +5% |
| **å¹³å‡** | - | **0.77** | 0.73 | **+4%** |

**å…³é”®å‘ç°**ï¼š
- âœ… **æ‰€æœ‰ä»»åŠ¡ç¬¬ä¸€å**
- âœ… å¹³å‡æå‡4%
- âœ… **æ— éœ€è°ƒå‚ï¼Œå¼€ç®±å³ç”¨**

### ä¸SOTAæ–¹æ³•å¯¹æ¯”

| æ•°æ®é›† | UNet | Attention UNet | UNet++ | TransUNet | **nnU-Net** |
|--------|------|---------------|--------|-----------|------------|
| Synapse Multi-organ | 76.85 | 77.77 | 78.32 | 81.87 | **82.10** |
| ACDC (å¿ƒè„) | 87.48 | 88.06 | - | 90.00 | **90.34** |
| LiTS (è‚è„) | 94.2 | - | - | - | **96.3** |
| KiTS (è‚¾è„) | 84.6 | - | - | - | **87.5** |

**åˆ†æ**ï¼š
- nnU-Netç”¨**æ ‡å‡†UNet**è¾¾åˆ°æˆ–è¶…è¿‡å¤æ‚æ¶æ„
- å…³é”®ä¸åœ¨äºæ–°æ¶æ„ï¼Œè€Œåœ¨äº**æ­£ç¡®é…ç½®**

---

## ğŸ’¡ nnU-Netçš„ä¼˜åŠ¿

### 1. é›¶è°ƒå‚

```
ä¼ ç»Ÿæ–¹æ³•ï¼š
ç ”ç©¶è€…éœ€è¦ï¼š
- æ·±åº¦å­¦ä¹ ä¸“ä¸šçŸ¥è¯†
- åŒ»å­¦å›¾åƒç†è§£
- å¤§é‡è°ƒå‚ç»éªŒ
- 2-3ä¸ªæœˆæ—¶é—´

nnU-Netï¼š
ç”¨æˆ·éœ€è¦ï¼š
- å‡†å¤‡æ•°æ®ï¼ˆæŒ‰æ ¼å¼ï¼‰
- è¿è¡Œä¸€è¡Œå‘½ä»¤ï¼š
  $ nnUNet_train DATASET_NAME

ç»“æœï¼š
- 3-7å¤©è®­ç»ƒï¼ˆGPUï¼‰
- è¾¾åˆ°SOTA
```

### 2. å¯å¤ç°

```
é—®é¢˜ï¼šè®ºæ–‡å£°ç§°Dice=0.85
      è‡ªå·±å¤ç°ï¼šDice=0.75

åŸå› ï¼š
- è®ºæ–‡æœªå…¬å¼€æ‰€æœ‰è¶…å‚æ•°
- è°ƒå‚è¿‡ç¨‹ä¸é€æ˜
- "è°ƒå‚è‰ºæœ¯"éš¾ä»¥å¤åˆ¶

nnU-Netï¼š
- æ‰€æœ‰é…ç½®è‡ªåŠ¨åŒ–
- è§„åˆ™æ˜ç¡®
- å¼€æºä»£ç +é¢„è®­ç»ƒæ¨¡å‹
â†’ 100%å¯å¤ç°
```

### 3. é²æ£’æ€§

```
ä¼ ç»ŸUNetï¼š
ä»»åŠ¡Aï¼ˆè‚è„ï¼‰ï¼šDice=0.95ï¼ˆè°ƒå‚åï¼‰
ä»»åŠ¡Bï¼ˆèƒ°è…ºï¼‰ï¼šDice=0.45ï¼ˆç”¨ä»»åŠ¡Açš„é…ç½®ï¼‰

nnU-Netï¼š
ä»»åŠ¡Aï¼ˆè‚è„ï¼‰ï¼šDice=0.96ï¼ˆè‡ªåŠ¨é…ç½®ï¼‰
ä»»åŠ¡Bï¼ˆèƒ°è…ºï¼‰ï¼šDice=0.62ï¼ˆè‡ªåŠ¨é…ç½®ï¼‰
â†’ ä»»ä½•ä»»åŠ¡éƒ½ç¨³å®š
```

### 4. é›†æˆå­¦ä¹ 

```python
# nnU-Netè‡ªåŠ¨é›†æˆå¤šä¸ªæ¨¡å‹
predictions = []

# 3ç§é…ç½®
for config in ['2d', '3d_fullres', '3d_cascade']:
    # 5æŠ˜äº¤å‰éªŒè¯
    for fold in range(5):
        model = load_model(f"nnUNet/{config}/fold_{fold}")
        pred = model.predict(image)
        predictions.append(pred)

# å¹³å‡15ä¸ªé¢„æµ‹ï¼ˆ3é…ç½® Ã— 5æŠ˜ï¼‰
final_pred = np.mean(predictions, axis=0)
```

**æå‡**ï¼šé›†æˆé€šå¸¸+2-3% Dice vs. å•æ¨¡å‹

---

## ğŸ“ ä½¿ç”¨nnU-Net

### å®‰è£…

```bash
# å®‰è£…nnU-Net
pip install nnunet

# è®¾ç½®ç¯å¢ƒå˜é‡
export nnUNet_raw_data_base="/path/to/nnUNet_raw_data_base"
export nnUNet_preprocessed="/path/to/nnUNet_preprocessed"
export RESULTS_FOLDER="/path/to/nnUNet_trained_models"
```

### æ•°æ®å‡†å¤‡

```
nnUNet_raw_data_base/
â””â”€â”€ nnUNet_raw_data/
    â””â”€â”€ Task001_LiverTumor/
        â”œâ”€â”€ imagesTr/        # è®­ç»ƒå›¾åƒ
        â”‚   â”œâ”€â”€ liver_001_0000.nii.gz
        â”‚   â”œâ”€â”€ liver_002_0000.nii.gz
        â”‚   â””â”€â”€ ...
        â”œâ”€â”€ labelsTr/        # è®­ç»ƒæ ‡ç­¾
        â”‚   â”œâ”€â”€ liver_001.nii.gz
        â”‚   â”œâ”€â”€ liver_002.nii.gz
        â”‚   â””â”€â”€ ...
        â”œâ”€â”€ imagesTs/        # æµ‹è¯•å›¾åƒï¼ˆå¯é€‰ï¼‰
        â””â”€â”€ dataset.json     # æ•°æ®é›†æè¿°
```

**dataset.json**ï¼š

```json
{
    "name": "Liver Tumor",
    "description": "Liver and liver tumor segmentation",
    "modality": {
        "0": "CT"
    },
    "labels": {
        "0": "background",
        "1": "liver",
        "2": "tumor"
    },
    "numTraining": 131,
    "numTest": 70,
    "training": [
        {"image": "./imagesTr/liver_001.nii.gz", "label": "./labelsTr/liver_001.nii.gz"},
        ...
    ],
    "test": ["./imagesTs/liver_001.nii.gz", ...]
}
```

### è®­ç»ƒæµç¨‹

```bash
# æ­¥éª¤1ï¼šæ•°æ®é›†æŒ‡çº¹æå–å’Œé¢„å¤„ç†è®¡åˆ’
nnUNet_plan_and_preprocess -t 1 --verify_dataset_integrity

# è¾“å‡ºï¼š
# - Task001_LiverTumor/nnUNetPlansv2.1_plans_2D.pkl
# - Task001_LiverTumor/nnUNetPlansv2.1_plans_3D.pkl
# - é¢„å¤„ç†åçš„æ•°æ®

# æ­¥éª¤2ï¼šè®­ç»ƒï¼ˆ3ç§é…ç½®ï¼‰
# 2D UNet
nnUNet_train 2d nnUNetTrainerV2 Task001_LiverTumor 0  # fold 0
nnUNet_train 2d nnUNetTrainerV2 Task001_LiverTumor 1  # fold 1
...

# 3D Full Res UNet
nnUNet_train 3d_fullres nnUNetTrainerV2 Task001_LiverTumor 0

# 3D Cascade UNet
nnUNet_train 3d_cascade_fullres nnUNetTrainerV2 Task001_LiverTumor 0

# æ­¥éª¤3ï¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜é…ç½®
nnUNet_find_best_configuration -m 2d 3d_fullres 3d_cascade_fullres -t 1

# è¾“å‡ºï¼šBest configuration: 3d_fullres (Dice=0.96)

# æ­¥éª¤4ï¼šé¢„æµ‹
nnUNet_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -t 1 -m 3d_fullres
```

### å¸¸ç”¨å‘½ä»¤

```bash
# ä»…è®­ç»ƒç‰¹å®šé…ç½®å’ŒæŠ˜
nnUNet_train 3d_fullres nnUNetTrainerV2 Task001_LiverTumor 0

# ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹
nnUNet_predict -i ./test_images -o ./predictions \
    -t 1 -m 3d_fullres -chk model_best

# é›†æˆé¢„æµ‹ï¼ˆæ‰€æœ‰é…ç½®ï¼‰
nnUNet_predict -i ./test_images -o ./predictions \
    -t 1 -m 2d 3d_fullres 3d_cascade_fullres
```

---

## ğŸ”¬ è¿›é˜¶æŠ€å·§

### 1. è‡ªå®šä¹‰Trainer

```python
from nnunet.training.network_training.nnUNetTrainerV2 import nnUNetTrainerV2

class CustomTrainer(nnUNetTrainerV2):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        
        # è‡ªå®šä¹‰å­¦ä¹ ç‡
        self.initial_lr = 5e-4
        
        # è‡ªå®šä¹‰æŸå¤±å‡½æ•°æƒé‡
        self.loss = DC_and_CE_loss({'batch_dice': True, 'smooth': 1e-5}, {})
    
    def initialize_optimizer_and_scheduler(self):
        """è‡ªå®šä¹‰ä¼˜åŒ–å™¨"""
        self.optimizer = torch.optim.SGD(
            self.network.parameters(),
            self.initial_lr,
            weight_decay=self.weight_decay,
            momentum=0.99,
            nesterov=True
        )
        
        self.lr_scheduler = torch.optim.lr_scheduler.PolyLR(
            self.optimizer,
            self.num_epochs,
            power=0.9
        )
```

### 2. åå¤„ç†ä¼˜åŒ–

```python
# nnU-Netè‡ªåŠ¨å­¦ä¹ åå¤„ç†ç­–ç•¥
# åœ¨éªŒè¯é›†ä¸Šæµ‹è¯•ä¸åŒåå¤„ç†çš„æ•ˆæœ

def custom_postprocessing(pred_mask, remove_small_lesions_threshold=100):
    """ç§»é™¤å°è¿é€šåŸŸ"""
    import cc3d
    
    # è¿é€šåŸŸåˆ†æ
    labels_out = cc3d.connected_components(pred_mask, connectivity=26)
    
    # è®¡ç®—æ¯ä¸ªè¿é€šåŸŸçš„å¤§å°
    stats = cc3d.statistics(labels_out)
    
    # ç§»é™¤å°è¿é€šåŸŸ
    for label_id in range(1, stats['voxel_counts'].shape[0]):
        if stats['voxel_counts'][label_id] < remove_small_lesions_threshold:
            pred_mask[labels_out == label_id] = 0
    
    return pred_mask
```

### 3. å¤„ç†ä¸å¹³è¡¡æ•°æ®

```python
class ImbalancedTrainer(nnUNetTrainerV2):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
    
    def get_train_transforms(self):
        """å¢å¼ºå°ç±»åˆ«çš„é‡‡æ ·"""
        transforms = super().get_train_transforms()
        
        # æ·»åŠ ç±»åˆ«å¹³è¡¡é‡‡æ ·
        transforms.append(OverSampleForegroundClasses(
            classes_to_oversample=[2],  # è‚¿ç˜¤ç±»åˆ«
            oversample_factor=2.0
        ))
        
        return transforms
```

---

## ğŸ“– æ€»ç»“

### nnU-Netçš„æ ¸å¿ƒè´¡çŒ®

1. **è‡ªé…ç½®æ–¹æ³•è®º**
   - å°†"è°ƒå‚è‰ºæœ¯"è½¬åŒ–ä¸º"ç³»ç»Ÿå·¥ç¨‹"
   - è¯æ˜äº†æ­£ç¡®é…ç½®æ¯”æ–°æ¶æ„æ›´é‡è¦

2. **å®ç”¨ä¸»ä¹‰**
   - ä¸è¿½æ±‚æ–°é¢–æ€§ï¼Œè¿½æ±‚å¯ç”¨æ€§
   - "No new UNet" - æ ‡å‡†æ¶æ„+æœ€ä½³å®è·µ

3. **å¹¿æ³›éªŒè¯**
   - 23ä¸ªåŒ»å­¦åˆ†å‰²ä»»åŠ¡SOTA
   - æˆä¸ºåŒ»å­¦åˆ†å‰²çš„**äº‹å®æ ‡å‡†**

4. **å¼€æºç”Ÿæ€**
   - å®Œæ•´ä»£ç  + æ–‡æ¡£
   - é¢„è®­ç»ƒæ¨¡å‹
   - æ´»è·ƒç¤¾åŒº

### é€‚ç”¨åœºæ™¯

| åœºæ™¯ | æ¨èåº¦ | åŸå›  |
|------|-------|------|
| **æ–°ä»»åŠ¡å¿«é€Ÿbaseline** | âœ…âœ…âœ… | æ— éœ€è°ƒå‚ï¼Œå¼€ç®±å³ç”¨ |
| **ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²** | âœ…âœ…âœ… | é²æ£’æ€§å¼ºï¼Œå¯å¤ç° |
| **ç¼ºä¹è°ƒå‚ç»éªŒ** | âœ…âœ…âœ… | è‡ªåŠ¨é…ç½® |
| **æœ‰é™æ—¶é—´/èµ„æº** | âœ…âœ… | 3-7å¤©è¾¾åˆ°SOTA |
| **æ¢ç´¢æ–°æ¶æ„** | âš ï¸ | æ¶æ„å›ºå®šï¼Œéš¾ä»¥ä¿®æ”¹ |

### å±€é™ä¸å±•æœ›

**å±€é™**ï¼š
- âŒ æ¶æ„å›ºå®šï¼Œéš¾ä»¥é›†æˆæ–°æ¨¡å—ï¼ˆå¦‚Transformerï¼‰
- âŒ è®¡ç®—é‡å¤§ï¼ˆ3é…ç½®Ã—5æŠ˜=15ä¸ªæ¨¡å‹ï¼‰
- âŒ å¯¹æå°æ•°æ®é›†ï¼ˆ<20ä¾‹ï¼‰æ•ˆæœæœ‰é™

**æœªæ¥æ–¹å‘**ï¼š
- **nnU-Net v2**ï¼ˆ2022ï¼‰ï¼šæ”¯æŒæ›´å¤šæ¶æ„ï¼ˆResNetã€Transformerï¼‰
- **è½»é‡åŒ–**ï¼šè‡ªåŠ¨å‰ªæå’Œè’¸é¦
- **Few-shot nnU-Net**ï¼šç»“åˆMeta Learning

---

## ğŸ“š å‚è€ƒèµ„æ–™

### è®ºæ–‡
1. [nnU-Net] Isensee, F., et al. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. *Nature Methods*.
2. [nnU-Net v2] Isensee, F., et al. (2022). nnU-Net revisited: A call for rigorous validation in 3D medical image segmentation. *arXiv*.

### ä»£ç ä¸èµ„æº
- [å®˜æ–¹GitHub](https://github.com/MIC-DKFZ/nnUNet) - å®Œæ•´ä»£ç +æ–‡æ¡£
- [é¢„è®­ç»ƒæ¨¡å‹](https://zenodo.org/record/4485926) - Medical Decathlonæ¨¡å‹
- [ä½¿ç”¨æ•™ç¨‹](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/how_to_use_nnunet.md)

### æ•°æ®é›†
- [Medical Segmentation Decathlon](http://medicaldecathlon.com/) - 10ä»»åŠ¡benchmark
- [MONAI Model Zoo](https://github.com/Project-MONAI/model-zoo) - é›†æˆnnU-Net

---

## ğŸ”— ç³»åˆ—æ–‡ç« å¯¼èˆª

1. [FCNä¸UNetï¼šåŒ»å­¦åˆ†å‰²çš„å¥ åŸºä¹‹ä½œ](/2025/02/01/fcn-unet-foundation/)
2. [V-Netï¼š3DåŒ»å­¦å›¾åƒåˆ†å‰²çš„çªç ´](/2025/02/05/vnet-3d-segmentation/)
3. [Attention UNetï¼šæ³¨æ„åŠ›æœºåˆ¶çš„å¼•å…¥](/2025/02/10/attention-unet/)
4. [UNet++/UNet 3+ï¼šå¯†é›†è¿æ¥çš„åŠ›é‡](/2025/02/15/unet-plus-series/)
5. [TransUNetï¼šCNNä¸Transformerçš„èåˆ](/2025/02/20/transunet-hybrid-architecture/)
6. [Swin-UNetï¼šå±‚çº§åŒ–Transformer](/2025/02/25/swin-unet-hierarchical-transformer/)
7. [SAMä¸MedSAMï¼šåŸºç¡€æ¨¡å‹çš„åŒ»å­¦åº”ç”¨](/2025/03/05/sam-segment-anything/)
8. ğŸ“ **nnU-Netï¼šè‡ªé€‚åº”åŒ»å­¦åˆ†å‰²æ¡†æ¶**ï¼ˆæœ¬æ–‡ï¼‰

---

**ç³»åˆ—å®Œç»“å¯„è¯­**ï¼š

ä»2015å¹´çš„[UNet](/2025/02/01/fcn-unet-foundation/)åˆ°2024å¹´çš„[MedSAM](/2025/03/05/sam-segment-anything/)ï¼ŒåŒ»å­¦å›¾åƒåˆ†å‰²ç»å†äº†10å¹´çš„å¿«é€Ÿå‘å±•ã€‚æˆ‘ä»¬è§è¯äº†æ¶æ„åˆ›æ–°ï¼ˆæ³¨æ„åŠ›ã€å¯†é›†è¿æ¥ã€Transformerï¼‰ã€æ•ˆç‡æå‡ï¼ˆWindow Attentionï¼‰ã€èŒƒå¼è½¬å˜ï¼ˆPromptable Segmentationï¼‰å’Œå·¥ç¨‹ä¼˜åŒ–ï¼ˆnnU-Netï¼‰ã€‚

**æ ¸å¿ƒå¯ç¤º**ï¼š
- âœ… **æ­£ç¡®é…ç½®æ¯”æ–°æ¶æ„æ›´é‡è¦**ï¼ˆnnU-Netï¼‰
- âœ… **å…¨å±€å»ºæ¨¡vs.å±€éƒ¨ç»†èŠ‚çš„å¹³è¡¡**ï¼ˆTransformer vs. CNNï¼‰
- âœ… **æ•°æ®æ¯”ç®—æ³•æ›´é‡è¦**ï¼ˆSAMçš„11äº¿maskï¼‰
- âœ… **å®ç”¨æ€§>æ–°é¢–æ€§**ï¼ˆnnU-Netçš„æˆåŠŸï¼‰

æœªæ¥çš„åŒ»å­¦å›¾åƒåˆ†å‰²å°†èµ°å‘ï¼š
1. **åŸºç¡€æ¨¡å‹**ï¼šFew-shotå­¦ä¹ ï¼Œé™ä½æ ‡æ³¨æˆæœ¬
2. **å¤šæ¨¡æ€èåˆ**ï¼šå›¾åƒ+æ–‡æœ¬+ä¸´åºŠä¿¡æ¯
3. **å¯è§£é‡Šæ€§**ï¼šè¾…åŠ©ä¸´åºŠå†³ç­–
4. **å®æ—¶åŒ–**ï¼šæ‰‹æœ¯å¯¼èˆªã€å³æ—¶è¯Šæ–­

*æ„Ÿè°¢æ‚¨é˜…è¯»æœ¬ç³»åˆ—ï¼Œå¸Œæœ›å¯¹æ‚¨çš„ç ”ç©¶å’Œå·¥ä½œæœ‰æ‰€å¸®åŠ©ï¼*

